libdc1394 error: Failed to initialize libdc1394
Training net...

Iteration     0: accuracy_at_1 =  0.78%; accuracy_at_5 =  5.86%; loss = 4.605170 
Iteration    10: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.08%; loss = 4.632771  (0.445965 s/it)
Iteration    20: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.69%; loss = 4.604494  (0.451511 s/it)
Iteration    30: accuracy_at_1 =  1.56%; accuracy_at_5 =  5.47%; loss = 4.608736  (0.451451 s/it)
Iteration    40: accuracy_at_1 =  1.17%; accuracy_at_5 =  4.69%; loss = 4.602696  (0.451610 s/it)
Iteration    50: accuracy_at_1 =  0.00%; accuracy_at_5 =  4.69%; loss = 4.606717  (0.451403 s/it)
Iteration    60: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.52%; loss = 4.607482  (0.451394 s/it)
Iteration    70: accuracy_at_1 =  1.17%; accuracy_at_5 =  6.25%; loss = 4.601665  (0.451234 s/it)
Iteration    80: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.47%; loss = 4.608912  (0.451645 s/it)
Iteration    90: accuracy_at_1 =  0.39%; accuracy_at_5 =  4.69%; loss = 4.606465  (0.451458 s/it)
Iteration   100: accuracy_at_1 =  1.17%; accuracy_at_5 =  4.69%; loss = 4.605208  (0.451137 s/it)
Iteration   110: accuracy_at_1 =  2.34%; accuracy_at_5 =  8.20%; loss = 4.603545  (0.451620 s/it)
Iteration   120: accuracy_at_1 =  1.17%; accuracy_at_5 =  7.03%; loss = 4.605536  (0.451191 s/it)
Iteration   130: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.52%; loss = 4.602451  (0.452142 s/it)
Iteration   140: accuracy_at_1 =  0.78%; accuracy_at_5 =  5.47%; loss = 4.606650  (0.452876 s/it)
Iteration   150: accuracy_at_1 =  0.00%; accuracy_at_5 =  2.73%; loss = 4.607742  (0.452634 s/it)
Iteration   160: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.91%; loss = 4.604978  (0.452558 s/it)
Iteration   170: accuracy_at_1 =  0.39%; accuracy_at_5 =  5.08%; loss = 4.606430  (0.452950 s/it)
Iteration   180: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.91%; loss = 4.606864  (0.452328 s/it)
Iteration   190: accuracy_at_1 =  1.95%; accuracy_at_5 =  6.64%; loss = 4.605674  (0.452478 s/it)
Iteration   200: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.30%; loss = 4.609039  (0.450586 s/it)
Iteration   210: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.69%; loss = 4.605463  (0.450638 s/it)
Iteration   220: accuracy_at_1 =  1.17%; accuracy_at_5 =  7.03%; loss = 4.605620  (0.449928 s/it)
Iteration   230: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.12%; loss = 4.605581  (0.450986 s/it)
Iteration   240: accuracy_at_1 =  0.39%; accuracy_at_5 =  5.47%; loss = 4.606121  (0.451712 s/it)
Iteration   250: accuracy_at_1 =  1.95%; accuracy_at_5 =  6.64%; loss = 4.605847  (0.451704 s/it)
Iteration   260: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.12%; loss = 4.607388  (0.452011 s/it)
Iteration   270: accuracy_at_1 =  1.56%; accuracy_at_5 =  5.86%; loss = 4.607033  (0.452466 s/it)
Iteration   280: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.91%; loss = 4.604822  (0.452299 s/it)
Iteration   290: accuracy_at_1 =  0.00%; accuracy_at_5 =  4.69%; loss = 4.604113  (0.451666 s/it)
Iteration   300: accuracy_at_1 =  1.17%; accuracy_at_5 =  3.91%; loss = 4.606124  (0.452475 s/it)
Iteration   310: accuracy_at_1 =  0.00%; accuracy_at_5 =  3.12%; loss = 4.606094  (0.452567 s/it)
Iteration   320: accuracy_at_1 =  1.95%; accuracy_at_5 =  3.52%; loss = 4.605588  (0.452374 s/it)
Iteration   330: accuracy_at_1 =  0.00%; accuracy_at_5 =  3.12%; loss = 4.607185  (0.451251 s/it)
Iteration   340: accuracy_at_1 =  1.95%; accuracy_at_5 =  6.25%; loss = 4.607868  (0.451185 s/it)
Iteration   350: accuracy_at_1 =  0.39%; accuracy_at_5 =  5.08%; loss = 4.605144  (0.451211 s/it)
Iteration   360: accuracy_at_1 =  0.00%; accuracy_at_5 =  4.30%; loss = 4.605458  (0.451056 s/it)
Iteration   370: accuracy_at_1 =  1.56%; accuracy_at_5 =  4.30%; loss = 4.605984  (0.451475 s/it)
Iteration   380: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.12%; loss = 4.606805  (0.451316 s/it)
Iteration   390: accuracy_at_1 =  0.39%; accuracy_at_5 =  5.86%; loss = 4.605582  (0.453207 s/it)
Iteration   400: accuracy_at_1 =  1.56%; accuracy_at_5 =  6.64%; loss = 4.605702  (0.452529 s/it)
Iteration   410: accuracy_at_1 =  1.56%; accuracy_at_5 =  6.25%; loss = 4.603865  (0.452320 s/it)
Iteration   420: accuracy_at_1 =  0.78%; accuracy_at_5 =  7.03%; loss = 4.604667  (0.452012 s/it)
Iteration   430: accuracy_at_1 =  1.56%; accuracy_at_5 =  4.69%; loss = 4.605876  (0.452603 s/it)
Iteration   440: accuracy_at_1 =  0.78%; accuracy_at_5 =  5.47%; loss = 4.604894  (0.452196 s/it)
Iteration   450: accuracy_at_1 =  0.78%; accuracy_at_5 =  5.47%; loss = 4.605178  (0.452075 s/it)
Iteration   460: accuracy_at_1 =  1.17%; accuracy_at_5 =  3.52%; loss = 4.605934  (0.451253 s/it)
Iteration   470: accuracy_at_1 =  1.95%; accuracy_at_5 =  5.08%; loss = 4.604862  (0.451109 s/it)
Iteration   480: accuracy_at_1 =  1.56%; accuracy_at_5 =  5.47%; loss = 4.605305  (0.451139 s/it)
Iteration   490: accuracy_at_1 =  0.39%; accuracy_at_5 =  4.69%; loss = 4.604958  (0.451045 s/it)
Iteration   500: accuracy_at_1 =  0.00%; accuracy_at_5 =  4.69%; loss = 4.606459  (0.451157 s/it)
Iteration   510: accuracy_at_1 =  0.78%; accuracy_at_5 =  6.25%; loss = 4.605753  (0.450395 s/it)
Iteration   520: accuracy_at_1 =  1.17%; accuracy_at_5 =  4.30%; loss = 4.606153  (0.451812 s/it)
Iteration   530: accuracy_at_1 =  1.56%; accuracy_at_5 =  4.69%; loss = 4.606584  (0.451500 s/it)
Iteration   540: accuracy_at_1 =  1.56%; accuracy_at_5 =  5.08%; loss = 4.604181  (0.451546 s/it)
Iteration   550: accuracy_at_1 =  0.39%; accuracy_at_5 =  5.86%; loss = 4.606432  (0.451763 s/it)
Iteration   560: accuracy_at_1 =  0.00%; accuracy_at_5 =  4.30%; loss = 4.607741  (0.451610 s/it)
Iteration   570: accuracy_at_1 =  0.00%; accuracy_at_5 =  1.95%; loss = 4.605736  (0.451900 s/it)
Iteration   580: accuracy_at_1 =  1.17%; accuracy_at_5 =  3.52%; loss = 4.607142  (0.451256 s/it)
Iteration   590: accuracy_at_1 =  1.56%; accuracy_at_5 =  5.08%; loss = 4.604772  (0.450163 s/it)
Iteration   600: accuracy_at_1 =  0.00%; accuracy_at_5 =  5.08%; loss = 4.605282  (0.449798 s/it)
Iteration   610: accuracy_at_1 =  0.78%; accuracy_at_5 =  6.25%; loss = 4.605682  (0.449604 s/it)
Iteration   620: accuracy_at_1 =  1.95%; accuracy_at_5 =  5.86%; loss = 4.604264  (0.449696 s/it)
Iteration   630: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.52%; loss = 4.605990  (0.449906 s/it)
Iteration   640: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.91%; loss = 4.604656  (0.450750 s/it)
Iteration   650: accuracy_at_1 =  1.95%; accuracy_at_5 =  5.47%; loss = 4.604939  (0.451743 s/it)
Iteration   660: accuracy_at_1 =  2.34%; accuracy_at_5 =  5.86%; loss = 4.605157  (0.451508 s/it)
Iteration   670: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.12%; loss = 4.605395  (0.451782 s/it)
Iteration   680: accuracy_at_1 =  0.00%; accuracy_at_5 =  3.12%; loss = 4.606398  (0.452106 s/it)
Iteration   690: accuracy_at_1 =  1.17%; accuracy_at_5 =  4.69%; loss = 4.607337  (0.451771 s/it)
Iteration   700: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.69%; loss = 4.605618  (0.452331 s/it)
Iteration   710: accuracy_at_1 =  0.39%; accuracy_at_5 =  4.30%; loss = 4.605323  (0.451217 s/it)
Iteration   720: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.69%; loss = 4.605441  (0.450576 s/it)
Iteration   730: accuracy_at_1 =  0.00%; accuracy_at_5 =  6.25%; loss = 4.605574  (0.450876 s/it)
Iteration   740: accuracy_at_1 =  0.00%; accuracy_at_5 =  4.69%; loss = 4.605049  (0.450804 s/it)
Iteration   750: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.86%; loss = 4.605735  (0.450849 s/it)
Iteration   760: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.91%; loss = 4.605948  (0.450746 s/it)
Iteration   770: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.69%; loss = 4.605612  (0.450947 s/it)
Iteration   780: accuracy_at_1 =  1.56%; accuracy_at_5 =  3.52%; loss = 4.605949  (0.453603 s/it)
Iteration   790: accuracy_at_1 =  2.73%; accuracy_at_5 =  5.08%; loss = 4.604461  (0.451499 s/it)
Iteration   800: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.12%; loss = 4.606188  (0.451999 s/it)
Iteration   810: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.69%; loss = 4.604856  (0.451821 s/it)
Iteration   820: accuracy_at_1 =  1.95%; accuracy_at_5 =  3.91%; loss = 4.605524  (0.451885 s/it)
Iteration   830: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.12%; loss = 4.605185  (0.451907 s/it)
Iteration   840: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.08%; loss = 4.606600  (0.450715 s/it)
Iteration   850: accuracy_at_1 =  0.00%; accuracy_at_5 =  5.08%; loss = 4.605314  (0.450592 s/it)
Iteration   860: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.91%; loss = 4.606184  (0.450889 s/it)
Iteration   870: accuracy_at_1 =  0.78%; accuracy_at_5 =  5.86%; loss = 4.604545  (0.450794 s/it)
Iteration   880: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.91%; loss = 4.604856  (0.450886 s/it)
Iteration   890: accuracy_at_1 =  0.39%; accuracy_at_5 =  5.08%; loss = 4.606885  (0.450883 s/it)
Iteration   900: accuracy_at_1 =  1.95%; accuracy_at_5 =  4.30%; loss = 4.606197  (0.451547 s/it)
Iteration   910: accuracy_at_1 =  1.95%; accuracy_at_5 =  5.08%; loss = 4.604961  (0.451912 s/it)
Iteration   920: accuracy_at_1 =  2.34%; accuracy_at_5 =  5.86%; loss = 4.604685  (0.451529 s/it)
Iteration   930: accuracy_at_1 =  0.00%; accuracy_at_5 =  5.86%; loss = 4.604972  (0.451949 s/it)
Iteration   940: accuracy_at_1 =  1.56%; accuracy_at_5 =  6.25%; loss = 4.604682  (0.452171 s/it)
Iteration   950: accuracy_at_1 =  0.78%; accuracy_at_5 =  5.86%; loss = 4.606785  (0.451941 s/it)
Iteration   960: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.52%; loss = 4.606221  (0.451836 s/it)
Iteration   970: accuracy_at_1 =  1.95%; accuracy_at_5 =  6.25%; loss = 4.605932  (0.450917 s/it)
Iteration   980: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.30%; loss = 4.606196  (0.450815 s/it)
Iteration   990: accuracy_at_1 =  0.00%; accuracy_at_5 =  3.52%; loss = 4.606560  (0.451055 s/it)
Iteration  1000: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.30%; loss = 4.605499  (0.450677 s/it)
Iteration  1010: accuracy_at_1 =  0.00%; accuracy_at_5 =  1.95%; loss = 4.606138  (0.450924 s/it)
Iteration  1020: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.91%; loss = 4.605989  (0.450332 s/it)
Iteration  1030: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.86%; loss = 4.605104  (0.451756 s/it)
Iteration  1040: accuracy_at_1 =  1.17%; accuracy_at_5 =  4.69%; loss = 4.605063  (0.452329 s/it)
Iteration  1050: accuracy_at_1 =  0.00%; accuracy_at_5 =  5.47%; loss = 4.604619  (0.452174 s/it)
Iteration  1060: accuracy_at_1 =  0.78%; accuracy_at_5 =  5.86%; loss = 4.605345  (0.452202 s/it)
Iteration  1070: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.91%; loss = 4.606128  (0.452312 s/it)
Iteration  1080: accuracy_at_1 =  1.95%; accuracy_at_5 =  4.30%; loss = 4.606285  (0.452055 s/it)
Iteration  1090: accuracy_at_1 =  1.17%; accuracy_at_5 =  2.34%; loss = 4.605923  (0.451863 s/it)
Iteration  1100: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.12%; loss = 4.606654  (0.451008 s/it)
Iteration  1110: accuracy_at_1 =  0.39%; accuracy_at_5 =  2.73%; loss = 4.606188  (0.450654 s/it)
Iteration  1120: accuracy_at_1 =  1.56%; accuracy_at_5 =  3.52%; loss = 4.605584  (0.450935 s/it)
Iteration  1130: accuracy_at_1 =  0.39%; accuracy_at_5 =  5.08%; loss = 4.605262  (0.450549 s/it)
Iteration  1140: accuracy_at_1 =  0.39%; accuracy_at_5 =  6.64%; loss = 4.605083  (0.450779 s/it)
Iteration  1150: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.52%; loss = 4.605304  (0.450737 s/it)
Iteration  1160: accuracy_at_1 =  1.17%; accuracy_at_5 =  7.81%; loss = 4.605315  (0.451736 s/it)
Iteration  1170: accuracy_at_1 =  1.17%; accuracy_at_5 =  4.30%; loss = 4.605700  (0.453770 s/it)
Iteration  1180: accuracy_at_1 =  0.78%; accuracy_at_5 =  5.47%; loss = 4.605166  (0.452191 s/it)
Iteration  1190: accuracy_at_1 =  1.56%; accuracy_at_5 =  5.47%; loss = 4.605242  (0.452156 s/it)
Iteration  1200: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.08%; loss = 4.604745  (0.451933 s/it)
Iteration  1210: accuracy_at_1 =  0.78%; accuracy_at_5 =  2.34%; loss = 4.606692  (0.452134 s/it)
Iteration  1220: accuracy_at_1 =  0.78%; accuracy_at_5 =  5.86%; loss = 4.605821  (0.451139 s/it)
Iteration  1230: accuracy_at_1 =  0.39%; accuracy_at_5 =  5.47%; loss = 4.604892  (0.450857 s/it)
Iteration  1240: accuracy_at_1 =  1.17%; accuracy_at_5 =  4.30%; loss = 4.604504  (0.450809 s/it)
Iteration  1250: accuracy_at_1 =  0.39%; accuracy_at_5 =  5.47%; loss = 4.604259  (0.450546 s/it)
Iteration  1260: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.86%; loss = 4.606293  (0.450898 s/it)
Iteration  1270: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.86%; loss = 4.605208  (0.451002 s/it)
Iteration  1280: accuracy_at_1 =  0.39%; accuracy_at_5 =  5.08%; loss = 4.605193  (0.451055 s/it)
Iteration  1290: accuracy_at_1 =  0.39%; accuracy_at_5 =  4.30%; loss = 4.604794  (0.452050 s/it)
Iteration  1300: accuracy_at_1 =  0.00%; accuracy_at_5 =  3.52%; loss = 4.606671  (0.452039 s/it)
Iteration  1310: accuracy_at_1 =  1.56%; accuracy_at_5 =  5.08%; loss = 4.605711  (0.451800 s/it)
Iteration  1320: accuracy_at_1 =  1.17%; accuracy_at_5 =  4.69%; loss = 4.605907  (0.451921 s/it)
Iteration  1330: accuracy_at_1 =  0.00%; accuracy_at_5 =  5.47%; loss = 4.605478  (0.451914 s/it)
Iteration  1340: accuracy_at_1 =  0.39%; accuracy_at_5 =  4.30%; loss = 4.605713  (0.452012 s/it)
Iteration  1350: accuracy_at_1 =  1.95%; accuracy_at_5 =  5.47%; loss = 4.604714  (0.451042 s/it)
Iteration  1360: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.86%; loss = 4.603941  (0.450844 s/it)
Iteration  1370: accuracy_at_1 =  1.56%; accuracy_at_5 =  5.47%; loss = 4.605182  (0.450900 s/it)
Iteration  1380: accuracy_at_1 =  1.95%; accuracy_at_5 =  4.69%; loss = 4.606319  (0.450939 s/it)
Iteration  1390: accuracy_at_1 =  0.39%; accuracy_at_5 =  5.47%; loss = 4.605951  (0.451068 s/it)
Iteration  1400: accuracy_at_1 =  0.78%; accuracy_at_5 =  5.47%; loss = 4.606067  (0.451228 s/it)
Iteration  1410: accuracy_at_1 =  0.00%; accuracy_at_5 =  4.69%; loss = 4.605567  (0.451310 s/it)
Iteration  1420: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.52%; loss = 4.606315  (0.452370 s/it)
Iteration  1430: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.69%; loss = 4.605654  (0.452188 s/it)
Iteration  1440: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.30%; loss = 4.605104  (0.452231 s/it)
Iteration  1450: accuracy_at_1 =  1.17%; accuracy_at_5 =  4.69%; loss = 4.605890  (0.452391 s/it)
Iteration  1460: accuracy_at_1 =  0.00%; accuracy_at_5 =  1.95%; loss = 4.605682  (0.452084 s/it)
Iteration  1470: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.12%; loss = 4.606718  (0.452094 s/it)
Iteration  1480: accuracy_at_1 =  0.00%; accuracy_at_5 =  3.52%; loss = 4.605786  (0.450637 s/it)
Iteration  1490: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.91%; loss = 4.605389  (0.450714 s/it)
Iteration  1500: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.08%; loss = 4.605748  (0.450673 s/it)
Iteration  1510: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.47%; loss = 4.605143  (0.450993 s/it)
Iteration  1520: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.69%; loss = 4.605630  (0.450892 s/it)
Iteration  1530: accuracy_at_1 =  1.17%; accuracy_at_5 =  4.69%; loss = 4.605771  (0.450796 s/it)
Iteration  1540: accuracy_at_1 =  1.17%; accuracy_at_5 =  3.91%; loss = 4.605865  (0.451434 s/it)
Iteration  1550: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.91%; loss = 4.606022  (0.451908 s/it)
Iteration  1560: accuracy_at_1 =  0.78%; accuracy_at_5 =  1.95%; loss = 4.605450  (0.452208 s/it)
Iteration  1570: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.86%; loss = 4.605536  (0.453311 s/it)
Iteration  1580: accuracy_at_1 =  1.56%; accuracy_at_5 =  7.03%; loss = 4.605034  (0.451936 s/it)
Iteration  1590: accuracy_at_1 =  1.17%; accuracy_at_5 =  3.52%; loss = 4.605584  (0.451595 s/it)
Iteration  1600: accuracy_at_1 =  1.17%; accuracy_at_5 =  8.20%; loss = 4.604904  (0.451648 s/it)
Iteration  1610: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.30%; loss = 4.604859  (0.450612 s/it)
Iteration  1620: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.47%; loss = 4.605815  (0.450678 s/it)
Iteration  1630: accuracy_at_1 =  0.39%; accuracy_at_5 =  4.30%; loss = 4.606340  (0.450741 s/it)
Iteration  1640: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.91%; loss = 4.605374  (0.451329 s/it)
Iteration  1650: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.52%; loss = 4.605600  (0.450683 s/it)
Iteration  1660: accuracy_at_1 =  0.78%; accuracy_at_5 =  6.25%; loss = 4.605714  (0.450635 s/it)
Iteration  1670: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.86%; loss = 4.604776  (0.451730 s/it)
Iteration  1680: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.30%; loss = 4.606289  (0.452087 s/it)
Iteration  1690: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.08%; loss = 4.605201  (0.451865 s/it)
Iteration  1700: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.47%; loss = 4.604827  (0.451791 s/it)
Iteration  1710: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.52%; loss = 4.606107  (0.451665 s/it)
Iteration  1720: accuracy_at_1 =  0.00%; accuracy_at_5 =  3.91%; loss = 4.605240  (0.451779 s/it)
Iteration  1730: accuracy_at_1 =  0.78%; accuracy_at_5 =  6.64%; loss = 4.605390  (0.451432 s/it)
Iteration  1740: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.12%; loss = 4.605951  (0.450530 s/it)
Iteration  1750: accuracy_at_1 =  0.39%; accuracy_at_5 =  4.30%; loss = 4.605367  (0.450838 s/it)
Iteration  1760: accuracy_at_1 =  0.78%; accuracy_at_5 =  7.42%; loss = 4.604325  (0.450633 s/it)
Iteration  1770: accuracy_at_1 =  1.17%; accuracy_at_5 =  4.69%; loss = 4.606003  (0.450696 s/it)
Iteration  1780: accuracy_at_1 =  1.95%; accuracy_at_5 =  7.03%; loss = 4.604325  (0.450620 s/it)
Iteration  1790: accuracy_at_1 =  1.17%; accuracy_at_5 =  3.52%; loss = 4.605507  (0.450727 s/it)
Iteration  1800: accuracy_at_1 =  1.17%; accuracy_at_5 =  6.64%; loss = 4.603839  (0.452013 s/it)
Iteration  1810: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.91%; loss = 4.604757  (0.452034 s/it)
Iteration  1820: accuracy_at_1 =  2.34%; accuracy_at_5 =  5.08%; loss = 4.605629  (0.451799 s/it)
Iteration  1830: accuracy_at_1 =  1.95%; accuracy_at_5 =  7.42%; loss = 4.604375  (0.451788 s/it)
Iteration  1840: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.08%; loss = 4.605217  (0.452037 s/it)
Iteration  1850: accuracy_at_1 =  0.00%; accuracy_at_5 =  4.30%; loss = 4.605479  (0.451888 s/it)
Iteration  1860: accuracy_at_1 =  0.39%; accuracy_at_5 =  4.69%; loss = 4.604610  (0.451507 s/it)
Iteration  1870: accuracy_at_1 =  0.00%; accuracy_at_5 =  3.52%; loss = 4.606269  (0.450983 s/it)
Iteration  1880: accuracy_at_1 =  0.39%; accuracy_at_5 =  4.69%; loss = 4.606874  (0.450787 s/it)
Iteration  1890: accuracy_at_1 =  1.56%; accuracy_at_5 =  5.08%; loss = 4.604276  (0.450691 s/it)
Iteration  1900: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.91%; loss = 4.606430  (0.450698 s/it)
Iteration  1910: accuracy_at_1 =  1.56%; accuracy_at_5 =  6.25%; loss = 4.606090  (0.450823 s/it)
Iteration  1920: accuracy_at_1 =  0.39%; accuracy_at_5 =  2.73%; loss = 4.605636  (0.450396 s/it)
Iteration  1930: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.91%; loss = 4.605241  (0.452024 s/it)
Iteration  1940: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.91%; loss = 4.605534  (0.451242 s/it)
Iteration  1950: accuracy_at_1 =  0.78%; accuracy_at_5 =  2.73%; loss = 4.605881  (0.452130 s/it)
Iteration  1960: accuracy_at_1 =  0.39%; accuracy_at_5 =  8.59%; loss = 4.605128  (0.452978 s/it)
Iteration  1970: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.91%; loss = 4.605625  (0.451810 s/it)
Iteration  1980: accuracy_at_1 =  1.56%; accuracy_at_5 =  6.64%; loss = 4.604425  (0.451975 s/it)
Iteration  1990: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.69%; loss = 4.605803  (0.450897 s/it)
Iteration  2000: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.91%; loss = 4.605617  (0.450705 s/it)
Iteration  2010: accuracy_at_1 =  1.17%; accuracy_at_5 =  4.30%; loss = 4.605983  (0.450862 s/it)
Iteration  2020: accuracy_at_1 =  1.17%; accuracy_at_5 =  7.03%; loss = 4.606009  (0.450885 s/it)
Iteration  2030: accuracy_at_1 =  0.00%; accuracy_at_5 =  4.30%; loss = 4.606359  (0.450631 s/it)
Iteration  2040: accuracy_at_1 =  0.78%; accuracy_at_5 =  5.86%; loss = 4.605165  (0.451389 s/it)
Iteration  2050: accuracy_at_1 =  1.56%; accuracy_at_5 =  8.98%; loss = 4.604247  (0.451197 s/it)
Iteration  2060: accuracy_at_1 =  1.17%; accuracy_at_5 =  3.91%; loss = 4.606226  (0.452139 s/it)
Iteration  2070: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.30%; loss = 4.605780  (0.451694 s/it)
Iteration  2080: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.08%; loss = 4.605260  (0.452467 s/it)
Iteration  2090: accuracy_at_1 =  0.39%; accuracy_at_5 =  4.69%; loss = 4.605342  (0.452267 s/it)
Iteration  2100: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.52%; loss = 4.606098  (0.452155 s/it)
Iteration  2110: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.08%; loss = 4.605159  (0.452085 s/it)
Iteration  2120: accuracy_at_1 =  2.34%; accuracy_at_5 =  7.03%; loss = 4.604576  (0.451732 s/it)
Iteration  2130: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.52%; loss = 4.606080  (0.450954 s/it)
Iteration  2140: accuracy_at_1 =  0.00%; accuracy_at_5 =  4.30%; loss = 4.605895  (0.451077 s/it)
Iteration  2150: accuracy_at_1 =  0.78%; accuracy_at_5 =  5.47%; loss = 4.605637  (0.450683 s/it)
Iteration  2160: accuracy_at_1 =  1.56%; accuracy_at_5 =  3.91%; loss = 4.605896  (0.451060 s/it)
Iteration  2170: accuracy_at_1 =  1.17%; accuracy_at_5 =  3.52%; loss = 4.605281  (0.450471 s/it)
Iteration  2180: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.12%; loss = 4.605032  (0.451305 s/it)
Iteration  2190: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.91%; loss = 4.606606  (0.451695 s/it)
Iteration  2200: accuracy_at_1 =  1.56%; accuracy_at_5 =  5.08%; loss = 4.604735  (0.451711 s/it)
Iteration  2210: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.30%; loss = 4.606361  (0.451368 s/it)
Iteration  2220: accuracy_at_1 =  1.56%; accuracy_at_5 =  5.86%; loss = 4.605505  (0.451692 s/it)
Iteration  2230: accuracy_at_1 =  0.39%; accuracy_at_5 =  2.73%; loss = 4.605529  (0.451413 s/it)
Iteration  2240: accuracy_at_1 =  1.56%; accuracy_at_5 =  5.86%; loss = 4.604621  (0.451277 s/it)
Iteration  2250: accuracy_at_1 =  1.95%; accuracy_at_5 =  6.64%; loss = 4.606485  (0.450399 s/it)
Iteration  2260: accuracy_at_1 =  0.39%; accuracy_at_5 =  4.30%; loss = 4.605744  (0.450386 s/it)
Iteration  2270: accuracy_at_1 =  1.17%; accuracy_at_5 =  4.69%; loss = 4.605602  (0.450378 s/it)
Iteration  2280: accuracy_at_1 =  0.00%; accuracy_at_5 =  4.69%; loss = 4.605966  (0.450565 s/it)
Iteration  2290: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.69%; loss = 4.605185  (0.450515 s/it)
Iteration  2300: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.91%; loss = 4.605596  (0.450671 s/it)
Iteration  2310: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.91%; loss = 4.605865  (0.451223 s/it)
Iteration  2320: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.52%; loss = 4.605994  (0.451626 s/it)
Iteration  2330: accuracy_at_1 =  0.39%; accuracy_at_5 =  4.69%; loss = 4.605684  (0.451754 s/it)
Iteration  2340: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.12%; loss = 4.605590  (0.451692 s/it)
Iteration  2350: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.52%; loss = 4.605577  (0.453161 s/it)
Iteration  2360: accuracy_at_1 =  1.56%; accuracy_at_5 =  6.25%; loss = 4.605107  (0.452081 s/it)
Iteration  2370: accuracy_at_1 =  0.78%; accuracy_at_5 =  5.86%; loss = 4.605052  (0.451159 s/it)
Iteration  2380: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.08%; loss = 4.605362  (0.450696 s/it)
Iteration  2390: accuracy_at_1 =  0.39%; accuracy_at_5 =  4.69%; loss = 4.605468  (0.450808 s/it)
Iteration  2400: accuracy_at_1 =  1.17%; accuracy_at_5 =  6.25%; loss = 4.604368  (0.450759 s/it)
Iteration  2410: accuracy_at_1 =  1.56%; accuracy_at_5 =  4.30%; loss = 4.604896  (0.450504 s/it)
Iteration  2420: accuracy_at_1 =  0.39%; accuracy_at_5 =  4.69%; loss = 4.604706  (0.450715 s/it)
Iteration  2430: accuracy_at_1 =  1.17%; accuracy_at_5 =  4.69%; loss = 4.606328  (0.450950 s/it)
Iteration  2440: accuracy_at_1 =  1.56%; accuracy_at_5 =  5.86%; loss = 4.604950  (0.451680 s/it)
Iteration  2450: accuracy_at_1 =  1.56%; accuracy_at_5 =  6.25%; loss = 4.606254  (0.451891 s/it)
Iteration  2460: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.69%; loss = 4.605536  (0.451566 s/it)
Iteration  2470: accuracy_at_1 =  0.39%; accuracy_at_5 =  2.34%; loss = 4.605601  (0.451991 s/it)
Iteration  2480: accuracy_at_1 =  1.17%; accuracy_at_5 =  4.69%; loss = 4.605774  (0.451792 s/it)
Iteration  2490: accuracy_at_1 =  1.56%; accuracy_at_5 =  5.08%; loss = 4.605045  (0.451697 s/it)
Iteration  2500: accuracy_at_1 =  0.00%; accuracy_at_5 =  3.12%; loss = 4.605284  (0.451241 s/it)
Iteration  2510: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.91%; loss = 4.605714  (0.450564 s/it)
Iteration  2520: accuracy_at_1 =  0.78%; accuracy_at_5 =  5.47%; loss = 4.606030  (0.450812 s/it)
Iteration  2530: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.12%; loss = 4.606996  (0.450853 s/it)
Iteration  2540: accuracy_at_1 =  1.17%; accuracy_at_5 =  4.69%; loss = 4.604955  (0.450572 s/it)
Iteration  2550: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.52%; loss = 4.606011  (0.451100 s/it)
Iteration  2560: accuracy_at_1 =  1.56%; accuracy_at_5 =  7.03%; loss = 4.604201  (0.450743 s/it)
Iteration  2570: accuracy_at_1 =  0.00%; accuracy_at_5 =  3.91%; loss = 4.606743  (0.451994 s/it)
Iteration  2580: accuracy_at_1 =  0.00%; accuracy_at_5 =  3.91%; loss = 4.606591  (0.452100 s/it)
Iteration  2590: accuracy_at_1 =  1.56%; accuracy_at_5 =  5.86%; loss = 4.605903  (0.452369 s/it)
Iteration  2600: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.08%; loss = 4.605597  (0.453267 s/it)
Iteration  2610: accuracy_at_1 =  1.95%; accuracy_at_5 =  5.86%; loss = 4.605822  (0.452463 s/it)
Iteration  2620: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.47%; loss = 4.604948  (0.452536 s/it)
Iteration  2630: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.91%; loss = 4.605830  (0.451454 s/it)
Iteration  2640: accuracy_at_1 =  1.56%; accuracy_at_5 =  5.86%; loss = 4.604908  (0.451209 s/it)
Iteration  2650: accuracy_at_1 =  1.95%; accuracy_at_5 =  5.08%; loss = 4.605201  (0.451391 s/it)
Iteration  2660: accuracy_at_1 =  1.17%; accuracy_at_5 =  3.91%; loss = 4.606042  (0.451756 s/it)
Iteration  2670: accuracy_at_1 =  0.39%; accuracy_at_5 =  5.47%; loss = 4.605746  (0.451301 s/it)
Iteration  2680: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.91%; loss = 4.605532  (0.451654 s/it)
Iteration  2690: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.91%; loss = 4.606105  (0.451604 s/it)
Iteration  2700: accuracy_at_1 =  0.78%; accuracy_at_5 =  1.95%; loss = 4.605733  (0.452483 s/it)
Iteration  2710: accuracy_at_1 =  0.78%; accuracy_at_5 =  5.86%; loss = 4.605155  (0.452511 s/it)
Iteration  2720: accuracy_at_1 =  0.39%; accuracy_at_5 =  5.08%; loss = 4.605803  (0.452165 s/it)
Iteration  2730: accuracy_at_1 =  0.39%; accuracy_at_5 =  4.30%; loss = 4.606047  (0.452478 s/it)
Iteration  2740: accuracy_at_1 =  0.78%; accuracy_at_5 =  2.73%; loss = 4.605237  (0.453305 s/it)
Iteration  2750: accuracy_at_1 =  1.56%; accuracy_at_5 =  5.86%; loss = 4.604765  (0.452708 s/it)
Iteration  2760: accuracy_at_1 =  1.95%; accuracy_at_5 =  6.25%; loss = 4.605067  (0.451265 s/it)
Iteration  2770: accuracy_at_1 =  0.39%; accuracy_at_5 =  2.73%; loss = 4.605612  (0.451170 s/it)
Iteration  2780: accuracy_at_1 =  0.78%; accuracy_at_5 =  5.86%; loss = 4.605009  (0.451373 s/it)
Iteration  2790: accuracy_at_1 =  1.17%; accuracy_at_5 =  3.91%; loss = 4.604309  (0.451184 s/it)
Iteration  2800: accuracy_at_1 =  1.17%; accuracy_at_5 =  4.30%; loss = 4.606140  (0.450558 s/it)
Iteration  2810: accuracy_at_1 =  1.56%; accuracy_at_5 =  5.47%; loss = 4.605191  (0.451403 s/it)
Iteration  2820: accuracy_at_1 =  0.39%; accuracy_at_5 =  4.69%; loss = 4.604537  (0.451412 s/it)
Iteration  2830: accuracy_at_1 =  0.39%; accuracy_at_5 =  2.34%; loss = 4.606089  (0.451968 s/it)
Iteration  2840: accuracy_at_1 =  1.95%; accuracy_at_5 =  3.91%; loss = 4.605550  (0.452086 s/it)
Iteration  2850: accuracy_at_1 =  0.78%; accuracy_at_5 =  5.47%; loss = 4.604271  (0.451878 s/it)
Iteration  2860: accuracy_at_1 =  1.17%; accuracy_at_5 =  4.69%; loss = 4.606071  (0.451920 s/it)
Iteration  2870: accuracy_at_1 =  2.34%; accuracy_at_5 =  4.30%; loss = 4.604791  (0.451487 s/it)
Iteration  2880: accuracy_at_1 =  0.00%; accuracy_at_5 =  2.73%; loss = 4.605458  (0.452320 s/it)
Iteration  2890: accuracy_at_1 =  0.78%; accuracy_at_5 =  5.47%; loss = 4.605387  (0.451042 s/it)
Iteration  2900: accuracy_at_1 =  0.78%; accuracy_at_5 =  5.86%; loss = 4.606030  (0.450966 s/it)
Iteration  2910: accuracy_at_1 =  1.56%; accuracy_at_5 =  5.08%; loss = 4.606109  (0.451217 s/it)
Iteration  2920: accuracy_at_1 =  1.56%; accuracy_at_5 =  3.91%; loss = 4.606751  (0.451386 s/it)
Iteration  2930: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.91%; loss = 4.605657  (0.451137 s/it)
Iteration  2940: accuracy_at_1 =  0.00%; accuracy_at_5 =  4.30%; loss = 4.605161  (0.451342 s/it)
Iteration  2950: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.12%; loss = 4.605308  (0.451888 s/it)
Iteration  2960: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.91%; loss = 4.605574  (0.452020 s/it)
Iteration  2970: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.91%; loss = 4.606211  (0.451688 s/it)
Iteration  2980: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.52%; loss = 4.606899  (0.451957 s/it)
Iteration  2990: accuracy_at_1 =  1.17%; accuracy_at_5 =  3.91%; loss = 4.605473  (0.451771 s/it)
Iteration  3000: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.12%; loss = 4.605405  (0.452039 s/it)
Iteration  3010: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.30%; loss = 4.606295  (0.452110 s/it)
Iteration  3020: accuracy_at_1 =  0.39%; accuracy_at_5 =  4.30%; loss = 4.604699  (0.450822 s/it)
Iteration  3030: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.30%; loss = 4.605450  (0.451190 s/it)
Iteration  3040: accuracy_at_1 =  1.95%; accuracy_at_5 =  4.30%; loss = 4.605705  (0.451094 s/it)
Iteration  3050: accuracy_at_1 =  0.00%; accuracy_at_5 =  2.34%; loss = 4.605626  (0.450816 s/it)
Iteration  3060: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.69%; loss = 4.605674  (0.450935 s/it)
Iteration  3070: accuracy_at_1 =  0.39%; accuracy_at_5 =  5.08%; loss = 4.605795  (0.451224 s/it)
Iteration  3080: accuracy_at_1 =  1.17%; accuracy_at_5 =  4.30%; loss = 4.605572  (0.452103 s/it)
Iteration  3090: accuracy_at_1 =  0.39%; accuracy_at_5 =  4.30%; loss = 4.605649  (0.452658 s/it)
Iteration  3100: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.30%; loss = 4.605641  (0.452770 s/it)
Iteration  3110: accuracy_at_1 =  1.56%; accuracy_at_5 =  2.73%; loss = 4.605480  (0.452514 s/it)
Iteration  3120: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.30%; loss = 4.605480  (0.451971 s/it)
Iteration  3130: accuracy_at_1 =  0.39%; accuracy_at_5 =  4.30%; loss = 4.605210  (0.453671 s/it)
Iteration  3140: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.12%; loss = 4.605381  (0.451417 s/it)
Iteration  3150: accuracy_at_1 =  0.78%; accuracy_at_5 =  5.86%; loss = 4.605101  (0.451092 s/it)
Iteration  3160: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.30%; loss = 4.605549  (0.451964 s/it)
Iteration  3170: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.12%; loss = 4.605513  (0.451866 s/it)
Iteration  3180: accuracy_at_1 =  1.56%; accuracy_at_5 =  5.47%; loss = 4.605426  (0.450352 s/it)
Iteration  3190: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.69%; loss = 4.606110  (0.450482 s/it)
Iteration  3200: accuracy_at_1 =  1.17%; accuracy_at_5 =  7.03%; loss = 4.605050  (0.449837 s/it)
Iteration  3210: accuracy_at_1 =  0.00%; accuracy_at_5 =  3.91%; loss = 4.605688  (0.452141 s/it)
Iteration  3220: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.30%; loss = 4.605531  (0.452141 s/it)
Iteration  3230: accuracy_at_1 =  1.17%; accuracy_at_5 =  4.30%; loss = 4.606648  (0.453612 s/it)
Iteration  3240: accuracy_at_1 =  1.17%; accuracy_at_5 =  4.69%; loss = 4.605851  (0.452012 s/it)
Iteration  3250: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.08%; loss = 4.604714  (0.453737 s/it)
Iteration  3260: accuracy_at_1 =  1.56%; accuracy_at_5 =  6.64%; loss = 4.605564  (0.452025 s/it)
Iteration  3270: accuracy_at_1 =  2.73%; accuracy_at_5 =  5.08%; loss = 4.604797  (0.450131 s/it)
Iteration  3280: accuracy_at_1 =  0.39%; accuracy_at_5 =  4.30%; loss = 4.606398  (0.451384 s/it)
Iteration  3290: accuracy_at_1 =  0.39%; accuracy_at_5 =  5.47%; loss = 4.605193  (0.450796 s/it)
Iteration  3300: accuracy_at_1 =  0.00%; accuracy_at_5 =  4.69%; loss = 4.605121  (0.450856 s/it)
Iteration  3310: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.69%; loss = 4.605721  (0.451349 s/it)
Iteration  3320: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.91%; loss = 4.605827  (0.451406 s/it)
Iteration  3330: accuracy_at_1 =  1.17%; accuracy_at_5 =  2.34%; loss = 4.606175  (0.451935 s/it)
Iteration  3340: accuracy_at_1 =  1.17%; accuracy_at_5 =  7.42%; loss = 4.604668  (0.451650 s/it)
Iteration  3350: accuracy_at_1 =  0.39%; accuracy_at_5 =  4.69%; loss = 4.605084  (0.452152 s/it)
Iteration  3360: accuracy_at_1 =  1.95%; accuracy_at_5 =  4.69%; loss = 4.605174  (0.452178 s/it)
Iteration  3370: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.47%; loss = 4.604823  (0.452454 s/it)
Iteration  3380: accuracy_at_1 =  0.39%; accuracy_at_5 =  5.47%; loss = 4.604482  (0.452904 s/it)
Iteration  3390: accuracy_at_1 =  0.39%; accuracy_at_5 =  4.30%; loss = 4.606733  (0.452547 s/it)
Iteration  3400: accuracy_at_1 =  0.39%; accuracy_at_5 =  2.73%; loss = 4.605762  (0.451214 s/it)
Iteration  3410: accuracy_at_1 =  0.00%; accuracy_at_5 =  4.69%; loss = 4.604509  (0.450834 s/it)
Iteration  3420: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.69%; loss = 4.606516  (0.451154 s/it)
Iteration  3430: accuracy_at_1 =  0.78%; accuracy_at_5 =  2.73%; loss = 4.605894  (0.451025 s/it)
Iteration  3440: accuracy_at_1 =  0.78%; accuracy_at_5 =  5.86%; loss = 4.605819  (0.451183 s/it)
Iteration  3450: accuracy_at_1 =  0.39%; accuracy_at_5 =  4.69%; loss = 4.605780  (0.451221 s/it)
Iteration  3460: accuracy_at_1 =  0.00%; accuracy_at_5 =  3.12%; loss = 4.606779  (0.451991 s/it)
Iteration  3470: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.52%; loss = 4.604951  (0.452305 s/it)
Iteration  3480: accuracy_at_1 =  0.39%; accuracy_at_5 =  5.08%; loss = 4.605979  (0.452520 s/it)
Iteration  3490: accuracy_at_1 =  1.17%; accuracy_at_5 =  7.42%; loss = 4.605144  (0.452064 s/it)
Iteration  3500: accuracy_at_1 =  0.39%; accuracy_at_5 =  2.34%; loss = 4.605815  (0.452074 s/it)
Iteration  3510: accuracy_at_1 =  0.78%; accuracy_at_5 =  2.73%; loss = 4.605690  (0.452277 s/it)
Iteration  3520: accuracy_at_1 =  1.56%; accuracy_at_5 =  6.25%; loss = 4.605063  (0.453340 s/it)
Iteration  3530: accuracy_at_1 =  0.39%; accuracy_at_5 =  4.69%; loss = 4.605530  (0.451709 s/it)
Iteration  3540: accuracy_at_1 =  0.78%; accuracy_at_5 =  8.59%; loss = 4.604726  (0.452227 s/it)
Iteration  3550: accuracy_at_1 =  0.78%; accuracy_at_5 =  5.08%; loss = 4.605049  (0.451715 s/it)
Iteration  3560: accuracy_at_1 =  1.56%; accuracy_at_5 =  5.47%; loss = 4.604352  (0.451588 s/it)
Iteration  3570: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.52%; loss = 4.605050  (0.451146 s/it)
Iteration  3580: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.91%; loss = 4.605737  (0.451258 s/it)
Iteration  3590: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.12%; loss = 4.604036  (0.451249 s/it)
Iteration  3600: accuracy_at_1 =  1.17%; accuracy_at_5 =  6.25%; loss = 4.605490  (0.452033 s/it)
Iteration  3610: accuracy_at_1 =  1.95%; accuracy_at_5 =  9.38%; loss = 4.604455  (0.451845 s/it)
Iteration  3620: accuracy_at_1 =  0.78%; accuracy_at_5 =  6.25%; loss = 4.604518  (0.451477 s/it)
Iteration  3630: accuracy_at_1 =  0.39%; accuracy_at_5 =  4.69%; loss = 4.605551  (0.451149 s/it)
Iteration  3640: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.86%; loss = 4.605392  (0.452373 s/it)
Iteration  3650: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.69%; loss = 4.605886  (0.452273 s/it)
Iteration  3660: accuracy_at_1 =  1.95%; accuracy_at_5 =  4.30%; loss = 4.605173  (0.450893 s/it)
Iteration  3670: accuracy_at_1 =  1.56%; accuracy_at_5 =  4.30%; loss = 4.605526  (0.450876 s/it)
Iteration  3680: accuracy_at_1 =  1.17%; accuracy_at_5 =  4.30%; loss = 4.605278  (0.451618 s/it)
Iteration  3690: accuracy_at_1 =  0.39%; accuracy_at_5 =  3.12%; loss = 4.606664  (0.451339 s/it)
Iteration  3700: accuracy_at_1 =  1.17%; accuracy_at_5 =  3.52%; loss = 4.605956  (0.451250 s/it)
Iteration  3710: accuracy_at_1 =  1.17%; accuracy_at_5 =  4.69%; loss = 4.605844  (0.451216 s/it)
Iteration  3720: accuracy_at_1 =  0.00%; accuracy_at_5 =  5.86%; loss = 4.606009  (0.452428 s/it)
Iteration  3730: accuracy_at_1 =  1.56%; accuracy_at_5 =  4.69%; loss = 4.606105  (0.452062 s/it)
Iteration  3740: accuracy_at_1 =  0.78%; accuracy_at_5 =  2.73%; loss = 4.606231  (0.452701 s/it)
Iteration  3750: accuracy_at_1 =  1.56%; accuracy_at_5 =  3.12%; loss = 4.605454  (0.452406 s/it)
Iteration  3760: accuracy_at_1 =  0.00%; accuracy_at_5 =  4.69%; loss = 4.606586  (0.452214 s/it)
Iteration  3770: accuracy_at_1 =  0.78%; accuracy_at_5 =  4.30%; loss = 4.605492  (0.451704 s/it)
Iteration  3780: accuracy_at_1 =  0.78%; accuracy_at_5 =  5.47%; loss = 4.606407  (0.451849 s/it)
Iteration  3790: accuracy_at_1 =  1.17%; accuracy_at_5 =  3.12%; loss = 4.606332  (0.451360 s/it)
Iteration  3800: accuracy_at_1 =  1.17%; accuracy_at_5 =  3.52%; loss = 4.605391  (0.451860 s/it)
Iteration  3810: accuracy_at_1 =  0.00%; accuracy_at_5 =  3.52%; loss = 4.606278  (0.452545 s/it)
Iteration  3820: accuracy_at_1 =  2.34%; accuracy_at_5 =  8.20%; loss = 4.605151  (0.451323 s/it)
