libdc1394 error: Failed to initialize libdc1394
Training net...

Iteration     0: accuracy_at_1 =  1.17%; accuracy_at_5 =  5.86%; loss = 4.605170 
Iteration    10: accuracy_at_1 =  0.78%; accuracy_at_5 =  3.12%; loss = 4.645832  (0.692064 s/it)
Iteration    20: accuracy_at_1 =  1.17%; accuracy_at_5 =  7.42%; loss = 4.578837  (0.696277 s/it)
Iteration    30: accuracy_at_1 =  3.91%; accuracy_at_5 = 10.94%; loss = 4.547076  (0.696676 s/it)
Iteration    40: accuracy_at_1 =  1.56%; accuracy_at_5 =  7.42%; loss = 4.542069  (0.695875 s/it)
Iteration    50: accuracy_at_1 =  2.73%; accuracy_at_5 = 10.55%; loss = 4.488612  (0.696366 s/it)
Iteration    60: accuracy_at_1 =  1.56%; accuracy_at_5 =  8.59%; loss = 4.564783  (0.695993 s/it)
Iteration    70: accuracy_at_1 =  3.12%; accuracy_at_5 = 11.33%; loss = 4.487512  (0.696237 s/it)
Iteration    80: accuracy_at_1 =  2.34%; accuracy_at_5 = 10.55%; loss = 4.437024  (0.696233 s/it)
Iteration    90: accuracy_at_1 =  2.34%; accuracy_at_5 =  9.38%; loss = 4.428781  (0.695915 s/it)
Iteration   100: accuracy_at_1 =  2.73%; accuracy_at_5 =  8.98%; loss = 4.426622  (0.696252 s/it)
Iteration   110: accuracy_at_1 =  4.30%; accuracy_at_5 = 14.06%; loss = 4.418448  (0.696306 s/it)
Iteration   120: accuracy_at_1 =  3.91%; accuracy_at_5 = 17.97%; loss = 4.334749  (0.695921 s/it)
Iteration   130: accuracy_at_1 =  2.34%; accuracy_at_5 = 10.94%; loss = 4.407681  (0.696781 s/it)
Iteration   140: accuracy_at_1 =  3.52%; accuracy_at_5 = 13.67%; loss = 4.282880  (0.697159 s/it)
Iteration   150: accuracy_at_1 =  2.34%; accuracy_at_5 =  8.98%; loss = 4.343795  (0.697421 s/it)
Iteration   160: accuracy_at_1 =  3.12%; accuracy_at_5 = 16.80%; loss = 4.300936  (0.697611 s/it)
Iteration   170: accuracy_at_1 =  5.08%; accuracy_at_5 = 17.58%; loss = 4.201925  (0.697299 s/it)
Iteration   180: accuracy_at_1 =  6.64%; accuracy_at_5 = 18.75%; loss = 4.140050  (0.697727 s/it)
Iteration   190: accuracy_at_1 =  5.86%; accuracy_at_5 = 18.36%; loss = 4.183881  (0.696852 s/it)
Iteration   200: accuracy_at_1 =  5.08%; accuracy_at_5 = 20.31%; loss = 4.135056  (0.695665 s/it)
Iteration   210: accuracy_at_1 =  7.03%; accuracy_at_5 = 21.88%; loss = 4.057692  (0.695979 s/it)
Iteration   220: accuracy_at_1 =  5.86%; accuracy_at_5 = 23.44%; loss = 4.166739  (0.696220 s/it)
Iteration   230: accuracy_at_1 =  6.64%; accuracy_at_5 = 22.27%; loss = 4.111593  (0.695629 s/it)
Iteration   240: accuracy_at_1 =  5.47%; accuracy_at_5 = 17.97%; loss = 4.248483  (0.695872 s/it)
Iteration   250: accuracy_at_1 =  7.81%; accuracy_at_5 = 25.39%; loss = 3.997887  (0.696419 s/it)
Iteration   260: accuracy_at_1 =  5.86%; accuracy_at_5 = 20.70%; loss = 4.154894  (0.696905 s/it)
Iteration   270: accuracy_at_1 =  5.47%; accuracy_at_5 = 24.22%; loss = 4.214264  (0.697212 s/it)
Iteration   280: accuracy_at_1 =  6.64%; accuracy_at_5 = 20.31%; loss = 4.085330  (0.697282 s/it)
Iteration   290: accuracy_at_1 =  7.81%; accuracy_at_5 = 22.27%; loss = 4.062696  (0.697133 s/it)
Iteration   300: accuracy_at_1 =  7.42%; accuracy_at_5 = 27.73%; loss = 3.998638  (0.697831 s/it)
Iteration   310: accuracy_at_1 =  7.42%; accuracy_at_5 = 21.09%; loss = 4.066383  (0.697702 s/it)
Iteration   320: accuracy_at_1 =  7.81%; accuracy_at_5 = 24.61%; loss = 3.963243  (0.696919 s/it)
Iteration   330: accuracy_at_1 =  7.03%; accuracy_at_5 = 26.17%; loss = 3.954987  (0.695775 s/it)
Iteration   340: accuracy_at_1 =  4.30%; accuracy_at_5 = 27.34%; loss = 3.995647  (0.695995 s/it)
Iteration   350: accuracy_at_1 =  7.03%; accuracy_at_5 = 28.52%; loss = 4.022654  (0.695964 s/it)
Iteration   360: accuracy_at_1 =  5.08%; accuracy_at_5 = 22.27%; loss = 4.068072  (0.696009 s/it)
Iteration   370: accuracy_at_1 =  7.81%; accuracy_at_5 = 23.44%; loss = 3.964069  (0.695916 s/it)
Iteration   380: accuracy_at_1 =  7.42%; accuracy_at_5 = 22.66%; loss = 4.088131  (0.696303 s/it)
Iteration   390: accuracy_at_1 = 11.33%; accuracy_at_5 = 31.25%; loss = 3.899275  (0.697941 s/it)
Iteration   400: accuracy_at_1 =  9.38%; accuracy_at_5 = 30.08%; loss = 3.955588  (0.697341 s/it)
Iteration   410: accuracy_at_1 =  8.20%; accuracy_at_5 = 27.73%; loss = 3.944180  (0.697303 s/it)
Iteration   420: accuracy_at_1 =  7.42%; accuracy_at_5 = 26.17%; loss = 3.943220  (0.697196 s/it)
Iteration   430: accuracy_at_1 =  7.42%; accuracy_at_5 = 26.95%; loss = 3.949576  (0.697336 s/it)
Iteration   440: accuracy_at_1 = 11.33%; accuracy_at_5 = 29.30%; loss = 3.905573  (0.697991 s/it)
Iteration   450: accuracy_at_1 =  7.42%; accuracy_at_5 = 29.69%; loss = 3.953887  (0.696517 s/it)
Iteration   460: accuracy_at_1 =  8.20%; accuracy_at_5 = 31.25%; loss = 3.863219  (0.696000 s/it)
Iteration   470: accuracy_at_1 =  8.59%; accuracy_at_5 = 35.16%; loss = 3.763346  (0.696330 s/it)
Iteration   480: accuracy_at_1 = 13.28%; accuracy_at_5 = 36.33%; loss = 3.770756  (0.695803 s/it)
Iteration   490: accuracy_at_1 = 11.33%; accuracy_at_5 = 32.81%; loss = 3.758275  (0.696203 s/it)
Iteration   500: accuracy_at_1 =  8.98%; accuracy_at_5 = 26.95%; loss = 3.982517  (0.695796 s/it)
Iteration   510: accuracy_at_1 =  9.38%; accuracy_at_5 = 27.73%; loss = 3.912499  (0.696044 s/it)
Iteration   520: accuracy_at_1 =  8.98%; accuracy_at_5 = 32.03%; loss = 3.770190  (0.697745 s/it)
Iteration   530: accuracy_at_1 =  8.98%; accuracy_at_5 = 32.42%; loss = 3.870244  (0.697946 s/it)
Iteration   540: accuracy_at_1 = 14.45%; accuracy_at_5 = 34.77%; loss = 3.762962  (0.698055 s/it)
Iteration   550: accuracy_at_1 = 12.50%; accuracy_at_5 = 37.50%; loss = 3.694422  (0.697261 s/it)
Iteration   560: accuracy_at_1 =  8.59%; accuracy_at_5 = 28.12%; loss = 3.836905  (0.696870 s/it)
Iteration   570: accuracy_at_1 = 14.45%; accuracy_at_5 = 33.59%; loss = 3.736467  (0.697410 s/it)
Iteration   580: accuracy_at_1 = 13.28%; accuracy_at_5 = 33.98%; loss = 3.799595  (0.697597 s/it)
Iteration   590: accuracy_at_1 =  9.77%; accuracy_at_5 = 33.59%; loss = 3.900449  (0.695980 s/it)
Iteration   600: accuracy_at_1 =  8.98%; accuracy_at_5 = 28.12%; loss = 3.887158  (0.695827 s/it)
Iteration   610: accuracy_at_1 = 14.45%; accuracy_at_5 = 34.77%; loss = 3.707319  (0.696047 s/it)
Iteration   620: accuracy_at_1 = 10.55%; accuracy_at_5 = 32.81%; loss = 3.743983  (0.696188 s/it)
Iteration   630: accuracy_at_1 = 12.50%; accuracy_at_5 = 30.86%; loss = 3.777612  (0.695851 s/it)
Iteration   640: accuracy_at_1 = 12.11%; accuracy_at_5 = 31.25%; loss = 3.742146  (0.695908 s/it)
Iteration   650: accuracy_at_1 = 12.11%; accuracy_at_5 = 30.47%; loss = 3.732156  (0.696832 s/it)
Iteration   660: accuracy_at_1 =  8.98%; accuracy_at_5 = 34.77%; loss = 3.727257  (0.696955 s/it)
Iteration   670: accuracy_at_1 = 15.62%; accuracy_at_5 = 39.84%; loss = 3.576529  (0.697672 s/it)
Iteration   680: accuracy_at_1 = 10.94%; accuracy_at_5 = 32.81%; loss = 3.761149  (0.697235 s/it)
Iteration   690: accuracy_at_1 = 12.50%; accuracy_at_5 = 36.33%; loss = 3.737587  (0.697223 s/it)
Iteration   700: accuracy_at_1 = 16.80%; accuracy_at_5 = 37.50%; loss = 3.640129  (0.697142 s/it)
Iteration   710: accuracy_at_1 = 15.23%; accuracy_at_5 = 34.38%; loss = 3.648121  (0.696356 s/it)
Iteration   720: accuracy_at_1 = 13.28%; accuracy_at_5 = 30.47%; loss = 3.681991  (0.695948 s/it)
Iteration   730: accuracy_at_1 = 11.33%; accuracy_at_5 = 36.33%; loss = 3.748898  (0.696584 s/it)
Iteration   740: accuracy_at_1 = 11.33%; accuracy_at_5 = 38.28%; loss = 3.690183  (0.696299 s/it)
Iteration   750: accuracy_at_1 = 12.50%; accuracy_at_5 = 35.94%; loss = 3.720331  (0.695721 s/it)
Iteration   760: accuracy_at_1 =  8.59%; accuracy_at_5 = 33.20%; loss = 3.753859  (0.696025 s/it)
Iteration   770: accuracy_at_1 =  8.20%; accuracy_at_5 = 30.86%; loss = 3.910870  (0.696676 s/it)
Iteration   780: accuracy_at_1 =  9.77%; accuracy_at_5 = 32.81%; loss = 3.745558  (0.698294 s/it)
Iteration   790: accuracy_at_1 = 12.50%; accuracy_at_5 = 37.11%; loss = 3.619024  (0.697108 s/it)
Iteration   800: accuracy_at_1 = 13.67%; accuracy_at_5 = 40.23%; loss = 3.461665  (0.698168 s/it)
Iteration   810: accuracy_at_1 = 14.45%; accuracy_at_5 = 39.06%; loss = 3.690651  (0.697303 s/it)
Iteration   820: accuracy_at_1 = 14.06%; accuracy_at_5 = 36.33%; loss = 3.586210  (0.696592 s/it)
Iteration   830: accuracy_at_1 = 15.62%; accuracy_at_5 = 41.02%; loss = 3.625704  (0.697580 s/it)
Iteration   840: accuracy_at_1 = 14.06%; accuracy_at_5 = 43.75%; loss = 3.566637  (0.695797 s/it)
Iteration   850: accuracy_at_1 = 13.28%; accuracy_at_5 = 35.16%; loss = 3.560302  (0.696181 s/it)
Iteration   860: accuracy_at_1 = 11.33%; accuracy_at_5 = 37.11%; loss = 3.718735  (0.696306 s/it)
Iteration   870: accuracy_at_1 = 14.45%; accuracy_at_5 = 34.38%; loss = 3.687014  (0.696824 s/it)
Iteration   880: accuracy_at_1 = 12.89%; accuracy_at_5 = 32.03%; loss = 3.828690  (0.695783 s/it)
Iteration   890: accuracy_at_1 = 13.67%; accuracy_at_5 = 37.89%; loss = 3.598879  (0.696756 s/it)
Iteration   900: accuracy_at_1 = 12.11%; accuracy_at_5 = 33.20%; loss = 3.767635  (0.696824 s/it)
Iteration   910: accuracy_at_1 = 14.45%; accuracy_at_5 = 37.11%; loss = 3.543863  (0.698326 s/it)
Iteration   920: accuracy_at_1 = 14.06%; accuracy_at_5 = 37.50%; loss = 3.660707  (0.855465 s/it)
Iteration   930: accuracy_at_1 = 16.02%; accuracy_at_5 = 35.94%; loss = 3.638494  (1.124355 s/it)
Iteration   940: accuracy_at_1 = 11.33%; accuracy_at_5 = 32.81%; loss = 3.690456  (0.829124 s/it)
Iteration   950: accuracy_at_1 = 12.89%; accuracy_at_5 = 33.59%; loss = 3.874039  (0.697157 s/it)
Iteration   960: accuracy_at_1 = 16.02%; accuracy_at_5 = 39.06%; loss = 3.608770  (0.697303 s/it)
Iteration   970: accuracy_at_1 = 14.45%; accuracy_at_5 = 39.45%; loss = 3.555533  (0.696144 s/it)
Iteration   980: accuracy_at_1 = 16.41%; accuracy_at_5 = 38.28%; loss = 3.569045  (0.695937 s/it)
Iteration   990: accuracy_at_1 = 16.41%; accuracy_at_5 = 39.84%; loss = 3.535859  (0.700160 s/it)
Iteration  1000: accuracy_at_1 = 14.06%; accuracy_at_5 = 40.23%; loss = 3.583427  (1.043387 s/it)
Iteration  1010: accuracy_at_1 = 14.06%; accuracy_at_5 = 39.45%; loss = 3.576774  (1.051851 s/it)
Iteration  1020: accuracy_at_1 = 10.55%; accuracy_at_5 = 39.45%; loss = 3.580170  (1.055228 s/it)
Iteration  1030: accuracy_at_1 = 17.97%; accuracy_at_5 = 44.14%; loss = 3.389332  (1.057065 s/it)
Iteration  1040: accuracy_at_1 = 10.94%; accuracy_at_5 = 39.45%; loss = 3.584703  (1.059940 s/it)
Iteration  1050: accuracy_at_1 = 16.41%; accuracy_at_5 = 41.02%; loss = 3.579869  (1.058083 s/it)
Iteration  1060: accuracy_at_1 = 13.67%; accuracy_at_5 = 34.38%; loss = 3.703234  (1.052080 s/it)
Iteration  1070: accuracy_at_1 = 14.84%; accuracy_at_5 = 37.11%; loss = 3.584627  (1.054778 s/it)
Iteration  1080: accuracy_at_1 = 12.11%; accuracy_at_5 = 37.50%; loss = 3.616339  (1.057005 s/it)
Iteration  1090: accuracy_at_1 = 14.06%; accuracy_at_5 = 32.42%; loss = 3.671221  (1.054827 s/it)
Iteration  1100: accuracy_at_1 = 14.06%; accuracy_at_5 = 37.11%; loss = 3.620419  (1.053039 s/it)
Iteration  1110: accuracy_at_1 = 14.84%; accuracy_at_5 = 42.58%; loss = 3.561386  (1.051626 s/it)
Iteration  1120: accuracy_at_1 = 17.19%; accuracy_at_5 = 40.62%; loss = 3.485190  (1.055004 s/it)
Iteration  1130: accuracy_at_1 =  9.77%; accuracy_at_5 = 30.08%; loss = 3.837024  (1.056142 s/it)
Iteration  1140: accuracy_at_1 = 14.84%; accuracy_at_5 = 37.50%; loss = 3.601315  (1.057981 s/it)
Iteration  1150: accuracy_at_1 = 12.89%; accuracy_at_5 = 38.67%; loss = 3.620883  (1.057690 s/it)
Iteration  1160: accuracy_at_1 = 19.14%; accuracy_at_5 = 43.36%; loss = 3.400702  (1.054611 s/it)
Iteration  1170: accuracy_at_1 = 16.80%; accuracy_at_5 = 42.58%; loss = 3.514397  (1.057770 s/it)
Iteration  1180: accuracy_at_1 = 15.23%; accuracy_at_5 = 42.58%; loss = 3.485257  (1.055293 s/it)
Iteration  1190: accuracy_at_1 = 18.75%; accuracy_at_5 = 42.97%; loss = 3.345933  (1.052617 s/it)
Iteration  1200: accuracy_at_1 = 16.80%; accuracy_at_5 = 44.53%; loss = 3.453975  (1.052969 s/it)
Iteration  1210: accuracy_at_1 = 18.75%; accuracy_at_5 = 44.14%; loss = 3.446417  (1.056441 s/it)
Iteration  1220: accuracy_at_1 = 16.41%; accuracy_at_5 = 43.36%; loss = 3.420759  (1.056920 s/it)
Iteration  1230: accuracy_at_1 = 15.62%; accuracy_at_5 = 46.88%; loss = 3.418940  (1.059736 s/it)
Iteration  1240: accuracy_at_1 = 16.80%; accuracy_at_5 = 45.70%; loss = 3.368734  (1.055415 s/it)
Iteration  1250: accuracy_at_1 = 12.50%; accuracy_at_5 = 39.84%; loss = 3.591080  (1.054878 s/it)
Iteration  1260: accuracy_at_1 = 15.62%; accuracy_at_5 = 38.28%; loss = 3.590977  (1.053319 s/it)
Iteration  1270: accuracy_at_1 = 14.84%; accuracy_at_5 = 42.19%; loss = 3.402328  (1.055490 s/it)
Iteration  1280: accuracy_at_1 = 16.80%; accuracy_at_5 = 43.36%; loss = 3.469393  (1.052236 s/it)
Iteration  1290: accuracy_at_1 = 13.67%; accuracy_at_5 = 36.72%; loss = 3.594769  (1.053110 s/it)
Iteration  1300: accuracy_at_1 = 11.72%; accuracy_at_5 = 35.16%; loss = 3.644592  (1.056493 s/it)
Iteration  1310: accuracy_at_1 = 20.70%; accuracy_at_5 = 42.19%; loss = 3.473471  (1.057550 s/it)
Iteration  1320: accuracy_at_1 =  9.77%; accuracy_at_5 = 39.84%; loss = 3.563877  (1.060895 s/it)
Iteration  1330: accuracy_at_1 = 19.14%; accuracy_at_5 = 50.00%; loss = 3.254285  (1.057906 s/it)
Iteration  1340: accuracy_at_1 = 17.97%; accuracy_at_5 = 44.14%; loss = 3.431181  (1.054920 s/it)
Iteration  1350: accuracy_at_1 = 14.45%; accuracy_at_5 = 42.58%; loss = 3.630904  (1.056525 s/it)
Iteration  1360: accuracy_at_1 = 17.58%; accuracy_at_5 = 41.80%; loss = 3.393886  (1.054618 s/it)
Iteration  1370: accuracy_at_1 = 16.80%; accuracy_at_5 = 42.97%; loss = 3.545133  (1.051968 s/it)
Iteration  1380: accuracy_at_1 = 16.02%; accuracy_at_5 = 44.53%; loss = 3.404952  (0.795813 s/it)
Iteration  1390: accuracy_at_1 = 17.97%; accuracy_at_5 = 44.53%; loss = 3.274172  (0.701286 s/it)
Iteration  1400: accuracy_at_1 = 18.75%; accuracy_at_5 = 42.58%; loss = 3.376335  (0.700692 s/it)
Iteration  1410: accuracy_at_1 = 14.06%; accuracy_at_5 = 44.14%; loss = 3.506901  (0.701645 s/it)
Iteration  1420: accuracy_at_1 = 25.00%; accuracy_at_5 = 50.39%; loss = 3.265473  (0.703553 s/it)
Iteration  1430: accuracy_at_1 = 19.14%; accuracy_at_5 = 46.88%; loss = 3.321965  (0.702073 s/it)
Iteration  1440: accuracy_at_1 = 19.14%; accuracy_at_5 = 48.83%; loss = 3.191549  (0.703337 s/it)
Iteration  1450: accuracy_at_1 = 19.53%; accuracy_at_5 = 50.00%; loss = 3.267584  (0.701815 s/it)
Iteration  1460: accuracy_at_1 = 12.89%; accuracy_at_5 = 42.19%; loss = 3.404320  (0.702022 s/it)
Iteration  1470: accuracy_at_1 = 12.89%; accuracy_at_5 = 43.36%; loss = 3.496009  (0.701750 s/it)
Iteration  1480: accuracy_at_1 = 16.02%; accuracy_at_5 = 41.80%; loss = 3.378924  (0.700676 s/it)
Iteration  1490: accuracy_at_1 = 13.67%; accuracy_at_5 = 41.02%; loss = 3.470960  (0.700612 s/it)
Iteration  1500: accuracy_at_1 = 15.23%; accuracy_at_5 = 37.50%; loss = 3.494472  (0.700750 s/it)
Iteration  1510: accuracy_at_1 = 18.36%; accuracy_at_5 = 47.66%; loss = 3.336547  (0.700911 s/it)
Iteration  1520: accuracy_at_1 = 18.36%; accuracy_at_5 = 44.92%; loss = 3.331022  (0.700630 s/it)
Iteration  1530: accuracy_at_1 = 22.27%; accuracy_at_5 = 42.97%; loss = 3.409832  (0.700382 s/it)
Iteration  1540: accuracy_at_1 = 15.62%; accuracy_at_5 = 37.11%; loss = 3.558886  (0.701842 s/it)
Iteration  1550: accuracy_at_1 = 13.67%; accuracy_at_5 = 36.72%; loss = 3.668171  (0.702007 s/it)
Iteration  1560: accuracy_at_1 = 14.84%; accuracy_at_5 = 40.23%; loss = 3.477710  (0.702691 s/it)
Iteration  1570: accuracy_at_1 = 19.14%; accuracy_at_5 = 42.19%; loss = 3.344348  (0.702324 s/it)
Iteration  1580: accuracy_at_1 = 20.31%; accuracy_at_5 = 48.44%; loss = 3.332678  (0.701209 s/it)
Iteration  1590: accuracy_at_1 = 15.23%; accuracy_at_5 = 41.80%; loss = 3.510781  (0.701878 s/it)
Iteration  1600: accuracy_at_1 = 20.31%; accuracy_at_5 = 44.14%; loss = 3.289303  (0.701993 s/it)
Iteration  1610: accuracy_at_1 = 20.70%; accuracy_at_5 = 51.56%; loss = 3.248596  (0.700737 s/it)
Iteration  1620: accuracy_at_1 = 21.09%; accuracy_at_5 = 48.05%; loss = 3.209310  (0.700562 s/it)
Iteration  1630: accuracy_at_1 = 17.19%; accuracy_at_5 = 44.14%; loss = 3.306271  (0.700276 s/it)
Iteration  1640: accuracy_at_1 = 20.70%; accuracy_at_5 = 46.09%; loss = 3.298404  (0.700977 s/it)
Iteration  1650: accuracy_at_1 = 14.84%; accuracy_at_5 = 39.06%; loss = 3.471249  (0.700545 s/it)
Iteration  1660: accuracy_at_1 = 18.75%; accuracy_at_5 = 48.83%; loss = 3.277197  (0.700588 s/it)
Iteration  1670: accuracy_at_1 = 18.75%; accuracy_at_5 = 46.88%; loss = 3.414313  (0.701791 s/it)
Iteration  1680: accuracy_at_1 = 18.75%; accuracy_at_5 = 42.19%; loss = 3.396300  (0.702964 s/it)
Iteration  1690: accuracy_at_1 = 18.36%; accuracy_at_5 = 47.66%; loss = 3.232309  (0.702972 s/it)
Iteration  1700: accuracy_at_1 = 25.39%; accuracy_at_5 = 54.30%; loss = 3.196742  (0.701601 s/it)
Iteration  1710: accuracy_at_1 = 16.41%; accuracy_at_5 = 42.58%; loss = 3.486701  (0.701564 s/it)
Iteration  1720: accuracy_at_1 = 21.09%; accuracy_at_5 = 46.88%; loss = 3.245917  (0.701273 s/it)
Iteration  1730: accuracy_at_1 = 16.80%; accuracy_at_5 = 44.14%; loss = 3.290897  (0.701174 s/it)
Iteration  1740: accuracy_at_1 = 19.92%; accuracy_at_5 = 46.09%; loss = 3.356010  (0.700272 s/it)
Iteration  1750: accuracy_at_1 = 20.31%; accuracy_at_5 = 49.61%; loss = 3.215668  (0.694512 s/it)
Iteration  1760: accuracy_at_1 = 19.92%; accuracy_at_5 = 48.44%; loss = 3.197701  (0.723217 s/it)
Iteration  1770: accuracy_at_1 = 17.58%; accuracy_at_5 = 46.09%; loss = 3.297376  (0.696384 s/it)
Iteration  1780: accuracy_at_1 = 19.14%; accuracy_at_5 = 51.17%; loss = 3.261993  (0.696539 s/it)
Iteration  1790: accuracy_at_1 = 15.62%; accuracy_at_5 = 41.41%; loss = 3.391319  (0.696541 s/it)
Iteration  1800: accuracy_at_1 = 19.53%; accuracy_at_5 = 47.27%; loss = 3.383300  (0.697469 s/it)
Iteration  1810: accuracy_at_1 = 21.09%; accuracy_at_5 = 46.88%; loss = 3.373917  (0.697479 s/it)
Iteration  1820: accuracy_at_1 = 22.66%; accuracy_at_5 = 50.00%; loss = 3.227521  (0.697160 s/it)
Iteration  1830: accuracy_at_1 = 18.36%; accuracy_at_5 = 46.09%; loss = 3.341150  (0.697644 s/it)
Iteration  1840: accuracy_at_1 = 20.31%; accuracy_at_5 = 49.22%; loss = 3.241788  (0.697946 s/it)
Iteration  1850: accuracy_at_1 = 17.19%; accuracy_at_5 = 42.58%; loss = 3.303555  (0.698000 s/it)
Iteration  1860: accuracy_at_1 = 19.92%; accuracy_at_5 = 42.97%; loss = 3.395373  (0.696939 s/it)
Iteration  1870: accuracy_at_1 = 21.48%; accuracy_at_5 = 53.12%; loss = 3.111688  (0.696347 s/it)
Iteration  1880: accuracy_at_1 = 18.36%; accuracy_at_5 = 50.00%; loss = 3.288026  (0.696321 s/it)
Iteration  1890: accuracy_at_1 = 17.58%; accuracy_at_5 = 46.88%; loss = 3.454806  (0.696651 s/it)
Iteration  1900: accuracy_at_1 = 23.44%; accuracy_at_5 = 50.39%; loss = 3.312722  (0.696433 s/it)
Iteration  1910: accuracy_at_1 = 19.92%; accuracy_at_5 = 46.88%; loss = 3.430607  (0.696256 s/it)
Iteration  1920: accuracy_at_1 = 17.97%; accuracy_at_5 = 42.97%; loss = 3.402232  (0.696549 s/it)
Iteration  1930: accuracy_at_1 = 18.36%; accuracy_at_5 = 42.19%; loss = 3.418756  (0.697323 s/it)
Iteration  1940: accuracy_at_1 = 19.14%; accuracy_at_5 = 46.88%; loss = 3.349486  (0.697316 s/it)
Iteration  1950: accuracy_at_1 = 18.36%; accuracy_at_5 = 45.31%; loss = 3.285918  (0.697668 s/it)
Iteration  1960: accuracy_at_1 = 25.00%; accuracy_at_5 = 48.44%; loss = 3.199852  (0.699137 s/it)
Iteration  1970: accuracy_at_1 = 17.97%; accuracy_at_5 = 44.14%; loss = 3.348819  (0.698001 s/it)
Iteration  1980: accuracy_at_1 = 20.70%; accuracy_at_5 = 46.48%; loss = 3.226235  (0.697429 s/it)
Iteration  1990: accuracy_at_1 = 19.14%; accuracy_at_5 = 48.44%; loss = 3.255461  (0.697709 s/it)
Iteration  2000: accuracy_at_1 = 18.36%; accuracy_at_5 = 46.88%; loss = 3.342613  (0.697411 s/it)
Iteration  2010: accuracy_at_1 = 21.09%; accuracy_at_5 = 46.09%; loss = 3.271916  (0.696505 s/it)
Iteration  2020: accuracy_at_1 = 21.09%; accuracy_at_5 = 50.39%; loss = 3.166202  (0.696859 s/it)
Iteration  2030: accuracy_at_1 = 21.09%; accuracy_at_5 = 49.61%; loss = 3.187915  (0.696297 s/it)
Iteration  2040: accuracy_at_1 = 19.14%; accuracy_at_5 = 48.83%; loss = 3.214325  (0.696154 s/it)
Iteration  2050: accuracy_at_1 = 26.17%; accuracy_at_5 = 55.86%; loss = 3.029219  (0.696851 s/it)
Iteration  2060: accuracy_at_1 = 23.44%; accuracy_at_5 = 51.95%; loss = 3.139415  (0.697233 s/it)
Iteration  2070: accuracy_at_1 = 22.27%; accuracy_at_5 = 52.73%; loss = 3.172130  (0.697433 s/it)
Iteration  2080: accuracy_at_1 = 18.75%; accuracy_at_5 = 48.83%; loss = 3.392060  (0.698488 s/it)
Iteration  2090: accuracy_at_1 = 16.80%; accuracy_at_5 = 46.09%; loss = 3.350860  (0.698032 s/it)
Iteration  2100: accuracy_at_1 = 21.88%; accuracy_at_5 = 46.48%; loss = 3.215433  (0.697596 s/it)
Iteration  2110: accuracy_at_1 = 20.70%; accuracy_at_5 = 52.73%; loss = 3.283021  (0.697788 s/it)
Iteration  2120: accuracy_at_1 = 17.58%; accuracy_at_5 = 46.88%; loss = 3.289343  (0.697144 s/it)
Iteration  2130: accuracy_at_1 = 19.14%; accuracy_at_5 = 45.31%; loss = 3.212787  (0.696238 s/it)
Iteration  2140: accuracy_at_1 = 15.62%; accuracy_at_5 = 42.97%; loss = 3.407499  (0.696694 s/it)
Iteration  2150: accuracy_at_1 = 19.14%; accuracy_at_5 = 50.78%; loss = 3.211534  (0.696459 s/it)
Iteration  2160: accuracy_at_1 = 19.14%; accuracy_at_5 = 43.36%; loss = 3.442958  (0.696337 s/it)
Iteration  2170: accuracy_at_1 = 21.09%; accuracy_at_5 = 44.53%; loss = 3.291571  (0.696304 s/it)
Iteration  2180: accuracy_at_1 = 18.75%; accuracy_at_5 = 50.78%; loss = 3.169735  (0.696793 s/it)
Iteration  2190: accuracy_at_1 = 20.70%; accuracy_at_5 = 48.44%; loss = 3.256178  (0.697373 s/it)
Iteration  2200: accuracy_at_1 = 21.09%; accuracy_at_5 = 48.44%; loss = 3.282485  (0.697857 s/it)
Iteration  2210: accuracy_at_1 = 27.73%; accuracy_at_5 = 52.73%; loss = 3.078526  (0.697573 s/it)
Iteration  2220: accuracy_at_1 = 26.17%; accuracy_at_5 = 55.08%; loss = 3.096695  (0.697835 s/it)
Iteration  2230: accuracy_at_1 = 16.80%; accuracy_at_5 = 38.28%; loss = 3.520134  (0.697758 s/it)
Iteration  2240: accuracy_at_1 = 18.75%; accuracy_at_5 = 44.53%; loss = 3.317941  (0.697018 s/it)
Iteration  2250: accuracy_at_1 = 19.53%; accuracy_at_5 = 43.36%; loss = 3.381320  (0.696120 s/it)
Iteration  2260: accuracy_at_1 = 18.75%; accuracy_at_5 = 45.31%; loss = 3.328179  (0.696754 s/it)
Iteration  2270: accuracy_at_1 = 24.61%; accuracy_at_5 = 51.95%; loss = 3.142039  (0.696684 s/it)
Iteration  2280: accuracy_at_1 = 22.27%; accuracy_at_5 = 48.05%; loss = 3.287066  (0.696068 s/it)
Iteration  2290: accuracy_at_1 = 17.97%; accuracy_at_5 = 42.97%; loss = 3.387450  (0.695813 s/it)
Iteration  2300: accuracy_at_1 = 23.05%; accuracy_at_5 = 53.12%; loss = 3.185292  (0.697120 s/it)
Iteration  2310: accuracy_at_1 = 20.31%; accuracy_at_5 = 45.70%; loss = 3.297816  (0.697504 s/it)
Iteration  2320: accuracy_at_1 = 20.70%; accuracy_at_5 = 46.48%; loss = 3.347892  (0.697298 s/it)
Iteration  2330: accuracy_at_1 = 20.31%; accuracy_at_5 = 45.31%; loss = 3.257493  (0.697396 s/it)
Iteration  2340: accuracy_at_1 = 19.53%; accuracy_at_5 = 44.14%; loss = 3.328661  (0.697528 s/it)
Iteration  2350: accuracy_at_1 = 19.92%; accuracy_at_5 = 47.27%; loss = 3.262165  (0.697923 s/it)
Iteration  2360: accuracy_at_1 = 22.27%; accuracy_at_5 = 48.05%; loss = 3.234539  (0.697424 s/it)
Iteration  2370: accuracy_at_1 = 21.88%; accuracy_at_5 = 51.56%; loss = 3.078154  (0.697443 s/it)
Iteration  2380: accuracy_at_1 = 22.27%; accuracy_at_5 = 49.61%; loss = 3.217322  (0.696287 s/it)
Iteration  2390: accuracy_at_1 = 21.88%; accuracy_at_5 = 42.19%; loss = 3.252468  (0.696029 s/it)
Iteration  2400: accuracy_at_1 = 19.92%; accuracy_at_5 = 43.36%; loss = 3.379374  (0.696493 s/it)
Iteration  2410: accuracy_at_1 = 23.05%; accuracy_at_5 = 51.95%; loss = 2.984602  (0.696546 s/it)
Iteration  2420: accuracy_at_1 = 21.88%; accuracy_at_5 = 52.73%; loss = 3.089306  (0.696587 s/it)
Iteration  2430: accuracy_at_1 = 19.53%; accuracy_at_5 = 49.61%; loss = 3.246610  (0.696286 s/it)
Iteration  2440: accuracy_at_1 = 23.44%; accuracy_at_5 = 50.39%; loss = 3.027387  (0.697445 s/it)
Iteration  2450: accuracy_at_1 = 25.78%; accuracy_at_5 = 50.39%; loss = 3.170754  (0.697241 s/it)
Iteration  2460: accuracy_at_1 = 23.83%; accuracy_at_5 = 54.30%; loss = 2.909822  (0.697956 s/it)
Iteration  2470: accuracy_at_1 = 23.83%; accuracy_at_5 = 50.78%; loss = 3.065236  (0.697459 s/it)
Iteration  2480: accuracy_at_1 = 23.05%; accuracy_at_5 = 51.95%; loss = 3.058642  (0.697285 s/it)
Iteration  2490: accuracy_at_1 = 22.27%; accuracy_at_5 = 44.14%; loss = 3.253349  (0.697422 s/it)
Iteration  2500: accuracy_at_1 = 23.05%; accuracy_at_5 = 50.78%; loss = 3.171734  (0.696513 s/it)
Iteration  2510: accuracy_at_1 = 21.48%; accuracy_at_5 = 51.95%; loss = 3.240861  (0.696290 s/it)
Iteration  2520: accuracy_at_1 = 19.92%; accuracy_at_5 = 48.83%; loss = 3.298810  (0.696548 s/it)
Iteration  2530: accuracy_at_1 = 20.70%; accuracy_at_5 = 48.83%; loss = 3.272439  (0.696431 s/it)
Iteration  2540: accuracy_at_1 = 27.73%; accuracy_at_5 = 51.56%; loss = 2.994632  (0.696548 s/it)
Iteration  2550: accuracy_at_1 = 27.34%; accuracy_at_5 = 56.64%; loss = 3.105975  (0.696776 s/it)
Iteration  2560: accuracy_at_1 = 23.44%; accuracy_at_5 = 53.12%; loss = 2.991302  (0.696982 s/it)
Iteration  2570: accuracy_at_1 = 14.45%; accuracy_at_5 = 44.92%; loss = 3.398242  (0.697297 s/it)
Iteration  2580: accuracy_at_1 = 26.95%; accuracy_at_5 = 55.08%; loss = 2.998304  (0.697558 s/it)
Iteration  2590: accuracy_at_1 = 18.75%; accuracy_at_5 = 47.27%; loss = 3.438408  (0.697849 s/it)
Iteration  2600: accuracy_at_1 = 20.31%; accuracy_at_5 = 45.70%; loss = 3.284565  (0.697838 s/it)
Iteration  2610: accuracy_at_1 = 19.92%; accuracy_at_5 = 53.91%; loss = 3.143764  (0.697555 s/it)
Iteration  2620: accuracy_at_1 = 19.14%; accuracy_at_5 = 44.53%; loss = 3.227895  (0.698230 s/it)
Iteration  2630: accuracy_at_1 = 22.66%; accuracy_at_5 = 51.17%; loss = 3.158449  (0.697766 s/it)
Iteration  2640: accuracy_at_1 = 16.80%; accuracy_at_5 = 46.09%; loss = 3.313212  (0.697087 s/it)
Iteration  2650: accuracy_at_1 = 23.44%; accuracy_at_5 = 54.69%; loss = 3.161076  (0.697278 s/it)
Iteration  2660: accuracy_at_1 = 25.39%; accuracy_at_5 = 54.69%; loss = 3.046988  (0.695950 s/it)
Iteration  2670: accuracy_at_1 = 24.22%; accuracy_at_5 = 51.95%; loss = 3.146666  (0.695993 s/it)
Iteration  2680: accuracy_at_1 = 22.27%; accuracy_at_5 = 50.78%; loss = 3.206388  (0.696472 s/it)
Iteration  2690: accuracy_at_1 = 23.83%; accuracy_at_5 = 51.56%; loss = 3.295756  (0.696686 s/it)
Iteration  2700: accuracy_at_1 = 20.70%; accuracy_at_5 = 53.52%; loss = 3.197145  (0.697871 s/it)
Iteration  2710: accuracy_at_1 = 23.44%; accuracy_at_5 = 48.83%; loss = 3.227939  (0.697156 s/it)
Iteration  2720: accuracy_at_1 = 23.83%; accuracy_at_5 = 53.12%; loss = 3.162127  (0.697212 s/it)
Iteration  2730: accuracy_at_1 = 21.48%; accuracy_at_5 = 47.27%; loss = 3.296591  (0.698145 s/it)
Iteration  2740: accuracy_at_1 = 24.61%; accuracy_at_5 = 50.00%; loss = 3.046351  (0.699094 s/it)
Iteration  2750: accuracy_at_1 = 22.66%; accuracy_at_5 = 53.91%; loss = 3.059136  (0.697989 s/it)
Iteration  2760: accuracy_at_1 = 25.00%; accuracy_at_5 = 55.86%; loss = 3.032359  (0.696479 s/it)
Iteration  2770: accuracy_at_1 = 26.56%; accuracy_at_5 = 55.47%; loss = 2.955086  (0.696006 s/it)
Iteration  2780: accuracy_at_1 = 26.17%; accuracy_at_5 = 51.95%; loss = 3.046614  (0.696284 s/it)
Iteration  2790: accuracy_at_1 = 30.86%; accuracy_at_5 = 61.33%; loss = 2.810235  (0.695912 s/it)
Iteration  2800: accuracy_at_1 = 23.83%; accuracy_at_5 = 57.81%; loss = 3.075757  (0.696292 s/it)
Iteration  2810: accuracy_at_1 = 21.48%; accuracy_at_5 = 54.30%; loss = 3.013124  (0.695737 s/it)
Iteration  2820: accuracy_at_1 = 27.34%; accuracy_at_5 = 53.52%; loss = 3.027813  (0.696872 s/it)
Iteration  2830: accuracy_at_1 = 23.83%; accuracy_at_5 = 54.30%; loss = 2.958754  (0.697870 s/it)
Iteration  2840: accuracy_at_1 = 25.00%; accuracy_at_5 = 53.52%; loss = 2.992407  (0.697164 s/it)
Iteration  2850: accuracy_at_1 = 23.83%; accuracy_at_5 = 53.52%; loss = 3.042121  (0.697472 s/it)
Iteration  2860: accuracy_at_1 = 25.39%; accuracy_at_5 = 56.64%; loss = 3.063341  (0.697581 s/it)
Iteration  2870: accuracy_at_1 = 23.44%; accuracy_at_5 = 56.25%; loss = 3.046427  (0.697287 s/it)
Iteration  2880: accuracy_at_1 = 25.39%; accuracy_at_5 = 52.73%; loss = 3.029257  (0.697624 s/it)
Iteration  2890: accuracy_at_1 = 20.70%; accuracy_at_5 = 54.30%; loss = 3.143319  (0.696428 s/it)
Iteration  2900: accuracy_at_1 = 24.61%; accuracy_at_5 = 52.34%; loss = 2.975626  (0.695405 s/it)
Iteration  2910: accuracy_at_1 = 21.09%; accuracy_at_5 = 47.66%; loss = 3.297389  (0.696061 s/it)
Iteration  2920: accuracy_at_1 = 24.22%; accuracy_at_5 = 51.17%; loss = 3.108974  (0.696336 s/it)
Iteration  2930: accuracy_at_1 = 21.88%; accuracy_at_5 = 50.78%; loss = 3.082719  (0.695893 s/it)
Iteration  2940: accuracy_at_1 = 22.66%; accuracy_at_5 = 54.69%; loss = 3.027301  (0.696395 s/it)
Iteration  2950: accuracy_at_1 = 25.00%; accuracy_at_5 = 52.34%; loss = 3.125138  (0.698003 s/it)
Iteration  2960: accuracy_at_1 = 23.44%; accuracy_at_5 = 47.66%; loss = 3.222488  (0.698176 s/it)
Iteration  2970: accuracy_at_1 = 26.17%; accuracy_at_5 = 55.08%; loss = 3.007209  (0.697543 s/it)
Iteration  2980: accuracy_at_1 = 21.48%; accuracy_at_5 = 50.78%; loss = 3.084337  (0.697169 s/it)
Iteration  2990: accuracy_at_1 = 21.48%; accuracy_at_5 = 48.44%; loss = 3.283352  (0.697392 s/it)
Iteration  3000: accuracy_at_1 = 25.39%; accuracy_at_5 = 49.22%; loss = 3.164325  (0.696983 s/it)
Iteration  3010: accuracy_at_1 = 24.61%; accuracy_at_5 = 51.56%; loss = 3.208311  (0.697329 s/it)
Iteration  3020: accuracy_at_1 = 20.70%; accuracy_at_5 = 48.05%; loss = 3.225503  (0.696289 s/it)
Iteration  3030: accuracy_at_1 = 22.27%; accuracy_at_5 = 51.56%; loss = 3.183515  (0.696206 s/it)
Iteration  3040: accuracy_at_1 = 25.78%; accuracy_at_5 = 52.34%; loss = 3.036982  (0.695899 s/it)
Iteration  3050: accuracy_at_1 = 24.61%; accuracy_at_5 = 55.86%; loss = 3.047573  (0.696212 s/it)
Iteration  3060: accuracy_at_1 = 27.73%; accuracy_at_5 = 55.47%; loss = 2.943348  (0.696262 s/it)
Iteration  3070: accuracy_at_1 = 17.97%; accuracy_at_5 = 44.92%; loss = 3.282687  (0.696625 s/it)
Iteration  3080: accuracy_at_1 = 21.09%; accuracy_at_5 = 47.66%; loss = 3.153004  (0.696957 s/it)
Iteration  3090: accuracy_at_1 = 19.53%; accuracy_at_5 = 43.36%; loss = 3.455453  (0.697689 s/it)
Iteration  3100: accuracy_at_1 = 26.56%; accuracy_at_5 = 53.12%; loss = 3.069551  (0.697564 s/it)
Iteration  3110: accuracy_at_1 = 24.22%; accuracy_at_5 = 57.42%; loss = 2.957112  (0.698266 s/it)
Iteration  3120: accuracy_at_1 = 19.92%; accuracy_at_5 = 51.56%; loss = 3.235309  (0.697856 s/it)
Iteration  3130: accuracy_at_1 = 25.39%; accuracy_at_5 = 57.81%; loss = 2.937407  (0.698448 s/it)
Iteration  3140: accuracy_at_1 = 25.39%; accuracy_at_5 = 53.91%; loss = 3.051508  (0.696336 s/it)
Iteration  3150: accuracy_at_1 = 26.95%; accuracy_at_5 = 56.64%; loss = 2.886932  (0.696025 s/it)
Iteration  3160: accuracy_at_1 = 22.66%; accuracy_at_5 = 52.34%; loss = 3.104212  (0.695563 s/it)
Iteration  3170: accuracy_at_1 = 23.83%; accuracy_at_5 = 53.91%; loss = 3.024231  (0.696658 s/it)
Iteration  3180: accuracy_at_1 = 25.00%; accuracy_at_5 = 52.73%; loss = 3.143522  (0.695940 s/it)
Iteration  3190: accuracy_at_1 = 25.00%; accuracy_at_5 = 52.73%; loss = 3.147471  (0.696205 s/it)
Iteration  3200: accuracy_at_1 = 26.56%; accuracy_at_5 = 53.91%; loss = 2.979755  (0.696663 s/it)
Iteration  3210: accuracy_at_1 = 25.00%; accuracy_at_5 = 53.12%; loss = 3.018203  (0.697728 s/it)
Iteration  3220: accuracy_at_1 = 26.56%; accuracy_at_5 = 55.86%; loss = 2.963886  (0.697091 s/it)
Iteration  3230: accuracy_at_1 = 27.34%; accuracy_at_5 = 55.47%; loss = 2.892371  (0.697233 s/it)
Iteration  3240: accuracy_at_1 = 30.08%; accuracy_at_5 = 59.77%; loss = 2.836422  (0.697219 s/it)
Iteration  3250: accuracy_at_1 = 23.05%; accuracy_at_5 = 53.91%; loss = 3.060203  (0.697142 s/it)
Iteration  3260: accuracy_at_1 = 22.66%; accuracy_at_5 = 55.08%; loss = 2.941761  (0.697372 s/it)
Iteration  3270: accuracy_at_1 = 21.09%; accuracy_at_5 = 56.25%; loss = 3.059250  (0.696526 s/it)
Iteration  3280: accuracy_at_1 = 28.91%; accuracy_at_5 = 55.47%; loss = 2.962824  (0.696563 s/it)
Iteration  3290: accuracy_at_1 = 21.09%; accuracy_at_5 = 51.17%; loss = 3.131730  (0.696450 s/it)
Iteration  3300: accuracy_at_1 = 24.61%; accuracy_at_5 = 55.47%; loss = 3.036145  (0.695739 s/it)
Iteration  3310: accuracy_at_1 = 18.75%; accuracy_at_5 = 51.56%; loss = 3.117375  (0.695916 s/it)
Iteration  3320: accuracy_at_1 = 26.17%; accuracy_at_5 = 50.39%; loss = 3.022757  (0.696350 s/it)
Iteration  3330: accuracy_at_1 = 28.52%; accuracy_at_5 = 53.52%; loss = 2.930386  (0.696133 s/it)
Iteration  3340: accuracy_at_1 = 19.53%; accuracy_at_5 = 45.31%; loss = 3.239705  (0.697430 s/it)
Iteration  3350: accuracy_at_1 = 23.44%; accuracy_at_5 = 51.17%; loss = 3.061355  (0.697396 s/it)
Iteration  3360: accuracy_at_1 = 23.05%; accuracy_at_5 = 55.86%; loss = 3.059984  (0.696933 s/it)
Iteration  3370: accuracy_at_1 = 24.22%; accuracy_at_5 = 51.95%; loss = 3.094065  (0.698092 s/it)
Iteration  3380: accuracy_at_1 = 26.17%; accuracy_at_5 = 55.86%; loss = 3.037455  (0.697500 s/it)
Iteration  3390: accuracy_at_1 = 28.12%; accuracy_at_5 = 56.25%; loss = 2.911634  (0.697603 s/it)
Iteration  3400: accuracy_at_1 = 26.56%; accuracy_at_5 = 55.47%; loss = 2.961214  (0.696160 s/it)
Iteration  3410: accuracy_at_1 = 26.17%; accuracy_at_5 = 57.81%; loss = 2.954320  (0.696284 s/it)
Iteration  3420: accuracy_at_1 = 23.83%; accuracy_at_5 = 53.91%; loss = 3.109864  (0.696177 s/it)
Iteration  3430: accuracy_at_1 = 21.48%; accuracy_at_5 = 57.03%; loss = 3.073708  (0.696142 s/it)
Iteration  3440: accuracy_at_1 = 21.09%; accuracy_at_5 = 46.09%; loss = 3.251276  (0.696307 s/it)
Iteration  3450: accuracy_at_1 = 24.22%; accuracy_at_5 = 55.47%; loss = 3.002749  (0.696385 s/it)
Iteration  3460: accuracy_at_1 = 28.52%; accuracy_at_5 = 52.73%; loss = 3.029187  (0.696547 s/it)
Iteration  3470: accuracy_at_1 = 24.61%; accuracy_at_5 = 53.52%; loss = 3.005636  (0.697427 s/it)
Iteration  3480: accuracy_at_1 = 22.27%; accuracy_at_5 = 52.73%; loss = 3.072977  (0.697208 s/it)
Iteration  3490: accuracy_at_1 = 22.27%; accuracy_at_5 = 53.52%; loss = 3.071200  (0.697287 s/it)
Iteration  3500: accuracy_at_1 = 25.78%; accuracy_at_5 = 54.30%; loss = 2.986602  (0.697430 s/it)
Iteration  3510: accuracy_at_1 = 27.73%; accuracy_at_5 = 55.08%; loss = 2.950560  (0.697337 s/it)
Iteration  3520: accuracy_at_1 = 26.56%; accuracy_at_5 = 57.03%; loss = 2.996251  (0.698913 s/it)
Iteration  3530: accuracy_at_1 = 28.12%; accuracy_at_5 = 58.59%; loss = 2.849828  (0.696288 s/it)
Iteration  3540: accuracy_at_1 = 25.78%; accuracy_at_5 = 55.08%; loss = 2.935812  (0.696020 s/it)
Iteration  3550: accuracy_at_1 = 25.78%; accuracy_at_5 = 55.86%; loss = 2.964293  (0.696228 s/it)
Iteration  3560: accuracy_at_1 = 26.56%; accuracy_at_5 = 56.64%; loss = 2.931010  (0.696415 s/it)
Iteration  3570: accuracy_at_1 = 28.91%; accuracy_at_5 = 57.42%; loss = 2.880088  (0.696083 s/it)
Iteration  3580: accuracy_at_1 = 25.78%; accuracy_at_5 = 59.38%; loss = 2.823102  (0.696090 s/it)
Iteration  3590: accuracy_at_1 = 26.17%; accuracy_at_5 = 58.20%; loss = 2.722281  (0.697407 s/it)
Iteration  3600: accuracy_at_1 = 21.88%; accuracy_at_5 = 55.86%; loss = 2.925342  (0.697170 s/it)
Iteration  3610: accuracy_at_1 = 26.95%; accuracy_at_5 = 58.59%; loss = 2.786960  (0.697221 s/it)
Iteration  3620: accuracy_at_1 = 26.56%; accuracy_at_5 = 53.12%; loss = 3.026872  (0.697395 s/it)
Iteration  3630: accuracy_at_1 = 26.17%; accuracy_at_5 = 55.08%; loss = 2.934965  (0.697262 s/it)
Iteration  3640: accuracy_at_1 = 26.95%; accuracy_at_5 = 51.56%; loss = 3.038152  (0.697630 s/it)
Iteration  3650: accuracy_at_1 = 29.30%; accuracy_at_5 = 56.25%; loss = 2.898690  (0.697695 s/it)
Iteration  3660: accuracy_at_1 = 27.73%; accuracy_at_5 = 53.12%; loss = 2.960348  (0.696255 s/it)
Iteration  3670: accuracy_at_1 = 25.78%; accuracy_at_5 = 57.42%; loss = 2.829759  (0.697908 s/it)
Iteration  3680: accuracy_at_1 = 26.17%; accuracy_at_5 = 55.47%; loss = 2.968522  (0.697223 s/it)
Iteration  3690: accuracy_at_1 = 20.70%; accuracy_at_5 = 55.86%; loss = 3.060179  (0.695959 s/it)
Iteration  3700: accuracy_at_1 = 28.12%; accuracy_at_5 = 51.17%; loss = 2.987719  (0.696768 s/it)
Iteration  3710: accuracy_at_1 = 27.34%; accuracy_at_5 = 55.86%; loss = 2.964447  (0.696768 s/it)
Iteration  3720: accuracy_at_1 = 25.39%; accuracy_at_5 = 53.52%; loss = 3.135701  (0.698061 s/it)
Iteration  3730: accuracy_at_1 = 28.52%; accuracy_at_5 = 62.11%; loss = 2.927337  (0.698814 s/it)
Iteration  3740: accuracy_at_1 = 26.95%; accuracy_at_5 = 57.03%; loss = 2.895642  (0.697489 s/it)
Iteration  3750: accuracy_at_1 = 29.30%; accuracy_at_5 = 61.33%; loss = 2.745617  (0.697170 s/it)
Iteration  3760: accuracy_at_1 = 26.56%; accuracy_at_5 = 60.55%; loss = 2.854070  (0.698102 s/it)
Iteration  3770: accuracy_at_1 = 16.41%; accuracy_at_5 = 50.39%; loss = 3.156109  (0.698070 s/it)
Iteration  3780: accuracy_at_1 = 22.27%; accuracy_at_5 = 51.56%; loss = 3.036543  (0.696413 s/it)
Iteration  3790: accuracy_at_1 = 23.83%; accuracy_at_5 = 55.47%; loss = 3.121275  (0.696260 s/it)
Iteration  3800: accuracy_at_1 = 23.05%; accuracy_at_5 = 51.17%; loss = 3.033577  (0.696044 s/it)
Iteration  3810: accuracy_at_1 = 24.22%; accuracy_at_5 = 56.64%; loss = 2.965343  (0.696092 s/it)
Iteration  3820: accuracy_at_1 = 25.78%; accuracy_at_5 = 58.98%; loss = 3.016299  (0.695829 s/it)
Iteration  3830: accuracy_at_1 = 26.56%; accuracy_at_5 = 57.81%; loss = 2.859445  (0.696785 s/it)
Iteration  3840: accuracy_at_1 = 25.00%; accuracy_at_5 = 52.34%; loss = 3.091822  (0.696333 s/it)
Iteration  3850: accuracy_at_1 = 23.83%; accuracy_at_5 = 53.52%; loss = 3.039423  (0.697706 s/it)
Iteration  3860: accuracy_at_1 = 27.73%; accuracy_at_5 = 60.55%; loss = 2.704949  (0.698120 s/it)
Iteration  3870: accuracy_at_1 = 25.78%; accuracy_at_5 = 52.34%; loss = 2.875582  (0.698999 s/it)
Iteration  3880: accuracy_at_1 = 29.30%; accuracy_at_5 = 58.20%; loss = 2.816113  (0.697458 s/it)
Iteration  3890: accuracy_at_1 = 21.88%; accuracy_at_5 = 52.73%; loss = 3.071712  (0.697001 s/it)
Iteration  3900: accuracy_at_1 = 26.17%; accuracy_at_5 = 52.34%; loss = 3.003284  (0.697546 s/it)
Iteration  3910: accuracy_at_1 = 23.83%; accuracy_at_5 = 53.52%; loss = 2.926672  (0.697634 s/it)
Iteration  3920: accuracy_at_1 = 28.12%; accuracy_at_5 = 58.20%; loss = 2.811742  (0.696059 s/it)
Iteration  3930: accuracy_at_1 = 31.64%; accuracy_at_5 = 60.55%; loss = 2.719670  (0.696477 s/it)
Iteration  3940: accuracy_at_1 = 26.56%; accuracy_at_5 = 62.50%; loss = 2.843814  (0.696336 s/it)
Iteration  3950: accuracy_at_1 = 28.91%; accuracy_at_5 = 65.23%; loss = 2.791688  (0.695936 s/it)
Iteration  3960: accuracy_at_1 = 23.83%; accuracy_at_5 = 53.12%; loss = 2.975296  (0.696199 s/it)
Iteration  3970: accuracy_at_1 = 22.27%; accuracy_at_5 = 57.03%; loss = 2.951584  (0.696773 s/it)
Iteration  3980: accuracy_at_1 = 26.95%; accuracy_at_5 = 59.77%; loss = 2.762537  (0.697786 s/it)
Iteration  3990: accuracy_at_1 = 27.34%; accuracy_at_5 = 57.81%; loss = 2.911006  (0.698157 s/it)
Iteration  4000: accuracy_at_1 = 29.30%; accuracy_at_5 = 60.94%; loss = 2.856256  (0.698483 s/it)
Iteration  4010: accuracy_at_1 = 28.12%; accuracy_at_5 = 57.03%; loss = 2.893267  (0.697648 s/it)
Iteration  4020: accuracy_at_1 = 25.78%; accuracy_at_5 = 53.91%; loss = 2.891059  (0.697341 s/it)
Iteration  4030: accuracy_at_1 = 21.09%; accuracy_at_5 = 54.69%; loss = 3.107297  (0.697499 s/it)
Iteration  4040: accuracy_at_1 = 25.39%; accuracy_at_5 = 57.81%; loss = 2.873079  (0.696422 s/it)
Iteration  4050: accuracy_at_1 = 29.30%; accuracy_at_5 = 58.59%; loss = 2.787975  (0.696599 s/it)
Iteration  4060: accuracy_at_1 = 29.69%; accuracy_at_5 = 53.52%; loss = 2.823503  (0.696566 s/it)
Iteration  4070: accuracy_at_1 = 30.47%; accuracy_at_5 = 60.55%; loss = 2.737503  (0.695863 s/it)
Iteration  4080: accuracy_at_1 = 32.42%; accuracy_at_5 = 58.59%; loss = 2.802763  (0.696192 s/it)
Iteration  4090: accuracy_at_1 = 28.91%; accuracy_at_5 = 59.38%; loss = 2.886343  (0.696412 s/it)
Iteration  4100: accuracy_at_1 = 27.73%; accuracy_at_5 = 56.64%; loss = 2.920024  (0.697150 s/it)
Iteration  4110: accuracy_at_1 = 31.25%; accuracy_at_5 = 60.16%; loss = 2.705619  (0.698293 s/it)
Iteration  4120: accuracy_at_1 = 23.44%; accuracy_at_5 = 55.86%; loss = 2.838082  (0.697424 s/it)
Iteration  4130: accuracy_at_1 = 25.39%; accuracy_at_5 = 56.25%; loss = 2.859136  (0.697176 s/it)
Iteration  4140: accuracy_at_1 = 28.52%; accuracy_at_5 = 57.81%; loss = 2.865463  (0.697957 s/it)
Iteration  4150: accuracy_at_1 = 23.44%; accuracy_at_5 = 56.64%; loss = 3.040913  (0.697130 s/it)
Iteration  4160: accuracy_at_1 = 30.08%; accuracy_at_5 = 55.08%; loss = 2.983073  (0.697534 s/it)
Iteration  4170: accuracy_at_1 = 24.22%; accuracy_at_5 = 56.25%; loss = 2.890935  (0.696412 s/it)
Iteration  4180: accuracy_at_1 = 28.52%; accuracy_at_5 = 53.52%; loss = 2.915861  (0.696072 s/it)
Iteration  4190: accuracy_at_1 = 32.81%; accuracy_at_5 = 60.55%; loss = 2.688978  (0.696318 s/it)
Iteration  4200: accuracy_at_1 = 28.91%; accuracy_at_5 = 60.94%; loss = 2.781088  (0.696253 s/it)
Iteration  4210: accuracy_at_1 = 24.22%; accuracy_at_5 = 53.12%; loss = 3.031065  (0.696333 s/it)
Iteration  4220: accuracy_at_1 = 24.61%; accuracy_at_5 = 57.81%; loss = 2.981227  (0.696794 s/it)
Iteration  4230: accuracy_at_1 = 30.08%; accuracy_at_5 = 57.81%; loss = 2.757673  (0.698810 s/it)
Iteration  4240: accuracy_at_1 = 25.00%; accuracy_at_5 = 55.86%; loss = 2.987632  (0.697188 s/it)
Iteration  4250: accuracy_at_1 = 25.39%; accuracy_at_5 = 61.33%; loss = 2.814828  (0.697399 s/it)
Iteration  4260: accuracy_at_1 = 28.12%; accuracy_at_5 = 57.03%; loss = 2.858993  (0.697756 s/it)
Iteration  4270: accuracy_at_1 = 33.59%; accuracy_at_5 = 60.94%; loss = 2.629646  (0.696858 s/it)
Iteration  4280: accuracy_at_1 = 30.08%; accuracy_at_5 = 57.42%; loss = 2.951221  (0.700540 s/it)
Iteration  4290: accuracy_at_1 = 20.70%; accuracy_at_5 = 52.34%; loss = 3.111366  (0.697303 s/it)
Iteration  4300: accuracy_at_1 = 29.69%; accuracy_at_5 = 58.98%; loss = 2.740813  (0.697140 s/it)
Iteration  4310: accuracy_at_1 = 30.08%; accuracy_at_5 = 62.89%; loss = 2.562043  (0.696402 s/it)
Iteration  4320: accuracy_at_1 = 34.77%; accuracy_at_5 = 62.50%; loss = 2.701466  (0.696183 s/it)
Iteration  4330: accuracy_at_1 = 28.52%; accuracy_at_5 = 54.30%; loss = 2.836735  (0.696516 s/it)
Iteration  4340: accuracy_at_1 = 29.30%; accuracy_at_5 = 58.59%; loss = 2.849547  (0.695715 s/it)
Iteration  4350: accuracy_at_1 = 27.73%; accuracy_at_5 = 55.08%; loss = 2.936551  (0.696071 s/it)
Iteration  4360: accuracy_at_1 = 31.64%; accuracy_at_5 = 60.16%; loss = 2.707196  (0.697143 s/it)
Iteration  4370: accuracy_at_1 = 28.91%; accuracy_at_5 = 58.98%; loss = 2.734709  (0.697703 s/it)
Iteration  4380: accuracy_at_1 = 33.20%; accuracy_at_5 = 56.25%; loss = 2.699215  (0.698716 s/it)
Iteration  4390: accuracy_at_1 = 26.95%; accuracy_at_5 = 57.03%; loss = 2.878895  (0.698769 s/it)
Iteration  4400: accuracy_at_1 = 30.47%; accuracy_at_5 = 61.33%; loss = 2.683983  (0.698977 s/it)
Iteration  4410: accuracy_at_1 = 27.34%; accuracy_at_5 = 58.20%; loss = 2.908679  (0.698619 s/it)
Iteration  4420: accuracy_at_1 = 29.30%; accuracy_at_5 = 58.20%; loss = 2.781412  (0.696879 s/it)
Iteration  4430: accuracy_at_1 = 27.73%; accuracy_at_5 = 58.20%; loss = 2.850902  (0.696389 s/it)
Iteration  4440: accuracy_at_1 = 30.86%; accuracy_at_5 = 53.52%; loss = 2.762058  (0.696109 s/it)
Iteration  4450: accuracy_at_1 = 29.69%; accuracy_at_5 = 60.55%; loss = 2.702054  (0.696055 s/it)
Iteration  4460: accuracy_at_1 = 28.91%; accuracy_at_5 = 58.98%; loss = 2.786919  (0.695643 s/it)
Iteration  4470: accuracy_at_1 = 24.61%; accuracy_at_5 = 57.03%; loss = 2.903533  (0.697188 s/it)
Iteration  4480: accuracy_at_1 = 27.73%; accuracy_at_5 = 60.55%; loss = 2.768916  (0.697243 s/it)
Iteration  4490: accuracy_at_1 = 27.73%; accuracy_at_5 = 60.94%; loss = 2.719029  (0.698882 s/it)
Iteration  4500: accuracy_at_1 = 25.39%; accuracy_at_5 = 57.42%; loss = 2.862792  (0.699777 s/it)
Iteration  4510: accuracy_at_1 = 30.47%; accuracy_at_5 = 60.94%; loss = 2.713079  (0.698107 s/it)
Iteration  4520: accuracy_at_1 = 32.03%; accuracy_at_5 = 60.55%; loss = 2.742417  (0.697398 s/it)
Iteration  4530: accuracy_at_1 = 30.86%; accuracy_at_5 = 56.64%; loss = 2.863685  (0.697725 s/it)
Iteration  4540: accuracy_at_1 = 28.91%; accuracy_at_5 = 60.94%; loss = 2.750260  (0.697316 s/it)
Iteration  4550: accuracy_at_1 = 36.33%; accuracy_at_5 = 65.23%; loss = 2.583322  (0.696982 s/it)
Iteration  4560: accuracy_at_1 = 28.12%; accuracy_at_5 = 59.38%; loss = 2.865144  (0.696035 s/it)
Iteration  4570: accuracy_at_1 = 28.91%; accuracy_at_5 = 57.81%; loss = 2.914152  (0.696296 s/it)
Iteration  4580: accuracy_at_1 = 31.25%; accuracy_at_5 = 60.16%; loss = 2.813809  (0.696406 s/it)
Iteration  4590: accuracy_at_1 = 29.30%; accuracy_at_5 = 58.20%; loss = 2.858839  (0.696776 s/it)
Iteration  4600: accuracy_at_1 = 27.73%; accuracy_at_5 = 57.42%; loss = 2.895822  (0.696320 s/it)
Iteration  4610: accuracy_at_1 = 24.22%; accuracy_at_5 = 55.86%; loss = 2.908102  (0.697635 s/it)
Iteration  4620: accuracy_at_1 = 28.91%; accuracy_at_5 = 57.81%; loss = 2.890738  (0.697590 s/it)
Iteration  4630: accuracy_at_1 = 28.12%; accuracy_at_5 = 59.38%; loss = 2.882873  (0.697449 s/it)
Iteration  4640: accuracy_at_1 = 32.03%; accuracy_at_5 = 61.33%; loss = 2.693190  (0.697111 s/it)
Iteration  4650: accuracy_at_1 = 22.27%; accuracy_at_5 = 57.42%; loss = 2.948086  (0.697592 s/it)
Iteration  4660: accuracy_at_1 = 29.30%; accuracy_at_5 = 51.95%; loss = 2.910426  (0.697483 s/it)
Iteration  4670: accuracy_at_1 = 27.73%; accuracy_at_5 = 55.86%; loss = 2.984477  (0.697671 s/it)
Iteration  4680: accuracy_at_1 = 27.34%; accuracy_at_5 = 62.50%; loss = 2.734476  (0.696783 s/it)
Iteration  4690: accuracy_at_1 = 37.11%; accuracy_at_5 = 63.67%; loss = 2.495424  (0.696916 s/it)
Iteration  4700: accuracy_at_1 = 36.33%; accuracy_at_5 = 69.14%; loss = 2.424466  (0.695980 s/it)
Iteration  4710: accuracy_at_1 = 26.95%; accuracy_at_5 = 59.77%; loss = 2.799470  (0.696350 s/it)
Iteration  4720: accuracy_at_1 = 32.81%; accuracy_at_5 = 57.03%; loss = 2.673443  (0.696663 s/it)
Iteration  4730: accuracy_at_1 = 30.47%; accuracy_at_5 = 58.59%; loss = 2.808564  (0.695907 s/it)
Iteration  4740: accuracy_at_1 = 30.86%; accuracy_at_5 = 56.25%; loss = 2.933810  (0.696639 s/it)
Iteration  4750: accuracy_at_1 = 30.47%; accuracy_at_5 = 61.33%; loss = 2.699010  (0.697192 s/it)
Iteration  4760: accuracy_at_1 = 30.47%; accuracy_at_5 = 64.06%; loss = 2.645343  (0.697546 s/it)
Iteration  4770: accuracy_at_1 = 28.91%; accuracy_at_5 = 60.16%; loss = 2.848591  (0.698027 s/it)
Iteration  4780: accuracy_at_1 = 30.08%; accuracy_at_5 = 64.06%; loss = 2.713055  (0.697654 s/it)
Iteration  4790: accuracy_at_1 = 27.73%; accuracy_at_5 = 58.20%; loss = 2.867137  (0.698771 s/it)
Iteration  4800: accuracy_at_1 = 32.42%; accuracy_at_5 = 62.50%; loss = 2.712272  (0.697795 s/it)
Iteration  4810: accuracy_at_1 = 33.98%; accuracy_at_5 = 62.89%; loss = 2.616948  (0.697133 s/it)
Iteration  4820: accuracy_at_1 = 30.08%; accuracy_at_5 = 63.67%; loss = 2.697445  (0.696298 s/it)
Iteration  4830: accuracy_at_1 = 31.64%; accuracy_at_5 = 61.33%; loss = 2.608373  (0.696674 s/it)
Iteration  4840: accuracy_at_1 = 27.34%; accuracy_at_5 = 54.30%; loss = 2.948350  (0.696205 s/it)
Iteration  4850: accuracy_at_1 = 26.56%; accuracy_at_5 = 60.16%; loss = 2.749599  (0.696297 s/it)
Iteration  4860: accuracy_at_1 = 26.17%; accuracy_at_5 = 57.03%; loss = 2.920276  (0.696386 s/it)
Iteration  4870: accuracy_at_1 = 29.30%; accuracy_at_5 = 58.98%; loss = 2.795135  (0.697466 s/it)
Iteration  4880: accuracy_at_1 = 31.64%; accuracy_at_5 = 60.94%; loss = 2.706343  (0.697775 s/it)
Iteration  4890: accuracy_at_1 = 28.91%; accuracy_at_5 = 59.77%; loss = 2.734403  (0.697397 s/it)
Iteration  4900: accuracy_at_1 = 27.73%; accuracy_at_5 = 58.59%; loss = 2.784514  (0.697743 s/it)
Iteration  4910: accuracy_at_1 = 29.30%; accuracy_at_5 = 60.16%; loss = 2.714926  (0.697487 s/it)
Iteration  4920: accuracy_at_1 = 29.69%; accuracy_at_5 = 58.98%; loss = 2.808102  (0.697316 s/it)
Iteration  4930: accuracy_at_1 = 32.03%; accuracy_at_5 = 59.77%; loss = 2.817510  (0.696758 s/it)
Iteration  4940: accuracy_at_1 = 30.86%; accuracy_at_5 = 59.38%; loss = 2.795969  (0.696845 s/it)
Iteration  4950: accuracy_at_1 = 26.56%; accuracy_at_5 = 55.47%; loss = 2.930645  (0.696241 s/it)
Iteration  4960: accuracy_at_1 = 33.98%; accuracy_at_5 = 66.41%; loss = 2.574578  (0.696261 s/it)
Iteration  4970: accuracy_at_1 = 32.81%; accuracy_at_5 = 59.38%; loss = 2.683161  (0.696765 s/it)
Iteration  4980: accuracy_at_1 = 32.81%; accuracy_at_5 = 58.20%; loss = 2.869396  (0.696012 s/it)
Iteration  4990: accuracy_at_1 = 31.64%; accuracy_at_5 = 56.64%; loss = 2.847095  (0.696368 s/it)
Iteration  5000: accuracy_at_1 = 26.56%; accuracy_at_5 = 62.50%; loss = 2.765743  (0.726241 s/it)
Iteration  5010: accuracy_at_1 = 30.08%; accuracy_at_5 = 63.28%; loss = 2.657362  (0.700498 s/it)
Iteration  5020: accuracy_at_1 = 30.47%; accuracy_at_5 = 55.86%; loss = 2.800803  (0.702266 s/it)
Iteration  5030: accuracy_at_1 = 31.64%; accuracy_at_5 = 59.38%; loss = 2.676213  (0.701490 s/it)
Iteration  5040: accuracy_at_1 = 33.20%; accuracy_at_5 = 57.42%; loss = 2.781450  (0.701822 s/it)
Iteration  5050: accuracy_at_1 = 35.16%; accuracy_at_5 = 63.67%; loss = 2.626562  (0.702137 s/it)
Iteration  5060: accuracy_at_1 = 25.39%; accuracy_at_5 = 56.64%; loss = 3.016591  (0.701299 s/it)
Iteration  5070: accuracy_at_1 = 27.73%; accuracy_at_5 = 60.55%; loss = 2.740159  (0.700536 s/it)
Iteration  5080: accuracy_at_1 = 33.20%; accuracy_at_5 = 64.45%; loss = 2.490928  (0.701878 s/it)
Iteration  5090: accuracy_at_1 = 31.25%; accuracy_at_5 = 68.75%; loss = 2.541085  (0.700827 s/it)
Iteration  5100: accuracy_at_1 = 33.20%; accuracy_at_5 = 62.11%; loss = 2.598244  (0.700204 s/it)
Iteration  5110: accuracy_at_1 = 25.78%; accuracy_at_5 = 62.50%; loss = 2.835022  (0.700296 s/it)
Iteration  5120: accuracy_at_1 = 37.11%; accuracy_at_5 = 68.36%; loss = 2.533697  (0.701506 s/it)
Iteration  5130: accuracy_at_1 = 31.64%; accuracy_at_5 = 61.72%; loss = 2.738641  (0.702030 s/it)
Iteration  5140: accuracy_at_1 = 33.20%; accuracy_at_5 = 64.06%; loss = 2.717284  (0.702648 s/it)
Iteration  5150: accuracy_at_1 = 28.91%; accuracy_at_5 = 59.77%; loss = 2.696302  (0.701979 s/it)
Iteration  5160: accuracy_at_1 = 28.12%; accuracy_at_5 = 62.11%; loss = 2.738869  (0.701746 s/it)
Iteration  5170: accuracy_at_1 = 36.72%; accuracy_at_5 = 66.80%; loss = 2.466449  (0.701651 s/it)
Iteration  5180: accuracy_at_1 = 29.69%; accuracy_at_5 = 61.72%; loss = 2.575240  (0.701819 s/it)
Iteration  5190: accuracy_at_1 = 31.64%; accuracy_at_5 = 65.62%; loss = 2.552821  (0.700654 s/it)
Iteration  5200: accuracy_at_1 = 33.98%; accuracy_at_5 = 61.33%; loss = 2.670842  (0.700429 s/it)
Iteration  5210: accuracy_at_1 = 30.86%; accuracy_at_5 = 61.72%; loss = 2.751672  (0.701048 s/it)
Iteration  5220: accuracy_at_1 = 27.73%; accuracy_at_5 = 57.81%; loss = 2.858070  (0.700687 s/it)
Iteration  5230: accuracy_at_1 = 33.20%; accuracy_at_5 = 61.33%; loss = 2.684189  (0.700059 s/it)
Iteration  5240: accuracy_at_1 = 31.64%; accuracy_at_5 = 66.41%; loss = 2.680103  (0.700114 s/it)
Iteration  5250: accuracy_at_1 = 32.42%; accuracy_at_5 = 64.84%; loss = 2.625124  (0.701216 s/it)
Iteration  5260: accuracy_at_1 = 35.55%; accuracy_at_5 = 62.50%; loss = 2.602656  (0.701540 s/it)
Iteration  5270: accuracy_at_1 = 30.08%; accuracy_at_5 = 62.89%; loss = 2.746660  (0.701792 s/it)
Iteration  5280: accuracy_at_1 = 28.12%; accuracy_at_5 = 57.42%; loss = 2.846952  (0.701715 s/it)
Iteration  5290: accuracy_at_1 = 25.39%; accuracy_at_5 = 57.03%; loss = 2.922269  (0.702142 s/it)
Iteration  5300: accuracy_at_1 = 31.64%; accuracy_at_5 = 58.98%; loss = 2.764009  (0.701641 s/it)
Iteration  5310: accuracy_at_1 = 26.95%; accuracy_at_5 = 57.03%; loss = 2.883763  (0.701624 s/it)
Iteration  5320: accuracy_at_1 = 26.56%; accuracy_at_5 = 59.38%; loss = 2.964297  (0.700029 s/it)
Iteration  5330: accuracy_at_1 = 26.56%; accuracy_at_5 = 60.16%; loss = 2.844688  (0.700153 s/it)
Iteration  5340: accuracy_at_1 = 32.42%; accuracy_at_5 = 56.25%; loss = 2.823577  (0.700308 s/it)
Iteration  5350: accuracy_at_1 = 32.81%; accuracy_at_5 = 60.55%; loss = 2.623322  (0.700303 s/it)
Iteration  5360: accuracy_at_1 = 33.20%; accuracy_at_5 = 62.89%; loss = 2.623796  (0.700371 s/it)
Iteration  5370: accuracy_at_1 = 25.00%; accuracy_at_5 = 63.28%; loss = 2.885156  (0.700405 s/it)
Iteration  5380: accuracy_at_1 = 26.17%; accuracy_at_5 = 57.03%; loss = 2.886352  (0.701373 s/it)
Iteration  5390: accuracy_at_1 = 30.47%; accuracy_at_5 = 62.50%; loss = 2.652897  (0.701608 s/it)
Iteration  5400: accuracy_at_1 = 30.08%; accuracy_at_5 = 53.52%; loss = 2.904925  (0.701225 s/it)
Iteration  5410: accuracy_at_1 = 33.20%; accuracy_at_5 = 59.77%; loss = 2.736864  (0.701229 s/it)
Iteration  5420: accuracy_at_1 = 34.77%; accuracy_at_5 = 63.67%; loss = 2.606753  (0.701861 s/it)
Iteration  5430: accuracy_at_1 = 33.59%; accuracy_at_5 = 57.81%; loss = 2.732723  (0.701346 s/it)
Iteration  5440: accuracy_at_1 = 25.39%; accuracy_at_5 = 58.98%; loss = 2.816176  (0.701311 s/it)
Iteration  5450: accuracy_at_1 = 31.25%; accuracy_at_5 = 62.89%; loss = 2.687275  (0.699784 s/it)
Iteration  5460: accuracy_at_1 = 30.08%; accuracy_at_5 = 63.28%; loss = 2.853161  (0.700207 s/it)
Iteration  5470: accuracy_at_1 = 32.81%; accuracy_at_5 = 60.16%; loss = 2.619967  (0.700687 s/it)
Iteration  5480: accuracy_at_1 = 32.03%; accuracy_at_5 = 67.19%; loss = 2.489410  (0.700175 s/it)
Iteration  5490: accuracy_at_1 = 32.42%; accuracy_at_5 = 64.84%; loss = 2.537938  (0.700261 s/it)
Iteration  5500: accuracy_at_1 = 29.30%; accuracy_at_5 = 62.11%; loss = 2.716139  (0.700304 s/it)
Iteration  5510: accuracy_at_1 = 34.38%; accuracy_at_5 = 65.23%; loss = 2.536562  (0.702025 s/it)
Iteration  5520: accuracy_at_1 = 32.42%; accuracy_at_5 = 66.02%; loss = 2.593651  (0.701472 s/it)
Iteration  5530: accuracy_at_1 = 33.20%; accuracy_at_5 = 66.41%; loss = 2.604212  (0.701219 s/it)
Iteration  5540: accuracy_at_1 = 30.86%; accuracy_at_5 = 65.62%; loss = 2.592440  (0.701608 s/it)
Iteration  5550: accuracy_at_1 = 30.47%; accuracy_at_5 = 58.20%; loss = 2.822180  (0.700860 s/it)
Iteration  5560: accuracy_at_1 = 35.94%; accuracy_at_5 = 67.97%; loss = 2.516580  (0.701302 s/it)
Iteration  5570: accuracy_at_1 = 27.73%; accuracy_at_5 = 62.11%; loss = 2.711578  (0.700969 s/it)
Iteration  5580: accuracy_at_1 = 35.55%; accuracy_at_5 = 65.23%; loss = 2.473955  (0.700007 s/it)
Iteration  5590: accuracy_at_1 = 32.81%; accuracy_at_5 = 59.38%; loss = 2.723632  (0.683594 s/it)
Iteration  5600: accuracy_at_1 = 28.12%; accuracy_at_5 = 60.94%; loss = 2.676101  (0.696047 s/it)
Iteration  5610: accuracy_at_1 = 36.33%; accuracy_at_5 = 66.41%; loss = 2.514697  (0.696241 s/it)
Iteration  5620: accuracy_at_1 = 33.98%; accuracy_at_5 = 62.89%; loss = 2.524485  (0.696446 s/it)
Iteration  5630: accuracy_at_1 = 33.20%; accuracy_at_5 = 62.50%; loss = 2.692885  (0.696162 s/it)
Iteration  5640: accuracy_at_1 = 30.47%; accuracy_at_5 = 62.11%; loss = 2.666584  (0.697590 s/it)
Iteration  5650: accuracy_at_1 = 30.08%; accuracy_at_5 = 58.20%; loss = 2.758809  (0.697595 s/it)
Iteration  5660: accuracy_at_1 = 27.34%; accuracy_at_5 = 62.50%; loss = 2.701784  (0.697805 s/it)
Iteration  5670: accuracy_at_1 = 32.81%; accuracy_at_5 = 67.19%; loss = 2.596083  (0.697433 s/it)
Iteration  5680: accuracy_at_1 = 33.98%; accuracy_at_5 = 64.06%; loss = 2.568161  (0.697725 s/it)
Iteration  5690: accuracy_at_1 = 29.69%; accuracy_at_5 = 62.50%; loss = 2.740789  (0.698238 s/it)
Iteration  5700: accuracy_at_1 = 28.91%; accuracy_at_5 = 58.20%; loss = 2.721604  (0.696963 s/it)
Iteration  5710: accuracy_at_1 = 29.30%; accuracy_at_5 = 59.38%; loss = 2.858290  (0.696593 s/it)
Iteration  5720: accuracy_at_1 = 28.91%; accuracy_at_5 = 62.11%; loss = 2.685057  (0.696503 s/it)
Iteration  5730: accuracy_at_1 = 29.30%; accuracy_at_5 = 59.38%; loss = 2.770232  (0.696011 s/it)
Iteration  5740: accuracy_at_1 = 33.98%; accuracy_at_5 = 64.45%; loss = 2.567511  (0.696739 s/it)
Iteration  5750: accuracy_at_1 = 28.91%; accuracy_at_5 = 60.94%; loss = 2.819319  (0.696818 s/it)
Iteration  5760: accuracy_at_1 = 29.69%; accuracy_at_5 = 61.33%; loss = 2.797039  (0.707229 s/it)
Iteration  5770: accuracy_at_1 = 27.73%; accuracy_at_5 = 56.25%; loss = 2.770412  (0.756748 s/it)
Iteration  5780: accuracy_at_1 = 35.16%; accuracy_at_5 = 66.80%; loss = 2.562591  (0.755203 s/it)
Iteration  5790: accuracy_at_1 = 33.59%; accuracy_at_5 = 63.67%; loss = 2.664690  (0.755278 s/it)
Iteration  5800: accuracy_at_1 = 28.12%; accuracy_at_5 = 63.28%; loss = 2.714439  (0.752546 s/it)
Iteration  5810: accuracy_at_1 = 24.61%; accuracy_at_5 = 55.08%; loss = 2.951388  (0.757166 s/it)
Iteration  5820: accuracy_at_1 = 28.12%; accuracy_at_5 = 60.94%; loss = 2.778148  (0.754862 s/it)
Iteration  5830: accuracy_at_1 = 27.73%; accuracy_at_5 = 60.16%; loss = 2.749248  (0.751777 s/it)
Iteration  5840: accuracy_at_1 = 26.95%; accuracy_at_5 = 62.50%; loss = 2.727425  (0.745022 s/it)
Iteration  5850: accuracy_at_1 = 29.30%; accuracy_at_5 = 60.55%; loss = 2.760597  (0.700564 s/it)
Iteration  5860: accuracy_at_1 = 32.03%; accuracy_at_5 = 62.11%; loss = 2.624098  (0.702316 s/it)
Iteration  5870: accuracy_at_1 = 31.25%; accuracy_at_5 = 67.97%; loss = 2.448989  (0.700192 s/it)
Iteration  5880: accuracy_at_1 = 35.94%; accuracy_at_5 = 66.02%; loss = 2.476320  (0.702391 s/it)
Iteration  5890: accuracy_at_1 = 29.30%; accuracy_at_5 = 57.03%; loss = 2.817999  (0.871271 s/it)
Iteration  5900: accuracy_at_1 = 35.94%; accuracy_at_5 = 65.62%; loss = 2.462219  (1.056347 s/it)
Iteration  5910: accuracy_at_1 = 40.23%; accuracy_at_5 = 71.09%; loss = 2.332822  (1.057584 s/it)
Iteration  5920: accuracy_at_1 = 35.55%; accuracy_at_5 = 67.58%; loss = 2.416991  (1.060433 s/it)
Iteration  5930: accuracy_at_1 = 32.81%; accuracy_at_5 = 67.19%; loss = 2.505591  (1.056948 s/it)
Iteration  5940: accuracy_at_1 = 35.94%; accuracy_at_5 = 70.31%; loss = 2.439502  (1.054524 s/it)
Iteration  5950: accuracy_at_1 = 33.98%; accuracy_at_5 = 58.98%; loss = 2.753447  (1.056404 s/it)
Iteration  5960: accuracy_at_1 = 32.81%; accuracy_at_5 = 64.06%; loss = 2.634972  (1.054318 s/it)
Iteration  5970: accuracy_at_1 = 34.38%; accuracy_at_5 = 62.89%; loss = 2.534203  (1.048625 s/it)
Iteration  5980: accuracy_at_1 = 32.81%; accuracy_at_5 = 57.42%; loss = 2.769895  (0.927367 s/it)
Iteration  5990: accuracy_at_1 = 33.20%; accuracy_at_5 = 67.19%; loss = 2.573554  (0.790473 s/it)
Iteration  6000: accuracy_at_1 = 31.25%; accuracy_at_5 = 62.50%; loss = 2.711713  (0.805084 s/it)
Iteration  6010: accuracy_at_1 = 36.33%; accuracy_at_5 = 69.53%; loss = 2.428284  (0.771704 s/it)
Iteration  6020: accuracy_at_1 = 30.08%; accuracy_at_5 = 55.47%; loss = 2.756775  (0.697228 s/it)
Iteration  6030: accuracy_at_1 = 37.11%; accuracy_at_5 = 64.84%; loss = 2.461459  (0.697295 s/it)
Iteration  6040: accuracy_at_1 = 32.42%; accuracy_at_5 = 66.02%; loss = 2.571495  (0.698243 s/it)
Iteration  6050: accuracy_at_1 = 33.59%; accuracy_at_5 = 60.16%; loss = 2.616854  (0.698304 s/it)
Iteration  6060: accuracy_at_1 = 29.69%; accuracy_at_5 = 63.28%; loss = 2.750355  (0.698750 s/it)
Iteration  6070: accuracy_at_1 = 33.59%; accuracy_at_5 = 63.67%; loss = 2.586805  (0.698556 s/it)
Iteration  6080: accuracy_at_1 = 33.20%; accuracy_at_5 = 61.33%; loss = 2.668296  (0.697957 s/it)
Iteration  6090: accuracy_at_1 = 28.12%; accuracy_at_5 = 62.50%; loss = 2.755165  (0.696335 s/it)
Iteration  6100: accuracy_at_1 = 27.73%; accuracy_at_5 = 60.16%; loss = 2.834722  (0.696451 s/it)
Iteration  6110: accuracy_at_1 = 31.64%; accuracy_at_5 = 63.67%; loss = 2.731836  (0.696645 s/it)
Iteration  6120: accuracy_at_1 = 27.34%; accuracy_at_5 = 60.16%; loss = 2.723455  (0.696110 s/it)
Iteration  6130: accuracy_at_1 = 34.38%; accuracy_at_5 = 65.62%; loss = 2.445453  (0.695788 s/it)
Iteration  6140: accuracy_at_1 = 36.72%; accuracy_at_5 = 63.28%; loss = 2.659091  (0.695963 s/it)
Iteration  6150: accuracy_at_1 = 31.64%; accuracy_at_5 = 64.06%; loss = 2.713115  (0.697111 s/it)
Iteration  6160: accuracy_at_1 = 30.47%; accuracy_at_5 = 64.84%; loss = 2.625999  (0.696819 s/it)
Iteration  6170: accuracy_at_1 = 31.25%; accuracy_at_5 = 67.58%; loss = 2.587056  (0.697000 s/it)
Iteration  6180: accuracy_at_1 = 32.42%; accuracy_at_5 = 65.62%; loss = 2.664939  (0.698104 s/it)
Iteration  6190: accuracy_at_1 = 29.69%; accuracy_at_5 = 63.28%; loss = 2.780149  (0.696780 s/it)
Iteration  6200: accuracy_at_1 = 31.64%; accuracy_at_5 = 58.98%; loss = 2.798409  (0.697877 s/it)
Iteration  6210: accuracy_at_1 = 28.12%; accuracy_at_5 = 60.94%; loss = 2.748273  (0.697255 s/it)
Iteration  6220: accuracy_at_1 = 32.42%; accuracy_at_5 = 62.50%; loss = 2.759078  (0.696032 s/it)
Iteration  6230: accuracy_at_1 = 27.34%; accuracy_at_5 = 57.42%; loss = 2.860872  (0.696421 s/it)
Iteration  6240: accuracy_at_1 = 27.34%; accuracy_at_5 = 62.50%; loss = 2.816047  (0.696580 s/it)
Iteration  6250: accuracy_at_1 = 30.86%; accuracy_at_5 = 65.23%; loss = 2.531814  (0.697492 s/it)
Iteration  6260: accuracy_at_1 = 32.81%; accuracy_at_5 = 63.28%; loss = 2.652640  (0.696231 s/it)
Iteration  6270: accuracy_at_1 = 44.14%; accuracy_at_5 = 70.70%; loss = 2.236242  (0.696169 s/it)
Iteration  6280: accuracy_at_1 = 32.81%; accuracy_at_5 = 61.72%; loss = 2.645285  (0.697330 s/it)
Iteration  6290: accuracy_at_1 = 37.11%; accuracy_at_5 = 65.23%; loss = 2.458869  (0.698318 s/it)
Iteration  6300: accuracy_at_1 = 32.42%; accuracy_at_5 = 67.19%; loss = 2.563610  (0.697627 s/it)
Iteration  6310: accuracy_at_1 = 32.81%; accuracy_at_5 = 63.67%; loss = 2.722107  (0.697326 s/it)
Iteration  6320: accuracy_at_1 = 35.16%; accuracy_at_5 = 63.67%; loss = 2.532439  (0.697566 s/it)
Iteration  6330: accuracy_at_1 = 30.47%; accuracy_at_5 = 65.62%; loss = 2.646414  (0.697033 s/it)
Iteration  6340: accuracy_at_1 = 33.98%; accuracy_at_5 = 64.84%; loss = 2.517429  (0.696913 s/it)
Iteration  6350: accuracy_at_1 = 29.30%; accuracy_at_5 = 61.33%; loss = 2.660398  (0.696005 s/it)
Iteration  6360: accuracy_at_1 = 32.81%; accuracy_at_5 = 69.92%; loss = 2.489959  (0.696349 s/it)
Iteration  6370: accuracy_at_1 = 34.38%; accuracy_at_5 = 63.67%; loss = 2.564962  (0.696392 s/it)
Iteration  6380: accuracy_at_1 = 38.28%; accuracy_at_5 = 69.92%; loss = 2.375047  (0.695718 s/it)
Iteration  6390: accuracy_at_1 = 34.77%; accuracy_at_5 = 64.06%; loss = 2.482865  (0.698022 s/it)
Iteration  6400: accuracy_at_1 = 31.25%; accuracy_at_5 = 64.45%; loss = 2.621508  (0.696863 s/it)
Iteration  6410: accuracy_at_1 = 33.98%; accuracy_at_5 = 64.06%; loss = 2.481810  (0.697996 s/it)
Iteration  6420: accuracy_at_1 = 28.91%; accuracy_at_5 = 63.67%; loss = 2.597166  (0.698021 s/it)
Iteration  6430: accuracy_at_1 = 33.98%; accuracy_at_5 = 71.48%; loss = 2.462661  (0.697457 s/it)
Iteration  6440: accuracy_at_1 = 39.84%; accuracy_at_5 = 69.14%; loss = 2.332331  (0.697938 s/it)
Iteration  6450: accuracy_at_1 = 33.20%; accuracy_at_5 = 68.75%; loss = 2.535839  (0.697066 s/it)
Iteration  6460: accuracy_at_1 = 30.08%; accuracy_at_5 = 66.41%; loss = 2.584006  (0.697703 s/it)
Iteration  6470: accuracy_at_1 = 25.00%; accuracy_at_5 = 63.67%; loss = 2.707283  (0.696857 s/it)
Iteration  6480: accuracy_at_1 = 32.81%; accuracy_at_5 = 63.28%; loss = 2.665411  (0.696276 s/it)
Iteration  6490: accuracy_at_1 = 37.50%; accuracy_at_5 = 64.06%; loss = 2.580716  (0.696416 s/it)
Iteration  6500: accuracy_at_1 = 26.56%; accuracy_at_5 = 60.55%; loss = 2.709244  (0.696368 s/it)
Iteration  6510: accuracy_at_1 = 28.52%; accuracy_at_5 = 60.55%; loss = 2.647094  (0.696585 s/it)
Iteration  6520: accuracy_at_1 = 27.34%; accuracy_at_5 = 58.59%; loss = 2.806725  (0.696018 s/it)
Iteration  6530: accuracy_at_1 = 31.25%; accuracy_at_5 = 53.12%; loss = 2.836894  (0.697034 s/it)
Iteration  6540: accuracy_at_1 = 33.98%; accuracy_at_5 = 64.84%; loss = 2.553622  (0.698039 s/it)
Iteration  6550: accuracy_at_1 = 28.91%; accuracy_at_5 = 56.25%; loss = 2.918124  (0.697009 s/it)
Iteration  6560: accuracy_at_1 = 36.33%; accuracy_at_5 = 61.72%; loss = 2.589472  (0.697670 s/it)
Iteration  6570: accuracy_at_1 = 35.94%; accuracy_at_5 = 65.23%; loss = 2.604444  (0.697757 s/it)
Iteration  6580: accuracy_at_1 = 28.12%; accuracy_at_5 = 55.47%; loss = 2.812739  (0.697779 s/it)
Iteration  6590: accuracy_at_1 = 30.47%; accuracy_at_5 = 58.59%; loss = 2.773589  (0.697626 s/it)
Iteration  6600: accuracy_at_1 = 32.81%; accuracy_at_5 = 72.27%; loss = 2.558185  (0.695578 s/it)
Iteration  6610: accuracy_at_1 = 26.95%; accuracy_at_5 = 59.77%; loss = 2.747484  (0.696534 s/it)
Iteration  6620: accuracy_at_1 = 24.22%; accuracy_at_5 = 52.73%; loss = 2.968327  (0.696473 s/it)
Iteration  6630: accuracy_at_1 = 30.08%; accuracy_at_5 = 64.45%; loss = 2.624334  (0.696398 s/it)
Iteration  6640: accuracy_at_1 = 33.59%; accuracy_at_5 = 64.84%; loss = 2.601056  (0.696871 s/it)
Iteration  6650: accuracy_at_1 = 32.42%; accuracy_at_5 = 63.28%; loss = 2.577634  (0.696022 s/it)
Iteration  6660: accuracy_at_1 = 40.62%; accuracy_at_5 = 69.53%; loss = 2.425506  (0.697019 s/it)
Iteration  6670: accuracy_at_1 = 34.38%; accuracy_at_5 = 66.41%; loss = 2.482175  (0.697778 s/it)
Iteration  6680: accuracy_at_1 = 37.50%; accuracy_at_5 = 69.53%; loss = 2.277858  (0.697516 s/it)
Iteration  6690: accuracy_at_1 = 33.20%; accuracy_at_5 = 66.80%; loss = 2.516842  (0.696528 s/it)
Iteration  6700: accuracy_at_1 = 36.33%; accuracy_at_5 = 68.36%; loss = 2.362989  (0.697084 s/it)
Iteration  6710: accuracy_at_1 = 28.12%; accuracy_at_5 = 63.67%; loss = 2.645413  (0.697549 s/it)
Iteration  6720: accuracy_at_1 = 33.20%; accuracy_at_5 = 67.58%; loss = 2.506422  (0.697085 s/it)
Iteration  6730: accuracy_at_1 = 34.38%; accuracy_at_5 = 65.23%; loss = 2.461870  (0.696719 s/it)
Iteration  6740: accuracy_at_1 = 34.77%; accuracy_at_5 = 65.23%; loss = 2.514678  (0.696410 s/it)
Iteration  6750: accuracy_at_1 = 38.28%; accuracy_at_5 = 67.19%; loss = 2.412232  (0.696227 s/it)
Iteration  6760: accuracy_at_1 = 30.86%; accuracy_at_5 = 66.80%; loss = 2.517831  (0.696155 s/it)
Iteration  6770: accuracy_at_1 = 30.86%; accuracy_at_5 = 64.45%; loss = 2.530436  (0.696509 s/it)
Iteration  6780: accuracy_at_1 = 35.55%; accuracy_at_5 = 63.28%; loss = 2.566506  (0.696690 s/it)
Iteration  6790: accuracy_at_1 = 26.95%; accuracy_at_5 = 60.16%; loss = 2.749615  (0.697203 s/it)
Iteration  6800: accuracy_at_1 = 32.42%; accuracy_at_5 = 65.23%; loss = 2.684575  (0.697311 s/it)
Iteration  6810: accuracy_at_1 = 32.03%; accuracy_at_5 = 62.11%; loss = 2.622570  (0.697808 s/it)
Iteration  6820: accuracy_at_1 = 33.59%; accuracy_at_5 = 66.02%; loss = 2.533238  (0.697516 s/it)
Iteration  6830: accuracy_at_1 = 34.77%; accuracy_at_5 = 69.92%; loss = 2.444632  (0.698076 s/it)
Iteration  6840: accuracy_at_1 = 29.69%; accuracy_at_5 = 61.72%; loss = 2.769558  (0.697547 s/it)
Iteration  6850: accuracy_at_1 = 32.81%; accuracy_at_5 = 61.72%; loss = 2.733909  (0.697538 s/it)
Iteration  6860: accuracy_at_1 = 36.33%; accuracy_at_5 = 67.97%; loss = 2.441926  (0.696135 s/it)
Iteration  6870: accuracy_at_1 = 32.03%; accuracy_at_5 = 59.38%; loss = 2.629444  (0.696778 s/it)
Iteration  6880: accuracy_at_1 = 32.81%; accuracy_at_5 = 60.16%; loss = 2.781129  (0.695984 s/it)
Iteration  6890: accuracy_at_1 = 32.42%; accuracy_at_5 = 63.67%; loss = 2.509457  (0.695964 s/it)
Iteration  6900: accuracy_at_1 = 31.25%; accuracy_at_5 = 61.72%; loss = 2.662235  (0.696025 s/it)
Iteration  6910: accuracy_at_1 = 31.25%; accuracy_at_5 = 64.45%; loss = 2.650333  (0.696103 s/it)
Iteration  6920: accuracy_at_1 = 33.98%; accuracy_at_5 = 66.02%; loss = 2.491776  (0.697026 s/it)
Iteration  6930: accuracy_at_1 = 31.64%; accuracy_at_5 = 65.23%; loss = 2.686766  (0.697230 s/it)
Iteration  6940: accuracy_at_1 = 35.55%; accuracy_at_5 = 68.75%; loss = 2.375801  (0.698250 s/it)
Iteration  6950: accuracy_at_1 = 32.81%; accuracy_at_5 = 62.11%; loss = 2.571109  (0.700815 s/it)
Iteration  6960: accuracy_at_1 = 32.81%; accuracy_at_5 = 69.92%; loss = 2.574217  (0.697976 s/it)
Iteration  6970: accuracy_at_1 = 27.73%; accuracy_at_5 = 55.86%; loss = 2.786896  (0.697110 s/it)
Iteration  6980: accuracy_at_1 = 30.08%; accuracy_at_5 = 62.89%; loss = 2.693329  (0.696699 s/it)
Iteration  6990: accuracy_at_1 = 30.86%; accuracy_at_5 = 64.84%; loss = 2.569247  (0.696397 s/it)
Iteration  7000: accuracy_at_1 = 34.77%; accuracy_at_5 = 71.09%; loss = 2.415258  (0.696201 s/it)
Iteration  7010: accuracy_at_1 = 28.91%; accuracy_at_5 = 58.20%; loss = 2.698046  (0.696342 s/it)
Iteration  7020: accuracy_at_1 = 38.28%; accuracy_at_5 = 73.05%; loss = 2.367536  (0.696910 s/it)
Iteration  7030: accuracy_at_1 = 29.69%; accuracy_at_5 = 60.94%; loss = 2.709195  (0.697273 s/it)
Iteration  7040: accuracy_at_1 = 39.45%; accuracy_at_5 = 64.45%; loss = 2.443854  (0.696541 s/it)
Iteration  7050: accuracy_at_1 = 40.23%; accuracy_at_5 = 69.92%; loss = 2.333129  (0.697606 s/it)
Iteration  7060: accuracy_at_1 = 30.86%; accuracy_at_5 = 64.84%; loss = 2.576670  (0.697951 s/it)
Iteration  7070: accuracy_at_1 = 34.77%; accuracy_at_5 = 69.92%; loss = 2.386513  (0.697560 s/it)
Iteration  7080: accuracy_at_1 = 30.08%; accuracy_at_5 = 65.62%; loss = 2.557099  (0.696954 s/it)
Iteration  7090: accuracy_at_1 = 29.69%; accuracy_at_5 = 62.11%; loss = 2.653746  (0.697352 s/it)
Iteration  7100: accuracy_at_1 = 35.16%; accuracy_at_5 = 65.62%; loss = 2.493453  (0.697520 s/it)
Iteration  7110: accuracy_at_1 = 34.38%; accuracy_at_5 = 71.09%; loss = 2.460998  (0.696389 s/it)
Iteration  7120: accuracy_at_1 = 35.16%; accuracy_at_5 = 66.02%; loss = 2.401810  (0.695698 s/it)
Iteration  7130: accuracy_at_1 = 35.55%; accuracy_at_5 = 67.58%; loss = 2.531968  (0.696252 s/it)
Iteration  7140: accuracy_at_1 = 40.62%; accuracy_at_5 = 69.53%; loss = 2.337025  (0.695846 s/it)
Iteration  7150: accuracy_at_1 = 33.20%; accuracy_at_5 = 65.23%; loss = 2.597752  (0.696873 s/it)
Iteration  7160: accuracy_at_1 = 39.84%; accuracy_at_5 = 71.48%; loss = 2.293316  (0.696211 s/it)
Iteration  7170: accuracy_at_1 = 36.72%; accuracy_at_5 = 67.19%; loss = 2.359160  (0.697061 s/it)
Iteration  7180: accuracy_at_1 = 36.72%; accuracy_at_5 = 64.06%; loss = 2.428390  (0.697748 s/it)
Iteration  7190: accuracy_at_1 = 36.72%; accuracy_at_5 = 68.36%; loss = 2.384055  (0.696962 s/it)
Iteration  7200: accuracy_at_1 = 34.77%; accuracy_at_5 = 69.14%; loss = 2.412906  (0.696865 s/it)
Iteration  7210: accuracy_at_1 = 37.89%; accuracy_at_5 = 71.88%; loss = 2.335541  (0.697652 s/it)
Iteration  7220: accuracy_at_1 = 36.72%; accuracy_at_5 = 64.45%; loss = 2.482015  (0.697003 s/it)
Iteration  7230: accuracy_at_1 = 31.64%; accuracy_at_5 = 64.06%; loss = 2.495244  (0.697108 s/it)
Iteration  7240: accuracy_at_1 = 41.02%; accuracy_at_5 = 68.36%; loss = 2.373907  (0.696290 s/it)
Iteration  7250: accuracy_at_1 = 30.47%; accuracy_at_5 = 64.45%; loss = 2.661079  (0.695842 s/it)
Iteration  7260: accuracy_at_1 = 38.67%; accuracy_at_5 = 71.48%; loss = 2.326859  (0.696417 s/it)
Iteration  7270: accuracy_at_1 = 41.80%; accuracy_at_5 = 66.80%; loss = 2.470653  (0.696183 s/it)
Iteration  7280: accuracy_at_1 = 29.30%; accuracy_at_5 = 61.72%; loss = 2.741328  (0.696153 s/it)
Iteration  7290: accuracy_at_1 = 34.77%; accuracy_at_5 = 65.62%; loss = 2.493653  (0.696417 s/it)
Iteration  7300: accuracy_at_1 = 32.42%; accuracy_at_5 = 64.84%; loss = 2.597617  (0.696765 s/it)
Iteration  7310: accuracy_at_1 = 38.67%; accuracy_at_5 = 67.58%; loss = 2.333589  (0.696868 s/it)
Iteration  7320: accuracy_at_1 = 38.67%; accuracy_at_5 = 64.84%; loss = 2.491946  (0.696859 s/it)
Iteration  7330: accuracy_at_1 = 29.30%; accuracy_at_5 = 68.75%; loss = 2.581242  (0.698029 s/it)
Iteration  7340: accuracy_at_1 = 30.86%; accuracy_at_5 = 63.28%; loss = 2.631372  (0.697310 s/it)
Iteration  7350: accuracy_at_1 = 31.25%; accuracy_at_5 = 61.72%; loss = 2.696279  (0.697174 s/it)
Iteration  7360: accuracy_at_1 = 33.20%; accuracy_at_5 = 66.02%; loss = 2.546748  (0.697557 s/it)
Iteration  7370: accuracy_at_1 = 36.33%; accuracy_at_5 = 66.41%; loss = 2.514565  (0.696069 s/it)
Iteration  7380: accuracy_at_1 = 33.59%; accuracy_at_5 = 61.33%; loss = 2.702096  (0.696290 s/it)
Iteration  7390: accuracy_at_1 = 26.56%; accuracy_at_5 = 59.38%; loss = 2.788282  (0.697334 s/it)
Iteration  7400: accuracy_at_1 = 32.81%; accuracy_at_5 = 61.72%; loss = 2.650232  (0.696836 s/it)
Iteration  7410: accuracy_at_1 = 32.42%; accuracy_at_5 = 62.50%; loss = 2.698050  (0.695974 s/it)
Iteration  7420: accuracy_at_1 = 33.98%; accuracy_at_5 = 62.89%; loss = 2.676232  (0.697249 s/it)
Iteration  7430: accuracy_at_1 = 32.42%; accuracy_at_5 = 65.62%; loss = 2.557551  (0.697245 s/it)
Iteration  7440: accuracy_at_1 = 47.27%; accuracy_at_5 = 76.56%; loss = 2.056146  (0.697807 s/it)
Iteration  7450: accuracy_at_1 = 39.84%; accuracy_at_5 = 76.17%; loss = 2.151285  (0.696722 s/it)
Iteration  7460: accuracy_at_1 = 34.77%; accuracy_at_5 = 67.19%; loss = 2.408999  (0.697412 s/it)
Iteration  7470: accuracy_at_1 = 41.41%; accuracy_at_5 = 71.88%; loss = 2.193558  (0.696805 s/it)
Iteration  7480: accuracy_at_1 = 39.06%; accuracy_at_5 = 71.09%; loss = 2.209246  (0.696839 s/it)
Iteration  7490: accuracy_at_1 = 33.98%; accuracy_at_5 = 69.14%; loss = 2.443609  (0.697042 s/it)
Iteration  7500: accuracy_at_1 = 35.16%; accuracy_at_5 = 65.23%; loss = 2.449508  (0.696909 s/it)
Iteration  7510: accuracy_at_1 = 34.77%; accuracy_at_5 = 70.31%; loss = 2.389297  (0.697093 s/it)
Iteration  7520: accuracy_at_1 = 34.38%; accuracy_at_5 = 71.09%; loss = 2.377752  (0.696274 s/it)
Iteration  7530: accuracy_at_1 = 31.25%; accuracy_at_5 = 66.80%; loss = 2.549165  (0.696591 s/it)
Iteration  7540: accuracy_at_1 = 29.30%; accuracy_at_5 = 63.28%; loss = 2.629759  (0.696048 s/it)
Iteration  7550: accuracy_at_1 = 41.02%; accuracy_at_5 = 72.27%; loss = 2.248063  (0.696076 s/it)
Iteration  7560: accuracy_at_1 = 34.38%; accuracy_at_5 = 67.19%; loss = 2.467306  (0.696608 s/it)
Iteration  7570: accuracy_at_1 = 41.41%; accuracy_at_5 = 70.31%; loss = 2.284384  (0.696583 s/it)
Iteration  7580: accuracy_at_1 = 39.45%; accuracy_at_5 = 68.36%; loss = 2.433465  (0.696841 s/it)
Iteration  7590: accuracy_at_1 = 37.11%; accuracy_at_5 = 71.09%; loss = 2.311143  (0.697743 s/it)
Iteration  7600: accuracy_at_1 = 37.11%; accuracy_at_5 = 65.62%; loss = 2.581546  (0.697619 s/it)
Iteration  7610: accuracy_at_1 = 39.06%; accuracy_at_5 = 66.80%; loss = 2.453335  (0.698451 s/it)
Iteration  7620: accuracy_at_1 = 36.72%; accuracy_at_5 = 63.67%; loss = 2.606597  (0.696298 s/it)
Iteration  7630: accuracy_at_1 = 29.69%; accuracy_at_5 = 62.50%; loss = 2.645373  (0.696266 s/it)
Iteration  7640: accuracy_at_1 = 28.91%; accuracy_at_5 = 62.50%; loss = 2.795095  (0.695956 s/it)
Iteration  7650: accuracy_at_1 = 33.98%; accuracy_at_5 = 62.89%; loss = 2.558695  (0.696699 s/it)
Iteration  7660: accuracy_at_1 = 33.98%; accuracy_at_5 = 66.02%; loss = 2.502919  (0.695639 s/it)
Iteration  7670: accuracy_at_1 = 33.98%; accuracy_at_5 = 62.89%; loss = 2.532516  (0.696139 s/it)
Iteration  7680: accuracy_at_1 = 33.98%; accuracy_at_5 = 64.06%; loss = 2.546235  (0.696484 s/it)
Iteration  7690: accuracy_at_1 = 33.20%; accuracy_at_5 = 60.94%; loss = 2.578177  (0.697441 s/it)
Iteration  7700: accuracy_at_1 = 37.50%; accuracy_at_5 = 69.14%; loss = 2.471289  (0.697672 s/it)
Iteration  7710: accuracy_at_1 = 34.77%; accuracy_at_5 = 62.50%; loss = 2.477734  (0.698030 s/it)
Iteration  7720: accuracy_at_1 = 38.28%; accuracy_at_5 = 66.41%; loss = 2.383308  (0.697793 s/it)
Iteration  7730: accuracy_at_1 = 33.98%; accuracy_at_5 = 67.97%; loss = 2.577120  (0.697626 s/it)
Iteration  7740: accuracy_at_1 = 28.91%; accuracy_at_5 = 63.28%; loss = 2.689713  (0.697666 s/it)
Iteration  7750: accuracy_at_1 = 27.34%; accuracy_at_5 = 60.55%; loss = 2.684109  (0.695526 s/it)
Iteration  7760: accuracy_at_1 = 36.33%; accuracy_at_5 = 70.70%; loss = 2.483671  (0.696496 s/it)
Iteration  7770: accuracy_at_1 = 32.03%; accuracy_at_5 = 64.45%; loss = 2.676162  (0.696345 s/it)
Iteration  7780: accuracy_at_1 = 33.59%; accuracy_at_5 = 58.20%; loss = 2.649405  (0.696748 s/it)
Iteration  7790: accuracy_at_1 = 33.20%; accuracy_at_5 = 60.55%; loss = 2.618484  (0.696273 s/it)
Iteration  7800: accuracy_at_1 = 30.86%; accuracy_at_5 = 60.16%; loss = 2.630446  (0.696762 s/it)
Iteration  7810: accuracy_at_1 = 28.91%; accuracy_at_5 = 67.97%; loss = 2.581598  (0.697726 s/it)
Iteration  7820: accuracy_at_1 = 35.94%; accuracy_at_5 = 62.89%; loss = 2.519700  (0.697527 s/it)
Iteration  7830: accuracy_at_1 = 37.11%; accuracy_at_5 = 66.41%; loss = 2.342658  (0.697383 s/it)
Iteration  7840: accuracy_at_1 = 41.02%; accuracy_at_5 = 69.53%; loss = 2.263109  (0.697768 s/it)
Iteration  7850: accuracy_at_1 = 35.16%; accuracy_at_5 = 64.06%; loss = 2.390810  (0.697821 s/it)
Iteration  7860: accuracy_at_1 = 39.84%; accuracy_at_5 = 71.88%; loss = 2.257721  (0.697506 s/it)
Iteration  7870: accuracy_at_1 = 39.06%; accuracy_at_5 = 73.44%; loss = 2.308837  (0.697760 s/it)
Iteration  7880: accuracy_at_1 = 37.89%; accuracy_at_5 = 69.53%; loss = 2.414447  (0.696097 s/it)
Iteration  7890: accuracy_at_1 = 37.89%; accuracy_at_5 = 66.02%; loss = 2.480815  (0.696285 s/it)
Iteration  7900: accuracy_at_1 = 36.33%; accuracy_at_5 = 67.19%; loss = 2.371370  (0.695813 s/it)
Iteration  7910: accuracy_at_1 = 39.06%; accuracy_at_5 = 73.05%; loss = 2.381202  (0.696763 s/it)
Iteration  7920: accuracy_at_1 = 36.72%; accuracy_at_5 = 64.45%; loss = 2.350806  (0.695816 s/it)
Iteration  7930: accuracy_at_1 = 33.98%; accuracy_at_5 = 63.28%; loss = 2.496397  (0.695849 s/it)
Iteration  7940: accuracy_at_1 = 38.67%; accuracy_at_5 = 71.09%; loss = 2.219371  (0.698072 s/it)
Iteration  7950: accuracy_at_1 = 40.62%; accuracy_at_5 = 68.36%; loss = 2.274091  (0.697698 s/it)
Iteration  7960: accuracy_at_1 = 37.50%; accuracy_at_5 = 62.50%; loss = 2.647380  (0.697364 s/it)
Iteration  7970: accuracy_at_1 = 39.84%; accuracy_at_5 = 69.92%; loss = 2.430694  (0.697494 s/it)
Iteration  7980: accuracy_at_1 = 34.77%; accuracy_at_5 = 63.67%; loss = 2.484027  (0.697393 s/it)
Iteration  7990: accuracy_at_1 = 34.38%; accuracy_at_5 = 65.62%; loss = 2.532514  (0.697511 s/it)
Iteration  8000: accuracy_at_1 = 37.89%; accuracy_at_5 = 68.75%; loss = 2.440087  (0.697262 s/it)
Iteration  8010: accuracy_at_1 = 35.55%; accuracy_at_5 = 64.45%; loss = 2.582291  (0.696063 s/it)
Iteration  8020: accuracy_at_1 = 34.77%; accuracy_at_5 = 62.50%; loss = 2.582149  (0.696186 s/it)
Iteration  8030: accuracy_at_1 = 35.55%; accuracy_at_5 = 66.80%; loss = 2.404262  (0.696126 s/it)
Iteration  8040: accuracy_at_1 = 36.72%; accuracy_at_5 = 68.36%; loss = 2.426518  (0.696315 s/it)
Iteration  8050: accuracy_at_1 = 35.94%; accuracy_at_5 = 66.80%; loss = 2.390588  (0.696888 s/it)
Iteration  8060: accuracy_at_1 = 37.89%; accuracy_at_5 = 67.58%; loss = 2.455420  (0.697447 s/it)
Iteration  8070: accuracy_at_1 = 37.11%; accuracy_at_5 = 64.45%; loss = 2.515818  (0.698246 s/it)
Iteration  8080: accuracy_at_1 = 31.25%; accuracy_at_5 = 64.84%; loss = 2.574955  (0.697538 s/it)
Iteration  8090: accuracy_at_1 = 36.72%; accuracy_at_5 = 72.66%; loss = 2.380876  (0.697798 s/it)
Iteration  8100: accuracy_at_1 = 37.11%; accuracy_at_5 = 65.23%; loss = 2.464931  (0.697525 s/it)
Iteration  8110: accuracy_at_1 = 35.16%; accuracy_at_5 = 63.67%; loss = 2.596011  (0.697409 s/it)
Iteration  8120: accuracy_at_1 = 33.59%; accuracy_at_5 = 64.06%; loss = 2.610128  (0.697544 s/it)
Iteration  8130: accuracy_at_1 = 31.25%; accuracy_at_5 = 64.84%; loss = 2.696001  (0.697612 s/it)
Iteration  8140: accuracy_at_1 = 34.38%; accuracy_at_5 = 65.62%; loss = 2.429024  (0.696904 s/it)
Iteration  8150: accuracy_at_1 = 36.33%; accuracy_at_5 = 69.92%; loss = 2.471040  (0.696924 s/it)
Iteration  8160: accuracy_at_1 = 34.38%; accuracy_at_5 = 66.02%; loss = 2.538244  (0.696644 s/it)
Iteration  8170: accuracy_at_1 = 33.59%; accuracy_at_5 = 61.33%; loss = 2.597493  (0.696297 s/it)
Iteration  8180: accuracy_at_1 = 32.81%; accuracy_at_5 = 58.20%; loss = 2.736068  (0.696042 s/it)
Iteration  8190: accuracy_at_1 = 30.86%; accuracy_at_5 = 66.41%; loss = 2.507177  (0.696096 s/it)
Iteration  8200: accuracy_at_1 = 27.73%; accuracy_at_5 = 58.59%; loss = 2.727641  (0.697101 s/it)
Iteration  8210: accuracy_at_1 = 38.28%; accuracy_at_5 = 71.09%; loss = 2.230616  (0.697957 s/it)
Iteration  8220: accuracy_at_1 = 38.28%; accuracy_at_5 = 73.83%; loss = 2.318241  (0.697235 s/it)
Iteration  8230: accuracy_at_1 = 42.58%; accuracy_at_5 = 71.48%; loss = 2.275890  (0.697582 s/it)
Iteration  8240: accuracy_at_1 = 35.94%; accuracy_at_5 = 72.66%; loss = 2.231068  (0.697500 s/it)
Iteration  8250: accuracy_at_1 = 40.62%; accuracy_at_5 = 68.75%; loss = 2.298905  (0.697431 s/it)
Iteration  8260: accuracy_at_1 = 41.02%; accuracy_at_5 = 69.53%; loss = 2.279901  (0.696446 s/it)
Iteration  8270: accuracy_at_1 = 39.84%; accuracy_at_5 = 74.61%; loss = 2.248346  (0.696527 s/it)
Iteration  8280: accuracy_at_1 = 35.16%; accuracy_at_5 = 67.19%; loss = 2.462495  (0.695928 s/it)
Iteration  8290: accuracy_at_1 = 37.11%; accuracy_at_5 = 66.02%; loss = 2.510742  (0.696099 s/it)
Iteration  8300: accuracy_at_1 = 39.84%; accuracy_at_5 = 66.80%; loss = 2.406507  (0.696286 s/it)
Iteration  8310: accuracy_at_1 = 37.50%; accuracy_at_5 = 70.70%; loss = 2.441673  (0.696680 s/it)
Iteration  8320: accuracy_at_1 = 35.94%; accuracy_at_5 = 72.27%; loss = 2.317196  (0.696574 s/it)
Iteration  8330: accuracy_at_1 = 42.19%; accuracy_at_5 = 68.36%; loss = 2.437722  (0.697690 s/it)
Iteration  8340: accuracy_at_1 = 40.23%; accuracy_at_5 = 67.97%; loss = 2.291767  (0.697023 s/it)
Iteration  8350: accuracy_at_1 = 31.64%; accuracy_at_5 = 62.11%; loss = 2.660381  (0.697186 s/it)
Iteration  8360: accuracy_at_1 = 35.55%; accuracy_at_5 = 69.92%; loss = 2.508415  (0.698075 s/it)
Iteration  8370: accuracy_at_1 = 37.89%; accuracy_at_5 = 66.41%; loss = 2.420318  (0.697122 s/it)
Iteration  8380: accuracy_at_1 = 37.50%; accuracy_at_5 = 70.70%; loss = 2.375197  (0.697556 s/it)
Iteration  8390: accuracy_at_1 = 38.28%; accuracy_at_5 = 70.70%; loss = 2.330849  (0.697572 s/it)
Iteration  8400: accuracy_at_1 = 35.94%; accuracy_at_5 = 63.67%; loss = 2.459483  (0.695986 s/it)
Iteration  8410: accuracy_at_1 = 36.33%; accuracy_at_5 = 68.75%; loss = 2.440479  (0.695874 s/it)
Iteration  8420: accuracy_at_1 = 34.38%; accuracy_at_5 = 65.23%; loss = 2.480693  (0.696117 s/it)
Iteration  8430: accuracy_at_1 = 33.20%; accuracy_at_5 = 66.41%; loss = 2.502423  (0.696409 s/it)
Iteration  8440: accuracy_at_1 = 37.11%; accuracy_at_5 = 66.80%; loss = 2.473407  (0.696588 s/it)
Iteration  8450: accuracy_at_1 = 36.72%; accuracy_at_5 = 67.58%; loss = 2.465692  (0.697525 s/it)
Iteration  8460: accuracy_at_1 = 42.58%; accuracy_at_5 = 66.02%; loss = 2.392470  (0.696760 s/it)
Iteration  8470: accuracy_at_1 = 34.77%; accuracy_at_5 = 67.97%; loss = 2.585957  (0.697767 s/it)
Iteration  8480: accuracy_at_1 = 35.94%; accuracy_at_5 = 69.53%; loss = 2.385984  (0.697359 s/it)
Iteration  8490: accuracy_at_1 = 36.33%; accuracy_at_5 = 66.80%; loss = 2.539268  (0.697042 s/it)
Iteration  8500: accuracy_at_1 = 33.20%; accuracy_at_5 = 62.50%; loss = 2.618770  (0.697962 s/it)
Iteration  8510: accuracy_at_1 = 35.16%; accuracy_at_5 = 68.36%; loss = 2.283965  (0.697608 s/it)
Iteration  8520: accuracy_at_1 = 33.20%; accuracy_at_5 = 67.97%; loss = 2.515785  (0.696471 s/it)
Iteration  8530: accuracy_at_1 = 37.11%; accuracy_at_5 = 63.67%; loss = 2.423374  (0.696354 s/it)
Iteration  8540: accuracy_at_1 = 35.16%; accuracy_at_5 = 65.62%; loss = 2.473527  (0.695905 s/it)
Iteration  8550: accuracy_at_1 = 34.38%; accuracy_at_5 = 62.89%; loss = 2.619960  (0.696122 s/it)
Iteration  8560: accuracy_at_1 = 31.64%; accuracy_at_5 = 63.28%; loss = 2.708994  (0.696372 s/it)
Iteration  8570: accuracy_at_1 = 33.98%; accuracy_at_5 = 67.19%; loss = 2.520467  (0.696169 s/it)
Iteration  8580: accuracy_at_1 = 34.77%; accuracy_at_5 = 64.84%; loss = 2.475536  (0.697147 s/it)
Iteration  8590: accuracy_at_1 = 35.55%; accuracy_at_5 = 66.80%; loss = 2.564527  (0.697234 s/it)
Iteration  8600: accuracy_at_1 = 36.72%; accuracy_at_5 = 71.48%; loss = 2.367766  (0.698897 s/it)
Iteration  8610: accuracy_at_1 = 37.11%; accuracy_at_5 = 67.58%; loss = 2.435416  (0.697842 s/it)
Iteration  8620: accuracy_at_1 = 35.55%; accuracy_at_5 = 69.14%; loss = 2.425544  (0.698057 s/it)
Iteration  8630: accuracy_at_1 = 33.98%; accuracy_at_5 = 72.66%; loss = 2.408270  (0.697490 s/it)
Iteration  8640: accuracy_at_1 = 45.31%; accuracy_at_5 = 69.53%; loss = 2.246582  (0.697022 s/it)
Iteration  8650: accuracy_at_1 = 39.45%; accuracy_at_5 = 69.14%; loss = 2.279603  (0.696332 s/it)
Iteration  8660: accuracy_at_1 = 33.98%; accuracy_at_5 = 70.70%; loss = 2.322768  (0.695540 s/it)
Iteration  8670: accuracy_at_1 = 41.80%; accuracy_at_5 = 69.92%; loss = 2.258659  (0.696006 s/it)
Iteration  8680: accuracy_at_1 = 41.80%; accuracy_at_5 = 71.09%; loss = 2.227026  (0.697003 s/it)
Iteration  8690: accuracy_at_1 = 37.89%; accuracy_at_5 = 69.92%; loss = 2.349819  (0.695883 s/it)
Iteration  8700: accuracy_at_1 = 37.89%; accuracy_at_5 = 71.09%; loss = 2.454473  (0.695822 s/it)
Iteration  8710: accuracy_at_1 = 36.33%; accuracy_at_5 = 67.19%; loss = 2.477462  (0.697219 s/it)
Iteration  8720: accuracy_at_1 = 42.19%; accuracy_at_5 = 70.31%; loss = 2.215940  (0.697730 s/it)
Iteration  8730: accuracy_at_1 = 40.62%; accuracy_at_5 = 76.17%; loss = 2.183204  (0.697419 s/it)
Iteration  8740: accuracy_at_1 = 41.41%; accuracy_at_5 = 68.75%; loss = 2.281909  (0.697240 s/it)
Iteration  8750: accuracy_at_1 = 35.94%; accuracy_at_5 = 71.09%; loss = 2.343761  (0.696923 s/it)
Iteration  8760: accuracy_at_1 = 37.11%; accuracy_at_5 = 69.53%; loss = 2.341638  (0.697585 s/it)
Iteration  8770: accuracy_at_1 = 35.94%; accuracy_at_5 = 67.19%; loss = 2.392420  (0.696522 s/it)
Iteration  8780: accuracy_at_1 = 33.20%; accuracy_at_5 = 67.19%; loss = 2.474778  (0.695851 s/it)
Iteration  8790: accuracy_at_1 = 33.98%; accuracy_at_5 = 68.75%; loss = 2.378200  (0.696732 s/it)
Iteration  8800: accuracy_at_1 = 32.81%; accuracy_at_5 = 64.45%; loss = 2.631429  (0.696482 s/it)
Iteration  8810: accuracy_at_1 = 40.62%; accuracy_at_5 = 71.88%; loss = 2.335918  (0.696217 s/it)
Iteration  8820: accuracy_at_1 = 35.55%; accuracy_at_5 = 68.75%; loss = 2.467891  (0.697143 s/it)
Iteration  8830: accuracy_at_1 = 38.28%; accuracy_at_5 = 71.09%; loss = 2.458153  (0.696341 s/it)
Iteration  8840: accuracy_at_1 = 37.11%; accuracy_at_5 = 70.70%; loss = 2.401488  (0.697471 s/it)
Iteration  8850: accuracy_at_1 = 32.42%; accuracy_at_5 = 60.94%; loss = 2.635346  (0.698015 s/it)
Iteration  8860: accuracy_at_1 = 38.67%; accuracy_at_5 = 71.48%; loss = 2.328379  (0.697438 s/it)
Iteration  8870: accuracy_at_1 = 34.38%; accuracy_at_5 = 71.48%; loss = 2.372748  (0.697353 s/it)
Iteration  8880: accuracy_at_1 = 35.16%; accuracy_at_5 = 63.28%; loss = 2.524639  (0.697434 s/it)
Iteration  8890: accuracy_at_1 = 31.25%; accuracy_at_5 = 67.19%; loss = 2.494022  (0.697046 s/it)
Iteration  8900: accuracy_at_1 = 36.72%; accuracy_at_5 = 65.62%; loss = 2.474904  (0.697225 s/it)
Iteration  8910: accuracy_at_1 = 37.89%; accuracy_at_5 = 68.36%; loss = 2.501561  (0.696492 s/it)
Iteration  8920: accuracy_at_1 = 31.64%; accuracy_at_5 = 64.45%; loss = 2.580035  (0.696607 s/it)
Iteration  8930: accuracy_at_1 = 42.58%; accuracy_at_5 = 69.53%; loss = 2.260863  (0.696197 s/it)
Iteration  8940: accuracy_at_1 = 35.16%; accuracy_at_5 = 64.84%; loss = 2.551039  (0.696517 s/it)
Iteration  8950: accuracy_at_1 = 35.55%; accuracy_at_5 = 66.02%; loss = 2.435149  (0.696503 s/it)
Iteration  8960: accuracy_at_1 = 39.45%; accuracy_at_5 = 69.92%; loss = 2.362468  (0.696413 s/it)
Iteration  8970: accuracy_at_1 = 36.33%; accuracy_at_5 = 67.19%; loss = 2.572582  (0.697712 s/it)
Iteration  8980: accuracy_at_1 = 37.11%; accuracy_at_5 = 68.36%; loss = 2.442758  (0.697483 s/it)
Iteration  8990: accuracy_at_1 = 40.23%; accuracy_at_5 = 73.83%; loss = 2.172728  (0.698379 s/it)
Iteration  9000: accuracy_at_1 = 41.02%; accuracy_at_5 = 72.27%; loss = 2.099227  (0.697192 s/it)
Iteration  9010: accuracy_at_1 = 42.19%; accuracy_at_5 = 75.00%; loss = 2.286924  (0.697500 s/it)
Iteration  9020: accuracy_at_1 = 41.80%; accuracy_at_5 = 72.66%; loss = 2.213201  (0.697246 s/it)
Iteration  9030: accuracy_at_1 = 42.19%; accuracy_at_5 = 71.09%; loss = 2.266669  (0.695992 s/it)
Iteration  9040: accuracy_at_1 = 36.72%; accuracy_at_5 = 66.02%; loss = 2.451979  (0.696989 s/it)
Iteration  9050: accuracy_at_1 = 41.80%; accuracy_at_5 = 68.36%; loss = 2.317892  (0.695919 s/it)
Iteration  9060: accuracy_at_1 = 35.55%; accuracy_at_5 = 67.97%; loss = 2.377883  (0.695890 s/it)
Iteration  9070: accuracy_at_1 = 40.23%; accuracy_at_5 = 71.09%; loss = 2.296489  (0.696328 s/it)
Iteration  9080: accuracy_at_1 = 33.98%; accuracy_at_5 = 66.41%; loss = 2.445130  (0.695883 s/it)
Iteration  9090: accuracy_at_1 = 41.80%; accuracy_at_5 = 71.88%; loss = 2.282061  (0.696280 s/it)
Iteration  9100: accuracy_at_1 = 32.42%; accuracy_at_5 = 68.36%; loss = 2.420077  (0.697333 s/it)
Iteration  9110: accuracy_at_1 = 36.33%; accuracy_at_5 = 67.97%; loss = 2.438166  (0.697461 s/it)
Iteration  9120: accuracy_at_1 = 44.92%; accuracy_at_5 = 75.00%; loss = 2.079287  (0.697288 s/it)
Iteration  9130: accuracy_at_1 = 36.33%; accuracy_at_5 = 67.19%; loss = 2.391399  (0.697394 s/it)
Iteration  9140: accuracy_at_1 = 32.81%; accuracy_at_5 = 66.80%; loss = 2.552541  (0.697251 s/it)
Iteration  9150: accuracy_at_1 = 39.84%; accuracy_at_5 = 73.05%; loss = 2.240650  (0.698317 s/it)
Iteration  9160: accuracy_at_1 = 40.23%; accuracy_at_5 = 70.70%; loss = 2.388142  (0.696358 s/it)
Iteration  9170: accuracy_at_1 = 36.33%; accuracy_at_5 = 69.92%; loss = 2.478984  (0.696267 s/it)
Iteration  9180: accuracy_at_1 = 40.23%; accuracy_at_5 = 63.67%; loss = 2.420181  (0.696772 s/it)
Iteration  9190: accuracy_at_1 = 41.41%; accuracy_at_5 = 67.97%; loss = 2.384095  (0.696198 s/it)
Iteration  9200: accuracy_at_1 = 35.55%; accuracy_at_5 = 66.02%; loss = 2.457195  (0.696052 s/it)
Iteration  9210: accuracy_at_1 = 41.02%; accuracy_at_5 = 68.75%; loss = 2.285590  (0.695929 s/it)
Iteration  9220: accuracy_at_1 = 35.94%; accuracy_at_5 = 62.89%; loss = 2.598405  (0.696545 s/it)
Iteration  9230: accuracy_at_1 = 37.50%; accuracy_at_5 = 62.11%; loss = 2.482490  (0.697270 s/it)
Iteration  9240: accuracy_at_1 = 39.06%; accuracy_at_5 = 66.02%; loss = 2.373745  (0.697303 s/it)
Iteration  9250: accuracy_at_1 = 41.41%; accuracy_at_5 = 66.80%; loss = 2.344703  (0.697148 s/it)
Iteration  9260: accuracy_at_1 = 26.95%; accuracy_at_5 = 66.80%; loss = 2.562694  (0.697407 s/it)
Iteration  9270: accuracy_at_1 = 35.55%; accuracy_at_5 = 68.36%; loss = 2.382742  (0.696853 s/it)
Iteration  9280: accuracy_at_1 = 42.97%; accuracy_at_5 = 72.66%; loss = 2.265861  (0.697057 s/it)
Iteration  9290: accuracy_at_1 = 35.94%; accuracy_at_5 = 66.41%; loss = 2.583310  (0.696078 s/it)
Iteration  9300: accuracy_at_1 = 32.03%; accuracy_at_5 = 69.92%; loss = 2.519628  (0.696539 s/it)
Iteration  9310: accuracy_at_1 = 38.67%; accuracy_at_5 = 71.48%; loss = 2.393410  (0.696041 s/it)
Iteration  9320: accuracy_at_1 = 40.23%; accuracy_at_5 = 68.75%; loss = 2.339049  (0.696391 s/it)
Iteration  9330: accuracy_at_1 = 35.16%; accuracy_at_5 = 67.97%; loss = 2.453736  (0.696329 s/it)
Iteration  9340: accuracy_at_1 = 36.33%; accuracy_at_5 = 71.09%; loss = 2.313814  (0.696104 s/it)
Iteration  9350: accuracy_at_1 = 38.28%; accuracy_at_5 = 66.80%; loss = 2.352420  (0.697164 s/it)
Iteration  9360: accuracy_at_1 = 35.16%; accuracy_at_5 = 63.28%; loss = 2.592269  (0.697358 s/it)
Iteration  9370: accuracy_at_1 = 35.55%; accuracy_at_5 = 63.67%; loss = 2.549984  (0.697784 s/it)
Iteration  9380: accuracy_at_1 = 43.36%; accuracy_at_5 = 70.70%; loss = 2.203374  (0.698305 s/it)
Iteration  9390: accuracy_at_1 = 41.80%; accuracy_at_5 = 75.39%; loss = 2.156957  (0.697032 s/it)
Iteration  9400: accuracy_at_1 = 42.97%; accuracy_at_5 = 75.78%; loss = 2.200865  (0.697182 s/it)
Iteration  9410: accuracy_at_1 = 42.58%; accuracy_at_5 = 73.44%; loss = 2.094749  (0.696988 s/it)
Iteration  9420: accuracy_at_1 = 35.16%; accuracy_at_5 = 67.19%; loss = 2.387338  (0.696170 s/it)
Iteration  9430: accuracy_at_1 = 39.84%; accuracy_at_5 = 66.41%; loss = 2.457355  (0.696001 s/it)
Iteration  9440: accuracy_at_1 = 40.62%; accuracy_at_5 = 71.09%; loss = 2.240447  (0.696812 s/it)
Iteration  9450: accuracy_at_1 = 42.97%; accuracy_at_5 = 76.17%; loss = 2.042426  (0.695519 s/it)
Iteration  9460: accuracy_at_1 = 41.02%; accuracy_at_5 = 68.36%; loss = 2.268218  (0.696199 s/it)
Iteration  9470: accuracy_at_1 = 39.84%; accuracy_at_5 = 68.75%; loss = 2.310420  (0.696377 s/it)
Iteration  9480: accuracy_at_1 = 39.84%; accuracy_at_5 = 72.66%; loss = 2.238086  (0.698098 s/it)
Iteration  9490: accuracy_at_1 = 36.72%; accuracy_at_5 = 67.58%; loss = 2.381079  (0.698132 s/it)
Iteration  9500: accuracy_at_1 = 38.28%; accuracy_at_5 = 72.66%; loss = 2.364455  (0.697401 s/it)
Iteration  9510: accuracy_at_1 = 37.11%; accuracy_at_5 = 71.09%; loss = 2.279634  (0.697606 s/it)
Iteration  9520: accuracy_at_1 = 33.59%; accuracy_at_5 = 66.80%; loss = 2.455728  (0.697558 s/it)
Iteration  9530: accuracy_at_1 = 34.77%; accuracy_at_5 = 67.58%; loss = 2.412640  (0.697516 s/it)
Iteration  9540: accuracy_at_1 = 38.28%; accuracy_at_5 = 69.92%; loss = 2.275295  (0.696594 s/it)
Iteration  9550: accuracy_at_1 = 36.33%; accuracy_at_5 = 67.19%; loss = 2.462809  (0.696147 s/it)
Iteration  9560: accuracy_at_1 = 36.72%; accuracy_at_5 = 72.27%; loss = 2.305591  (0.696697 s/it)
Iteration  9570: accuracy_at_1 = 39.45%; accuracy_at_5 = 70.70%; loss = 2.330732  (0.695197 s/it)
Iteration  9580: accuracy_at_1 = 41.80%; accuracy_at_5 = 66.80%; loss = 2.379591  (0.696002 s/it)
Iteration  9590: accuracy_at_1 = 43.36%; accuracy_at_5 = 72.66%; loss = 2.243479  (0.696730 s/it)
Iteration  9600: accuracy_at_1 = 32.42%; accuracy_at_5 = 63.28%; loss = 2.566735  (0.696544 s/it)
Iteration  9610: accuracy_at_1 = 36.72%; accuracy_at_5 = 69.92%; loss = 2.337550  (0.697331 s/it)
Iteration  9620: accuracy_at_1 = 38.28%; accuracy_at_5 = 69.92%; loss = 2.389434  (0.697947 s/it)
Iteration  9630: accuracy_at_1 = 36.33%; accuracy_at_5 = 67.58%; loss = 2.381896  (0.697641 s/it)
Iteration  9640: accuracy_at_1 = 38.67%; accuracy_at_5 = 71.09%; loss = 2.363714  (0.697804 s/it)
Iteration  9650: accuracy_at_1 = 35.94%; accuracy_at_5 = 68.36%; loss = 2.343376  (0.697224 s/it)
Iteration  9660: accuracy_at_1 = 39.45%; accuracy_at_5 = 69.14%; loss = 2.261908  (0.697025 s/it)
Iteration  9670: accuracy_at_1 = 33.59%; accuracy_at_5 = 67.58%; loss = 2.515474  (0.696763 s/it)
Iteration  9680: accuracy_at_1 = 30.86%; accuracy_at_5 = 59.38%; loss = 2.756628  (0.696267 s/it)
Iteration  9690: accuracy_at_1 = 34.77%; accuracy_at_5 = 68.36%; loss = 2.455487  (0.696005 s/it)
Iteration  9700: accuracy_at_1 = 38.28%; accuracy_at_5 = 64.45%; loss = 2.597771  (0.696049 s/it)
Iteration  9710: accuracy_at_1 = 36.33%; accuracy_at_5 = 71.48%; loss = 2.349118  (0.696929 s/it)
Iteration  9720: accuracy_at_1 = 40.23%; accuracy_at_5 = 67.97%; loss = 2.387700  (0.696231 s/it)
Iteration  9730: accuracy_at_1 = 34.38%; accuracy_at_5 = 64.84%; loss = 2.577059  (0.697288 s/it)
Iteration  9740: accuracy_at_1 = 30.86%; accuracy_at_5 = 64.84%; loss = 2.668770  (0.698859 s/it)
Iteration  9750: accuracy_at_1 = 34.77%; accuracy_at_5 = 63.28%; loss = 2.523987  (0.697151 s/it)
Iteration  9760: accuracy_at_1 = 34.77%; accuracy_at_5 = 71.88%; loss = 2.441988  (0.697380 s/it)
Iteration  9770: accuracy_at_1 = 46.48%; accuracy_at_5 = 75.78%; loss = 2.082250  (0.698622 s/it)
Iteration  9780: accuracy_at_1 = 42.58%; accuracy_at_5 = 73.83%; loss = 2.195024  (0.697571 s/it)
Iteration  9790: accuracy_at_1 = 37.50%; accuracy_at_5 = 71.48%; loss = 2.363411  (0.697224 s/it)
Iteration  9800: accuracy_at_1 = 41.80%; accuracy_at_5 = 75.39%; loss = 2.108531  (0.696154 s/it)
Iteration  9810: accuracy_at_1 = 42.19%; accuracy_at_5 = 70.70%; loss = 2.240209  (0.697113 s/it)
Iteration  9820: accuracy_at_1 = 40.62%; accuracy_at_5 = 73.83%; loss = 2.162946  (0.695834 s/it)
Iteration  9830: accuracy_at_1 = 44.53%; accuracy_at_5 = 72.66%; loss = 2.145338  (0.697153 s/it)
Iteration  9840: accuracy_at_1 = 37.50%; accuracy_at_5 = 70.70%; loss = 2.288720  (0.695790 s/it)
Iteration  9850: accuracy_at_1 = 35.16%; accuracy_at_5 = 73.83%; loss = 2.286788  (0.696081 s/it)
Iteration  9860: accuracy_at_1 = 42.19%; accuracy_at_5 = 69.14%; loss = 2.144292  (0.697149 s/it)
Iteration  9870: accuracy_at_1 = 36.72%; accuracy_at_5 = 73.44%; loss = 2.271575  (0.697407 s/it)
Iteration  9880: accuracy_at_1 = 49.22%; accuracy_at_5 = 73.44%; loss = 1.925132  (0.697380 s/it)
Iteration  9890: accuracy_at_1 = 35.16%; accuracy_at_5 = 67.97%; loss = 2.438121  (0.697682 s/it)
Iteration  9900: accuracy_at_1 = 36.72%; accuracy_at_5 = 71.48%; loss = 2.337680  (0.697649 s/it)
Iteration  9910: accuracy_at_1 = 37.11%; accuracy_at_5 = 71.48%; loss = 2.327357  (0.696831 s/it)
Iteration  9920: accuracy_at_1 = 39.84%; accuracy_at_5 = 73.44%; loss = 2.208444  (0.697305 s/it)
Iteration  9930: accuracy_at_1 = 43.36%; accuracy_at_5 = 75.78%; loss = 2.015690  (0.696098 s/it)
Iteration  9940: accuracy_at_1 = 39.84%; accuracy_at_5 = 72.27%; loss = 2.244613  (0.696593 s/it)
Iteration  9950: accuracy_at_1 = 32.42%; accuracy_at_5 = 67.19%; loss = 2.628818  (0.696297 s/it)
Iteration  9960: accuracy_at_1 = 36.72%; accuracy_at_5 = 70.70%; loss = 2.388679  (0.695576 s/it)
Iteration  9970: accuracy_at_1 = 34.38%; accuracy_at_5 = 73.44%; loss = 2.261019  (0.696084 s/it)
Iteration  9980: accuracy_at_1 = 39.45%; accuracy_at_5 = 70.31%; loss = 2.356406  (0.696227 s/it)
Iteration  9990: accuracy_at_1 = 28.52%; accuracy_at_5 = 60.55%; loss = 2.723614  (0.697764 s/it)
Iteration 10000: accuracy_at_1 = 37.50%; accuracy_at_5 = 69.53%; loss = 2.324447  (0.725320 s/it)
Iteration 10010: accuracy_at_1 = 32.42%; accuracy_at_5 = 66.41%; loss = 2.619439  (0.700648 s/it)
Iteration 10020: accuracy_at_1 = 36.33%; accuracy_at_5 = 68.36%; loss = 2.358478  (0.701603 s/it)
Iteration 10030: accuracy_at_1 = 41.02%; accuracy_at_5 = 73.05%; loss = 2.250729  (0.701844 s/it)
Iteration 10040: accuracy_at_1 = 39.84%; accuracy_at_5 = 69.14%; loss = 2.323317  (0.701591 s/it)
Iteration 10050: accuracy_at_1 = 39.45%; accuracy_at_5 = 71.48%; loss = 2.201354  (0.701790 s/it)
Iteration 10060: accuracy_at_1 = 40.62%; accuracy_at_5 = 74.22%; loss = 2.158383  (0.700590 s/it)
Iteration 10070: accuracy_at_1 = 39.84%; accuracy_at_5 = 66.80%; loss = 2.334142  (0.700184 s/it)
Iteration 10080: accuracy_at_1 = 45.31%; accuracy_at_5 = 78.52%; loss = 2.013711  (0.700706 s/it)
Iteration 10090: accuracy_at_1 = 43.36%; accuracy_at_5 = 73.05%; loss = 2.106769  (0.700095 s/it)
Iteration 10100: accuracy_at_1 = 40.62%; accuracy_at_5 = 70.31%; loss = 2.214817  (0.700526 s/it)
Iteration 10110: accuracy_at_1 = 37.89%; accuracy_at_5 = 69.92%; loss = 2.341531  (0.700293 s/it)
Iteration 10120: accuracy_at_1 = 40.62%; accuracy_at_5 = 74.22%; loss = 2.217295  (0.701872 s/it)
Iteration 10130: accuracy_at_1 = 41.02%; accuracy_at_5 = 76.95%; loss = 2.080925  (0.701663 s/it)
Iteration 10140: accuracy_at_1 = 42.97%; accuracy_at_5 = 73.05%; loss = 2.136261  (0.701434 s/it)
Iteration 10150: accuracy_at_1 = 45.31%; accuracy_at_5 = 77.73%; loss = 1.927131  (0.701633 s/it)
Iteration 10160: accuracy_at_1 = 50.78%; accuracy_at_5 = 76.56%; loss = 1.787249  (0.702972 s/it)
Iteration 10170: accuracy_at_1 = 49.22%; accuracy_at_5 = 82.81%; loss = 1.762623  (0.701742 s/it)
Iteration 10180: accuracy_at_1 = 47.27%; accuracy_at_5 = 79.30%; loss = 1.809367  (0.701136 s/it)
Iteration 10190: accuracy_at_1 = 42.19%; accuracy_at_5 = 76.95%; loss = 1.935854  (0.700205 s/it)
Iteration 10200: accuracy_at_1 = 51.17%; accuracy_at_5 = 76.95%; loss = 1.790139  (0.699810 s/it)
Iteration 10210: accuracy_at_1 = 55.86%; accuracy_at_5 = 80.86%; loss = 1.679204  (0.700028 s/it)
Iteration 10220: accuracy_at_1 = 55.47%; accuracy_at_5 = 80.86%; loss = 1.726821  (0.699788 s/it)
Iteration 10230: accuracy_at_1 = 55.86%; accuracy_at_5 = 82.81%; loss = 1.568375  (0.700371 s/it)
Iteration 10240: accuracy_at_1 = 53.12%; accuracy_at_5 = 81.64%; loss = 1.714700  (0.701141 s/it)
Iteration 10250: accuracy_at_1 = 45.70%; accuracy_at_5 = 76.17%; loss = 1.963751  (0.701291 s/it)
Iteration 10260: accuracy_at_1 = 53.91%; accuracy_at_5 = 81.25%; loss = 1.716674  (0.701167 s/it)
Iteration 10270: accuracy_at_1 = 46.09%; accuracy_at_5 = 80.86%; loss = 1.887108  (0.701235 s/it)
Iteration 10280: accuracy_at_1 = 55.08%; accuracy_at_5 = 83.59%; loss = 1.659477  (0.701183 s/it)
Iteration 10290: accuracy_at_1 = 46.88%; accuracy_at_5 = 76.17%; loss = 1.869116  (0.701562 s/it)
Iteration 10300: accuracy_at_1 = 48.44%; accuracy_at_5 = 77.73%; loss = 1.870678  (0.702690 s/it)
Iteration 10310: accuracy_at_1 = 52.73%; accuracy_at_5 = 82.03%; loss = 1.715338  (0.700254 s/it)
Iteration 10320: accuracy_at_1 = 50.78%; accuracy_at_5 = 78.52%; loss = 1.879519  (0.699818 s/it)
Iteration 10330: accuracy_at_1 = 50.00%; accuracy_at_5 = 80.08%; loss = 1.746162  (0.700695 s/it)
Iteration 10340: accuracy_at_1 = 50.39%; accuracy_at_5 = 78.52%; loss = 1.859859  (0.700460 s/it)
Iteration 10350: accuracy_at_1 = 53.52%; accuracy_at_5 = 81.25%; loss = 1.680388  (0.700560 s/it)
Iteration 10360: accuracy_at_1 = 51.56%; accuracy_at_5 = 81.64%; loss = 1.750228  (0.700134 s/it)
Iteration 10370: accuracy_at_1 = 50.39%; accuracy_at_5 = 76.95%; loss = 1.871030  (0.701405 s/it)
Iteration 10380: accuracy_at_1 = 55.86%; accuracy_at_5 = 82.81%; loss = 1.669877  (0.701492 s/it)
Iteration 10390: accuracy_at_1 = 49.22%; accuracy_at_5 = 82.03%; loss = 1.717284  (0.701741 s/it)
Iteration 10400: accuracy_at_1 = 51.95%; accuracy_at_5 = 79.69%; loss = 1.741330  (0.701646 s/it)
Iteration 10410: accuracy_at_1 = 50.78%; accuracy_at_5 = 82.03%; loss = 1.698853  (0.701373 s/it)
Iteration 10420: accuracy_at_1 = 47.66%; accuracy_at_5 = 79.30%; loss = 1.990733  (0.700899 s/it)
Iteration 10430: accuracy_at_1 = 54.30%; accuracy_at_5 = 82.42%; loss = 1.628589  (0.701314 s/it)
Iteration 10440: accuracy_at_1 = 52.73%; accuracy_at_5 = 80.08%; loss = 1.659665  (0.700242 s/it)
Iteration 10450: accuracy_at_1 = 56.64%; accuracy_at_5 = 80.08%; loss = 1.685051  (0.700567 s/it)
Iteration 10460: accuracy_at_1 = 49.22%; accuracy_at_5 = 82.03%; loss = 1.695135  (0.700668 s/it)
Iteration 10470: accuracy_at_1 = 53.91%; accuracy_at_5 = 83.98%; loss = 1.690046  (0.700980 s/it)
Iteration 10480: accuracy_at_1 = 55.47%; accuracy_at_5 = 82.42%; loss = 1.682626  (0.700344 s/it)
Iteration 10490: accuracy_at_1 = 51.95%; accuracy_at_5 = 83.20%; loss = 1.658363  (0.700820 s/it)
Iteration 10500: accuracy_at_1 = 48.83%; accuracy_at_5 = 79.30%; loss = 1.816864  (0.701278 s/it)
Iteration 10510: accuracy_at_1 = 53.52%; accuracy_at_5 = 81.64%; loss = 1.731008  (0.701384 s/it)
Iteration 10520: accuracy_at_1 = 51.17%; accuracy_at_5 = 84.38%; loss = 1.640993  (0.701405 s/it)
Iteration 10530: accuracy_at_1 = 51.56%; accuracy_at_5 = 83.59%; loss = 1.639501  (0.701232 s/it)
Iteration 10540: accuracy_at_1 = 49.22%; accuracy_at_5 = 81.25%; loss = 1.703111  (0.701584 s/it)
Iteration 10550: accuracy_at_1 = 54.69%; accuracy_at_5 = 83.59%; loss = 1.522007  (0.703031 s/it)
Iteration 10560: accuracy_at_1 = 60.16%; accuracy_at_5 = 88.67%; loss = 1.413393  (0.701515 s/it)
Iteration 10570: accuracy_at_1 = 57.03%; accuracy_at_5 = 83.59%; loss = 1.562018  (0.700579 s/it)
Iteration 10580: accuracy_at_1 = 48.05%; accuracy_at_5 = 84.38%; loss = 1.705715  (0.700416 s/it)
Iteration 10590: accuracy_at_1 = 56.25%; accuracy_at_5 = 80.08%; loss = 1.640478  (0.700729 s/it)
Iteration 10600: accuracy_at_1 = 51.95%; accuracy_at_5 = 78.52%; loss = 1.661001  (0.700250 s/it)
Iteration 10610: accuracy_at_1 = 53.52%; accuracy_at_5 = 83.59%; loss = 1.661603  (0.700912 s/it)
Iteration 10620: accuracy_at_1 = 55.08%; accuracy_at_5 = 81.64%; loss = 1.634385  (0.699913 s/it)
Iteration 10630: accuracy_at_1 = 57.42%; accuracy_at_5 = 83.59%; loss = 1.527543  (0.701494 s/it)
Iteration 10640: accuracy_at_1 = 56.25%; accuracy_at_5 = 85.16%; loss = 1.519358  (0.701224 s/it)
Iteration 10650: accuracy_at_1 = 57.42%; accuracy_at_5 = 85.55%; loss = 1.554269  (0.701250 s/it)
Iteration 10660: accuracy_at_1 = 55.47%; accuracy_at_5 = 78.52%; loss = 1.730909  (0.701416 s/it)
Iteration 10670: accuracy_at_1 = 50.78%; accuracy_at_5 = 85.55%; loss = 1.595800  (0.701627 s/it)
Iteration 10680: accuracy_at_1 = 55.47%; accuracy_at_5 = 82.03%; loss = 1.679396  (0.701722 s/it)
Iteration 10690: accuracy_at_1 = 53.91%; accuracy_at_5 = 84.77%; loss = 1.554442  (0.700834 s/it)
Iteration 10700: accuracy_at_1 = 55.86%; accuracy_at_5 = 84.38%; loss = 1.568592  (0.699710 s/it)
Iteration 10710: accuracy_at_1 = 53.91%; accuracy_at_5 = 87.11%; loss = 1.606028  (0.700079 s/it)
Iteration 10720: accuracy_at_1 = 58.20%; accuracy_at_5 = 84.77%; loss = 1.470427  (0.699877 s/it)
Iteration 10730: accuracy_at_1 = 53.52%; accuracy_at_5 = 84.77%; loss = 1.561198  (0.700088 s/it)
Iteration 10740: accuracy_at_1 = 51.95%; accuracy_at_5 = 82.81%; loss = 1.653615  (0.700149 s/it)
Iteration 10750: accuracy_at_1 = 59.38%; accuracy_at_5 = 84.77%; loss = 1.466685  (0.700928 s/it)
Iteration 10760: accuracy_at_1 = 51.17%; accuracy_at_5 = 83.59%; loss = 1.671534  (0.701681 s/it)
Iteration 10770: accuracy_at_1 = 58.20%; accuracy_at_5 = 82.42%; loss = 1.595560  (0.701559 s/it)
Iteration 10780: accuracy_at_1 = 51.95%; accuracy_at_5 = 81.64%; loss = 1.678162  (0.701523 s/it)
Iteration 10790: accuracy_at_1 = 54.30%; accuracy_at_5 = 81.64%; loss = 1.635763  (0.702224 s/it)
Iteration 10800: accuracy_at_1 = 55.86%; accuracy_at_5 = 85.94%; loss = 1.518427  (0.701776 s/it)
Iteration 10810: accuracy_at_1 = 54.69%; accuracy_at_5 = 87.11%; loss = 1.454804  (0.702057 s/it)
Iteration 10820: accuracy_at_1 = 57.81%; accuracy_at_5 = 85.94%; loss = 1.457037  (0.700927 s/it)
Iteration 10830: accuracy_at_1 = 53.52%; accuracy_at_5 = 80.47%; loss = 1.649862  (0.700092 s/it)
Iteration 10840: accuracy_at_1 = 49.22%; accuracy_at_5 = 77.34%; loss = 1.829052  (0.700740 s/it)
Iteration 10850: accuracy_at_1 = 53.52%; accuracy_at_5 = 82.03%; loss = 1.665837  (0.702057 s/it)
Iteration 10860: accuracy_at_1 = 61.72%; accuracy_at_5 = 88.28%; loss = 1.376671  (0.700535 s/it)
Iteration 10870: accuracy_at_1 = 52.73%; accuracy_at_5 = 82.42%; loss = 1.696889  (0.701017 s/it)
Iteration 10880: accuracy_at_1 = 53.12%; accuracy_at_5 = 85.16%; loss = 1.606337  (0.701194 s/it)
Iteration 10890: accuracy_at_1 = 55.86%; accuracy_at_5 = 85.94%; loss = 1.506549  (0.701352 s/it)
Iteration 10900: accuracy_at_1 = 52.73%; accuracy_at_5 = 84.38%; loss = 1.610147  (0.702222 s/it)
Iteration 10910: accuracy_at_1 = 62.89%; accuracy_at_5 = 87.11%; loss = 1.407822  (0.701471 s/it)
Iteration 10920: accuracy_at_1 = 52.34%; accuracy_at_5 = 81.25%; loss = 1.568707  (0.701812 s/it)
Iteration 10930: accuracy_at_1 = 56.64%; accuracy_at_5 = 81.64%; loss = 1.595058  (0.701540 s/it)
Iteration 10940: accuracy_at_1 = 59.77%; accuracy_at_5 = 87.50%; loss = 1.334056  (0.702434 s/it)
Iteration 10950: accuracy_at_1 = 56.25%; accuracy_at_5 = 84.77%; loss = 1.535606  (0.700781 s/it)
Iteration 10960: accuracy_at_1 = 60.94%; accuracy_at_5 = 88.28%; loss = 1.311319  (0.700587 s/it)
Iteration 10970: accuracy_at_1 = 62.50%; accuracy_at_5 = 89.06%; loss = 1.311654  (0.699960 s/it)
Iteration 10980: accuracy_at_1 = 56.64%; accuracy_at_5 = 85.16%; loss = 1.513108  (0.699861 s/it)
Iteration 10990: accuracy_at_1 = 54.69%; accuracy_at_5 = 85.94%; loss = 1.548106  (0.700566 s/it)
Iteration 11000: accuracy_at_1 = 53.52%; accuracy_at_5 = 84.77%; loss = 1.609807  (0.700369 s/it)
Iteration 11010: accuracy_at_1 = 54.30%; accuracy_at_5 = 85.16%; loss = 1.571414  (0.701086 s/it)
Iteration 11020: accuracy_at_1 = 60.16%; accuracy_at_5 = 86.72%; loss = 1.417065  (0.701741 s/it)
Iteration 11030: accuracy_at_1 = 55.86%; accuracy_at_5 = 85.94%; loss = 1.458893  (0.701516 s/it)
Iteration 11040: accuracy_at_1 = 60.16%; accuracy_at_5 = 91.41%; loss = 1.341295  (0.700938 s/it)
Iteration 11050: accuracy_at_1 = 51.56%; accuracy_at_5 = 84.77%; loss = 1.635812  (0.701390 s/it)
Iteration 11060: accuracy_at_1 = 57.42%; accuracy_at_5 = 87.11%; loss = 1.381292  (0.701567 s/it)
Iteration 11070: accuracy_at_1 = 56.64%; accuracy_at_5 = 82.03%; loss = 1.523757  (0.701403 s/it)
Iteration 11080: accuracy_at_1 = 53.91%; accuracy_at_5 = 84.77%; loss = 1.537047  (0.700745 s/it)
Iteration 11090: accuracy_at_1 = 53.91%; accuracy_at_5 = 84.77%; loss = 1.557208  (0.700971 s/it)
Iteration 11100: accuracy_at_1 = 58.98%; accuracy_at_5 = 84.77%; loss = 1.409593  (0.700238 s/it)
Iteration 11110: accuracy_at_1 = 58.59%; accuracy_at_5 = 90.23%; loss = 1.287280  (0.700955 s/it)
Iteration 11120: accuracy_at_1 = 51.95%; accuracy_at_5 = 89.06%; loss = 1.421477  (0.700287 s/it)
Iteration 11130: accuracy_at_1 = 61.72%; accuracy_at_5 = 84.77%; loss = 1.347213  (0.701097 s/it)
Iteration 11140: accuracy_at_1 = 58.98%; accuracy_at_5 = 87.11%; loss = 1.408154  (0.701307 s/it)
Iteration 11150: accuracy_at_1 = 52.73%; accuracy_at_5 = 87.50%; loss = 1.509858  (0.701282 s/it)
Iteration 11160: accuracy_at_1 = 55.47%; accuracy_at_5 = 86.72%; loss = 1.510777  (0.702455 s/it)
Iteration 11170: accuracy_at_1 = 60.16%; accuracy_at_5 = 87.89%; loss = 1.336955  (0.702195 s/it)
Iteration 11180: accuracy_at_1 = 55.47%; accuracy_at_5 = 83.20%; loss = 1.581318  (0.700964 s/it)
Iteration 11190: accuracy_at_1 = 58.59%; accuracy_at_5 = 83.59%; loss = 1.466213  (0.701748 s/it)
Iteration 11200: accuracy_at_1 = 51.95%; accuracy_at_5 = 85.94%; loss = 1.573879  (0.701160 s/it)
Iteration 11210: accuracy_at_1 = 60.55%; accuracy_at_5 = 85.94%; loss = 1.437418  (0.701118 s/it)
Iteration 11220: accuracy_at_1 = 60.16%; accuracy_at_5 = 85.16%; loss = 1.426888  (0.700187 s/it)
Iteration 11230: accuracy_at_1 = 53.91%; accuracy_at_5 = 84.77%; loss = 1.577666  (0.700438 s/it)
Iteration 11240: accuracy_at_1 = 62.50%; accuracy_at_5 = 88.67%; loss = 1.330256  (0.700331 s/it)
Iteration 11250: accuracy_at_1 = 58.59%; accuracy_at_5 = 82.03%; loss = 1.428522  (0.700217 s/it)
Iteration 11260: accuracy_at_1 = 60.16%; accuracy_at_5 = 87.89%; loss = 1.372982  (0.700260 s/it)
Iteration 11270: accuracy_at_1 = 54.69%; accuracy_at_5 = 83.59%; loss = 1.627190  (0.701601 s/it)
Iteration 11280: accuracy_at_1 = 58.98%; accuracy_at_5 = 88.67%; loss = 1.332662  (0.702250 s/it)
Iteration 11290: accuracy_at_1 = 59.38%; accuracy_at_5 = 85.55%; loss = 1.409917  (0.701543 s/it)
Iteration 11300: accuracy_at_1 = 64.06%; accuracy_at_5 = 89.06%; loss = 1.286407  (0.701123 s/it)
Iteration 11310: accuracy_at_1 = 57.81%; accuracy_at_5 = 87.11%; loss = 1.450950  (0.701657 s/it)
Iteration 11320: accuracy_at_1 = 58.98%; accuracy_at_5 = 87.11%; loss = 1.431605  (0.701584 s/it)
Iteration 11330: accuracy_at_1 = 60.16%; accuracy_at_5 = 87.11%; loss = 1.390580  (0.702613 s/it)
Iteration 11340: accuracy_at_1 = 57.42%; accuracy_at_5 = 87.89%; loss = 1.390379  (0.700985 s/it)
Iteration 11350: accuracy_at_1 = 59.38%; accuracy_at_5 = 89.06%; loss = 1.319500  (0.700337 s/it)
Iteration 11360: accuracy_at_1 = 62.11%; accuracy_at_5 = 91.02%; loss = 1.189700  (0.700501 s/it)
Iteration 11370: accuracy_at_1 = 60.55%; accuracy_at_5 = 85.55%; loss = 1.434868  (0.700643 s/it)
Iteration 11380: accuracy_at_1 = 57.42%; accuracy_at_5 = 87.11%; loss = 1.457482  (0.700106 s/it)
Iteration 11390: accuracy_at_1 = 54.30%; accuracy_at_5 = 88.28%; loss = 1.480103  (0.700718 s/it)
Iteration 11400: accuracy_at_1 = 58.98%; accuracy_at_5 = 88.28%; loss = 1.358272  (0.702642 s/it)
Iteration 11410: accuracy_at_1 = 56.25%; accuracy_at_5 = 85.16%; loss = 1.514039  (0.702023 s/it)
Iteration 11420: accuracy_at_1 = 64.06%; accuracy_at_5 = 89.06%; loss = 1.275224  (0.701533 s/it)
Iteration 11430: accuracy_at_1 = 60.16%; accuracy_at_5 = 83.59%; loss = 1.354351  (0.701924 s/it)
Iteration 11440: accuracy_at_1 = 63.67%; accuracy_at_5 = 86.72%; loss = 1.354370  (0.701183 s/it)
Iteration 11450: accuracy_at_1 = 53.52%; accuracy_at_5 = 85.94%; loss = 1.475434  (0.701360 s/it)
Iteration 11460: accuracy_at_1 = 60.16%; accuracy_at_5 = 85.55%; loss = 1.449706  (0.700384 s/it)
Iteration 11470: accuracy_at_1 = 61.33%; accuracy_at_5 = 86.72%; loss = 1.414177  (0.700169 s/it)
Iteration 11480: accuracy_at_1 = 61.33%; accuracy_at_5 = 89.06%; loss = 1.326575  (0.700336 s/it)
Iteration 11490: accuracy_at_1 = 60.55%; accuracy_at_5 = 90.23%; loss = 1.236214  (0.701027 s/it)
Iteration 11500: accuracy_at_1 = 57.81%; accuracy_at_5 = 86.72%; loss = 1.430280  (0.699890 s/it)
Iteration 11510: accuracy_at_1 = 62.11%; accuracy_at_5 = 85.94%; loss = 1.375395  (0.699950 s/it)
Iteration 11520: accuracy_at_1 = 65.23%; accuracy_at_5 = 89.06%; loss = 1.256424  (0.700504 s/it)
Iteration 11530: accuracy_at_1 = 57.03%; accuracy_at_5 = 84.38%; loss = 1.449640  (0.702258 s/it)
Iteration 11540: accuracy_at_1 = 56.25%; accuracy_at_5 = 85.94%; loss = 1.466187  (0.701357 s/it)
Iteration 11550: accuracy_at_1 = 57.81%; accuracy_at_5 = 83.98%; loss = 1.535216  (0.701462 s/it)
Iteration 11560: accuracy_at_1 = 61.72%; accuracy_at_5 = 88.28%; loss = 1.361673  (0.701939 s/it)
Iteration 11570: accuracy_at_1 = 58.20%; accuracy_at_5 = 84.77%; loss = 1.444341  (0.701067 s/it)
Iteration 11580: accuracy_at_1 = 61.72%; accuracy_at_5 = 85.55%; loss = 1.312804  (0.701386 s/it)
Iteration 11590: accuracy_at_1 = 56.64%; accuracy_at_5 = 86.72%; loss = 1.335904  (0.699924 s/it)
Iteration 11600: accuracy_at_1 = 59.38%; accuracy_at_5 = 86.33%; loss = 1.318290  (0.699884 s/it)
Iteration 11610: accuracy_at_1 = 62.11%; accuracy_at_5 = 86.33%; loss = 1.314895  (0.699816 s/it)
Iteration 11620: accuracy_at_1 = 63.28%; accuracy_at_5 = 86.72%; loss = 1.353181  (0.700046 s/it)
Iteration 11630: accuracy_at_1 = 54.30%; accuracy_at_5 = 85.16%; loss = 1.472232  (0.699827 s/it)
Iteration 11640: accuracy_at_1 = 66.80%; accuracy_at_5 = 89.45%; loss = 1.197321  (0.699881 s/it)
Iteration 11650: accuracy_at_1 = 62.50%; accuracy_at_5 = 90.23%; loss = 1.227114  (0.701144 s/it)
Iteration 11660: accuracy_at_1 = 60.55%; accuracy_at_5 = 87.11%; loss = 1.340807  (0.701865 s/it)
Iteration 11670: accuracy_at_1 = 52.34%; accuracy_at_5 = 87.50%; loss = 1.455979  (0.701918 s/it)
Iteration 11680: accuracy_at_1 = 56.25%; accuracy_at_5 = 86.33%; loss = 1.520055  (0.701117 s/it)
Iteration 11690: accuracy_at_1 = 63.28%; accuracy_at_5 = 89.06%; loss = 1.213546  (0.701572 s/it)
Iteration 11700: accuracy_at_1 = 56.25%; accuracy_at_5 = 87.11%; loss = 1.403600  (0.701632 s/it)
Iteration 11710: accuracy_at_1 = 62.50%; accuracy_at_5 = 88.28%; loss = 1.262368  (0.701217 s/it)
Iteration 11720: accuracy_at_1 = 57.03%; accuracy_at_5 = 84.38%; loss = 1.494764  (0.701559 s/it)
Iteration 11730: accuracy_at_1 = 63.28%; accuracy_at_5 = 89.45%; loss = 1.171096  (0.700147 s/it)
Iteration 11740: accuracy_at_1 = 59.77%; accuracy_at_5 = 89.84%; loss = 1.289758  (0.699909 s/it)
Iteration 11750: accuracy_at_1 = 61.33%; accuracy_at_5 = 89.06%; loss = 1.337747  (0.700234 s/it)
Iteration 11760: accuracy_at_1 = 66.02%; accuracy_at_5 = 89.06%; loss = 1.213632  (0.701077 s/it)
Iteration 11770: accuracy_at_1 = 61.72%; accuracy_at_5 = 90.62%; loss = 1.148171  (0.700396 s/it)
Iteration 11780: accuracy_at_1 = 60.55%; accuracy_at_5 = 86.33%; loss = 1.339928  (0.701454 s/it)
Iteration 11790: accuracy_at_1 = 58.98%; accuracy_at_5 = 86.72%; loss = 1.410443  (0.701049 s/it)
Iteration 11800: accuracy_at_1 = 55.08%; accuracy_at_5 = 87.50%; loss = 1.374037  (0.701548 s/it)
Iteration 11810: accuracy_at_1 = 65.23%; accuracy_at_5 = 88.28%; loss = 1.242878  (0.701003 s/it)
Iteration 11820: accuracy_at_1 = 61.72%; accuracy_at_5 = 85.55%; loss = 1.289442  (0.701183 s/it)
Iteration 11830: accuracy_at_1 = 61.33%; accuracy_at_5 = 89.06%; loss = 1.233307  (0.701484 s/it)
Iteration 11840: accuracy_at_1 = 62.11%; accuracy_at_5 = 86.72%; loss = 1.336791  (0.701183 s/it)
Iteration 11850: accuracy_at_1 = 58.59%; accuracy_at_5 = 85.94%; loss = 1.338477  (0.700296 s/it)
Iteration 11860: accuracy_at_1 = 64.06%; accuracy_at_5 = 88.67%; loss = 1.139797  (0.700723 s/it)
Iteration 11870: accuracy_at_1 = 59.77%; accuracy_at_5 = 86.33%; loss = 1.327515  (0.700620 s/it)
Iteration 11880: accuracy_at_1 = 58.98%; accuracy_at_5 = 89.84%; loss = 1.331501  (0.700668 s/it)
Iteration 11890: accuracy_at_1 = 65.23%; accuracy_at_5 = 90.62%; loss = 1.163829  (0.701273 s/it)
Iteration 11900: accuracy_at_1 = 63.67%; accuracy_at_5 = 89.45%; loss = 1.248049  (0.700183 s/it)
Iteration 11910: accuracy_at_1 = 62.89%; accuracy_at_5 = 89.45%; loss = 1.220475  (0.701065 s/it)
Iteration 11920: accuracy_at_1 = 66.80%; accuracy_at_5 = 91.80%; loss = 1.116161  (0.701158 s/it)
Iteration 11930: accuracy_at_1 = 63.28%; accuracy_at_5 = 91.80%; loss = 1.220971  (0.701223 s/it)
Iteration 11940: accuracy_at_1 = 64.06%; accuracy_at_5 = 87.50%; loss = 1.266699  (0.701630 s/it)
Iteration 11950: accuracy_at_1 = 63.67%; accuracy_at_5 = 89.84%; loss = 1.170583  (0.702116 s/it)
Iteration 11960: accuracy_at_1 = 60.94%; accuracy_at_5 = 90.62%; loss = 1.226889  (0.703455 s/it)
Iteration 11970: accuracy_at_1 = 59.77%; accuracy_at_5 = 89.06%; loss = 1.339713  (0.700809 s/it)
Iteration 11980: accuracy_at_1 = 56.64%; accuracy_at_5 = 84.77%; loss = 1.450792  (0.700697 s/it)
Iteration 11990: accuracy_at_1 = 62.89%; accuracy_at_5 = 90.62%; loss = 1.235194  (0.700387 s/it)
Iteration 12000: accuracy_at_1 = 67.58%; accuracy_at_5 = 91.80%; loss = 1.122500  (0.699606 s/it)
Iteration 12010: accuracy_at_1 = 67.19%; accuracy_at_5 = 91.02%; loss = 1.117078  (0.700835 s/it)
Iteration 12020: accuracy_at_1 = 61.72%; accuracy_at_5 = 87.89%; loss = 1.331604  (0.700070 s/it)
Iteration 12030: accuracy_at_1 = 61.72%; accuracy_at_5 = 90.23%; loss = 1.196386  (0.700584 s/it)
Iteration 12040: accuracy_at_1 = 61.72%; accuracy_at_5 = 86.33%; loss = 1.305476  (0.701212 s/it)
Iteration 12050: accuracy_at_1 = 66.80%; accuracy_at_5 = 91.02%; loss = 1.141199  (0.701313 s/it)
Iteration 12060: accuracy_at_1 = 57.81%; accuracy_at_5 = 90.23%; loss = 1.247366  (0.702000 s/it)
Iteration 12070: accuracy_at_1 = 58.20%; accuracy_at_5 = 86.72%; loss = 1.388880  (0.701537 s/it)
Iteration 12080: accuracy_at_1 = 58.98%; accuracy_at_5 = 85.94%; loss = 1.459642  (0.701042 s/it)
Iteration 12090: accuracy_at_1 = 70.70%; accuracy_at_5 = 92.97%; loss = 1.010727  (0.701850 s/it)
Iteration 12100: accuracy_at_1 = 59.38%; accuracy_at_5 = 90.23%; loss = 1.271964  (0.701600 s/it)
Iteration 12110: accuracy_at_1 = 61.33%; accuracy_at_5 = 89.45%; loss = 1.218331  (0.701050 s/it)
Iteration 12120: accuracy_at_1 = 63.28%; accuracy_at_5 = 89.45%; loss = 1.128238  (0.700690 s/it)
Iteration 12130: accuracy_at_1 = 60.94%; accuracy_at_5 = 90.23%; loss = 1.233598  (0.700426 s/it)
Iteration 12140: accuracy_at_1 = 62.11%; accuracy_at_5 = 90.23%; loss = 1.265864  (0.700144 s/it)
Iteration 12150: accuracy_at_1 = 62.11%; accuracy_at_5 = 87.89%; loss = 1.167688  (0.700120 s/it)
Iteration 12160: accuracy_at_1 = 64.45%; accuracy_at_5 = 88.28%; loss = 1.290499  (0.700796 s/it)
Iteration 12170: accuracy_at_1 = 64.45%; accuracy_at_5 = 90.23%; loss = 1.184778  (0.701465 s/it)
Iteration 12180: accuracy_at_1 = 61.33%; accuracy_at_5 = 89.06%; loss = 1.217604  (0.701447 s/it)
Iteration 12190: accuracy_at_1 = 66.02%; accuracy_at_5 = 93.75%; loss = 1.045057  (0.701950 s/it)
Iteration 12200: accuracy_at_1 = 68.36%; accuracy_at_5 = 91.02%; loss = 1.085896  (0.701532 s/it)
Iteration 12210: accuracy_at_1 = 59.38%; accuracy_at_5 = 87.11%; loss = 1.338748  (0.701673 s/it)
Iteration 12220: accuracy_at_1 = 65.62%; accuracy_at_5 = 91.41%; loss = 1.105780  (0.701419 s/it)
Iteration 12230: accuracy_at_1 = 62.89%; accuracy_at_5 = 89.84%; loss = 1.244154  (0.701084 s/it)
Iteration 12240: accuracy_at_1 = 64.06%; accuracy_at_5 = 92.19%; loss = 1.243046  (0.700408 s/it)
Iteration 12250: accuracy_at_1 = 71.09%; accuracy_at_5 = 89.45%; loss = 1.107546  (0.699954 s/it)
Iteration 12260: accuracy_at_1 = 60.94%; accuracy_at_5 = 89.84%; loss = 1.223346  (0.700275 s/it)
Iteration 12270: accuracy_at_1 = 63.28%; accuracy_at_5 = 91.41%; loss = 1.159275  (0.700544 s/it)
Iteration 12280: accuracy_at_1 = 64.45%; accuracy_at_5 = 88.67%; loss = 1.204683  (0.700349 s/it)
Iteration 12290: accuracy_at_1 = 60.94%; accuracy_at_5 = 91.41%; loss = 1.154976  (0.701157 s/it)
Iteration 12300: accuracy_at_1 = 62.50%; accuracy_at_5 = 88.28%; loss = 1.253426  (0.701360 s/it)
Iteration 12310: accuracy_at_1 = 66.80%; accuracy_at_5 = 91.02%; loss = 1.212197  (0.701875 s/it)
Iteration 12320: accuracy_at_1 = 63.67%; accuracy_at_5 = 92.97%; loss = 1.070784  (0.701907 s/it)
Iteration 12330: accuracy_at_1 = 61.72%; accuracy_at_5 = 91.02%; loss = 1.211533  (0.701525 s/it)
Iteration 12340: accuracy_at_1 = 63.67%; accuracy_at_5 = 88.67%; loss = 1.253068  (0.701988 s/it)
Iteration 12350: accuracy_at_1 = 64.45%; accuracy_at_5 = 90.62%; loss = 1.181315  (0.701759 s/it)
Iteration 12360: accuracy_at_1 = 62.89%; accuracy_at_5 = 86.72%; loss = 1.164812  (0.700197 s/it)
Iteration 12370: accuracy_at_1 = 67.19%; accuracy_at_5 = 91.02%; loss = 0.970973  (0.700719 s/it)
Iteration 12380: accuracy_at_1 = 62.11%; accuracy_at_5 = 89.06%; loss = 1.229425  (0.700388 s/it)
Iteration 12390: accuracy_at_1 = 62.50%; accuracy_at_5 = 93.36%; loss = 1.104849  (0.700249 s/it)
Iteration 12400: accuracy_at_1 = 66.41%; accuracy_at_5 = 90.23%; loss = 1.179353  (0.699832 s/it)
Iteration 12410: accuracy_at_1 = 66.80%; accuracy_at_5 = 89.84%; loss = 1.151258  (0.700782 s/it)
Iteration 12420: accuracy_at_1 = 68.75%; accuracy_at_5 = 91.80%; loss = 1.053649  (0.701003 s/it)
Iteration 12430: accuracy_at_1 = 66.02%; accuracy_at_5 = 90.62%; loss = 1.155086  (0.702323 s/it)
Iteration 12440: accuracy_at_1 = 62.89%; accuracy_at_5 = 87.11%; loss = 1.344955  (0.701304 s/it)
Iteration 12450: accuracy_at_1 = 69.14%; accuracy_at_5 = 89.06%; loss = 1.102442  (0.701493 s/it)
Iteration 12460: accuracy_at_1 = 58.59%; accuracy_at_5 = 84.38%; loss = 1.425099  (0.701562 s/it)
Iteration 12470: accuracy_at_1 = 64.06%; accuracy_at_5 = 90.23%; loss = 1.098199  (0.701112 s/it)
Iteration 12480: accuracy_at_1 = 53.12%; accuracy_at_5 = 87.50%; loss = 1.363749  (0.701287 s/it)
Iteration 12490: accuracy_at_1 = 59.38%; accuracy_at_5 = 89.84%; loss = 1.256506  (0.700212 s/it)
Iteration 12500: accuracy_at_1 = 73.05%; accuracy_at_5 = 93.75%; loss = 0.911076  (0.701288 s/it)
Iteration 12510: accuracy_at_1 = 68.36%; accuracy_at_5 = 93.36%; loss = 1.046818  (0.701355 s/it)
Iteration 12520: accuracy_at_1 = 61.72%; accuracy_at_5 = 91.80%; loss = 1.163183  (0.700943 s/it)
Iteration 12530: accuracy_at_1 = 69.53%; accuracy_at_5 = 91.80%; loss = 1.066194  (0.699842 s/it)
Iteration 12540: accuracy_at_1 = 61.72%; accuracy_at_5 = 87.11%; loss = 1.271302  (0.701151 s/it)
Iteration 12550: accuracy_at_1 = 64.45%; accuracy_at_5 = 89.45%; loss = 1.182585  (0.701175 s/it)
Iteration 12560: accuracy_at_1 = 58.59%; accuracy_at_5 = 89.45%; loss = 1.271308  (0.701610 s/it)
Iteration 12570: accuracy_at_1 = 69.53%; accuracy_at_5 = 92.97%; loss = 1.044629  (0.701901 s/it)
Iteration 12580: accuracy_at_1 = 63.67%; accuracy_at_5 = 89.84%; loss = 1.222048  (0.701640 s/it)
Iteration 12590: accuracy_at_1 = 67.97%; accuracy_at_5 = 94.14%; loss = 1.057581  (0.701653 s/it)
Iteration 12600: accuracy_at_1 = 63.67%; accuracy_at_5 = 91.80%; loss = 1.145308  (0.701469 s/it)
Iteration 12610: accuracy_at_1 = 71.48%; accuracy_at_5 = 92.97%; loss = 0.965260  (0.700872 s/it)
Iteration 12620: accuracy_at_1 = 65.62%; accuracy_at_5 = 92.58%; loss = 1.074723  (0.700098 s/it)
Iteration 12630: accuracy_at_1 = 58.20%; accuracy_at_5 = 88.67%; loss = 1.313345  (0.700372 s/it)
Iteration 12640: accuracy_at_1 = 62.50%; accuracy_at_5 = 88.28%; loss = 1.215772  (0.700522 s/it)
Iteration 12650: accuracy_at_1 = 69.53%; accuracy_at_5 = 88.67%; loss = 1.103985  (0.701289 s/it)
Iteration 12660: accuracy_at_1 = 66.02%; accuracy_at_5 = 92.19%; loss = 1.102729  (0.700814 s/it)
Iteration 12670: accuracy_at_1 = 67.19%; accuracy_at_5 = 91.41%; loss = 1.069427  (0.700277 s/it)
Iteration 12680: accuracy_at_1 = 63.67%; accuracy_at_5 = 90.62%; loss = 1.132054  (0.701933 s/it)
Iteration 12690: accuracy_at_1 = 65.62%; accuracy_at_5 = 91.80%; loss = 1.119680  (0.701298 s/it)
Iteration 12700: accuracy_at_1 = 66.02%; accuracy_at_5 = 91.80%; loss = 1.075925  (0.701734 s/it)
Iteration 12710: accuracy_at_1 = 75.78%; accuracy_at_5 = 94.14%; loss = 0.841288  (0.701848 s/it)
Iteration 12720: accuracy_at_1 = 67.19%; accuracy_at_5 = 87.89%; loss = 1.183938  (0.701578 s/it)
Iteration 12730: accuracy_at_1 = 60.55%; accuracy_at_5 = 91.41%; loss = 1.283751  (0.701334 s/it)
Iteration 12740: accuracy_at_1 = 68.75%; accuracy_at_5 = 90.62%; loss = 1.028817  (0.700759 s/it)
Iteration 12750: accuracy_at_1 = 67.58%; accuracy_at_5 = 91.02%; loss = 1.099654  (0.699943 s/it)
Iteration 12760: accuracy_at_1 = 62.50%; accuracy_at_5 = 87.89%; loss = 1.251285  (0.699954 s/it)
Iteration 12770: accuracy_at_1 = 66.80%; accuracy_at_5 = 91.02%; loss = 1.137205  (0.700442 s/it)
Iteration 12780: accuracy_at_1 = 63.67%; accuracy_at_5 = 87.11%; loss = 1.220606  (0.700291 s/it)
Iteration 12790: accuracy_at_1 = 66.41%; accuracy_at_5 = 91.02%; loss = 1.099046  (0.699940 s/it)
Iteration 12800: accuracy_at_1 = 70.70%; accuracy_at_5 = 93.36%; loss = 0.970262  (0.701382 s/it)
Iteration 12810: accuracy_at_1 = 67.97%; accuracy_at_5 = 91.02%; loss = 0.996273  (0.701655 s/it)
Iteration 12820: accuracy_at_1 = 67.19%; accuracy_at_5 = 89.84%; loss = 1.117383  (0.701234 s/it)
Iteration 12830: accuracy_at_1 = 64.06%; accuracy_at_5 = 89.06%; loss = 1.182313  (0.701705 s/it)
Iteration 12840: accuracy_at_1 = 64.06%; accuracy_at_5 = 91.02%; loss = 1.122572  (0.701574 s/it)
Iteration 12850: accuracy_at_1 = 71.88%; accuracy_at_5 = 93.36%; loss = 0.959922  (0.701305 s/it)
Iteration 12860: accuracy_at_1 = 67.19%; accuracy_at_5 = 89.84%; loss = 1.090712  (0.701443 s/it)
Iteration 12870: accuracy_at_1 = 68.36%; accuracy_at_5 = 90.23%; loss = 1.055680  (0.701823 s/it)
Iteration 12880: accuracy_at_1 = 65.62%; accuracy_at_5 = 89.84%; loss = 1.233606  (0.700338 s/it)
Iteration 12890: accuracy_at_1 = 66.80%; accuracy_at_5 = 92.19%; loss = 0.996821  (0.700684 s/it)
Iteration 12900: accuracy_at_1 = 68.75%; accuracy_at_5 = 92.58%; loss = 0.989683  (0.700755 s/it)
Iteration 12910: accuracy_at_1 = 67.58%; accuracy_at_5 = 92.19%; loss = 1.039719  (0.700257 s/it)
Iteration 12920: accuracy_at_1 = 70.31%; accuracy_at_5 = 91.80%; loss = 0.996274  (0.700795 s/it)
Iteration 12930: accuracy_at_1 = 69.53%; accuracy_at_5 = 91.02%; loss = 1.073203  (0.700491 s/it)
Iteration 12940: accuracy_at_1 = 70.70%; accuracy_at_5 = 92.58%; loss = 0.915018  (0.701788 s/it)
Iteration 12950: accuracy_at_1 = 67.58%; accuracy_at_5 = 92.58%; loss = 1.069291  (0.700927 s/it)
Iteration 12960: accuracy_at_1 = 67.19%; accuracy_at_5 = 92.19%; loss = 1.091460  (0.701328 s/it)
Iteration 12970: accuracy_at_1 = 70.31%; accuracy_at_5 = 93.75%; loss = 0.938610  (0.701358 s/it)
Iteration 12980: accuracy_at_1 = 73.83%; accuracy_at_5 = 94.53%; loss = 0.875680  (0.702062 s/it)
Iteration 12990: accuracy_at_1 = 66.80%; accuracy_at_5 = 91.41%; loss = 1.019749  (0.701896 s/it)
Iteration 13000: accuracy_at_1 = 68.36%; accuracy_at_5 = 94.53%; loss = 0.889255  (0.700608 s/it)
Iteration 13010: accuracy_at_1 = 74.22%; accuracy_at_5 = 93.75%; loss = 0.894326  (0.700169 s/it)
Iteration 13020: accuracy_at_1 = 69.92%; accuracy_at_5 = 92.19%; loss = 0.988540  (0.700032 s/it)
Iteration 13030: accuracy_at_1 = 66.41%; accuracy_at_5 = 91.80%; loss = 1.043183  (0.700410 s/it)
Iteration 13040: accuracy_at_1 = 68.36%; accuracy_at_5 = 93.36%; loss = 1.044426  (0.700488 s/it)
Iteration 13050: accuracy_at_1 = 67.19%; accuracy_at_5 = 90.62%; loss = 1.066648  (0.700166 s/it)
Iteration 13060: accuracy_at_1 = 71.88%; accuracy_at_5 = 94.14%; loss = 0.899742  (0.700994 s/it)
Iteration 13070: accuracy_at_1 = 65.23%; accuracy_at_5 = 89.06%; loss = 1.202570  (0.702938 s/it)
Iteration 13080: accuracy_at_1 = 73.44%; accuracy_at_5 = 95.31%; loss = 0.901614  (0.701131 s/it)
Iteration 13090: accuracy_at_1 = 63.28%; accuracy_at_5 = 90.23%; loss = 1.122250  (0.701947 s/it)
Iteration 13100: accuracy_at_1 = 64.06%; accuracy_at_5 = 93.75%; loss = 1.051036  (0.701006 s/it)
Iteration 13110: accuracy_at_1 = 68.75%; accuracy_at_5 = 95.70%; loss = 0.928359  (0.701783 s/it)
Iteration 13120: accuracy_at_1 = 70.70%; accuracy_at_5 = 92.58%; loss = 0.991508  (0.701150 s/it)
Iteration 13130: accuracy_at_1 = 66.02%; accuracy_at_5 = 93.75%; loss = 1.044066  (0.700104 s/it)
Iteration 13140: accuracy_at_1 = 69.92%; accuracy_at_5 = 91.80%; loss = 1.012385  (0.699709 s/it)
Iteration 13150: accuracy_at_1 = 66.80%; accuracy_at_5 = 94.14%; loss = 0.973741  (0.699751 s/it)
Iteration 13160: accuracy_at_1 = 70.31%; accuracy_at_5 = 91.80%; loss = 1.045558  (0.700336 s/it)
Iteration 13170: accuracy_at_1 = 67.19%; accuracy_at_5 = 90.62%; loss = 0.998621  (0.700844 s/it)
Iteration 13180: accuracy_at_1 = 71.09%; accuracy_at_5 = 94.92%; loss = 0.895853  (0.699880 s/it)
Iteration 13190: accuracy_at_1 = 62.50%; accuracy_at_5 = 92.19%; loss = 1.085765  (0.701519 s/it)
Iteration 13200: accuracy_at_1 = 58.59%; accuracy_at_5 = 87.89%; loss = 1.306763  (0.702192 s/it)
Iteration 13210: accuracy_at_1 = 67.58%; accuracy_at_5 = 91.41%; loss = 1.043359  (0.701410 s/it)
Iteration 13220: accuracy_at_1 = 62.50%; accuracy_at_5 = 92.97%; loss = 1.190198  (0.701973 s/it)
Iteration 13230: accuracy_at_1 = 67.58%; accuracy_at_5 = 91.02%; loss = 1.019137  (0.701044 s/it)
Iteration 13240: accuracy_at_1 = 65.62%; accuracy_at_5 = 91.02%; loss = 1.075972  (0.701269 s/it)
Iteration 13250: accuracy_at_1 = 68.75%; accuracy_at_5 = 91.41%; loss = 1.014865  (0.700794 s/it)
Iteration 13260: accuracy_at_1 = 67.58%; accuracy_at_5 = 92.58%; loss = 1.076679  (0.700328 s/it)
Iteration 13270: accuracy_at_1 = 69.14%; accuracy_at_5 = 94.92%; loss = 0.985377  (0.699919 s/it)
Iteration 13280: accuracy_at_1 = 71.88%; accuracy_at_5 = 94.92%; loss = 0.925281  (0.701406 s/it)
Iteration 13290: accuracy_at_1 = 69.53%; accuracy_at_5 = 93.36%; loss = 0.955559  (0.700370 s/it)
Iteration 13300: accuracy_at_1 = 68.36%; accuracy_at_5 = 91.80%; loss = 0.984053  (0.700418 s/it)
Iteration 13310: accuracy_at_1 = 73.44%; accuracy_at_5 = 96.48%; loss = 0.849461  (0.700368 s/it)
Iteration 13320: accuracy_at_1 = 70.31%; accuracy_at_5 = 94.53%; loss = 0.954429  (0.701627 s/it)
Iteration 13330: accuracy_at_1 = 69.53%; accuracy_at_5 = 93.75%; loss = 0.940744  (0.701422 s/it)
Iteration 13340: accuracy_at_1 = 64.84%; accuracy_at_5 = 92.58%; loss = 1.034466  (0.701524 s/it)
Iteration 13350: accuracy_at_1 = 69.14%; accuracy_at_5 = 92.97%; loss = 0.965692  (0.701638 s/it)
Iteration 13360: accuracy_at_1 = 72.27%; accuracy_at_5 = 92.19%; loss = 0.910184  (0.701097 s/it)
Iteration 13370: accuracy_at_1 = 70.31%; accuracy_at_5 = 94.14%; loss = 0.934661  (0.701450 s/it)
Iteration 13380: accuracy_at_1 = 74.22%; accuracy_at_5 = 95.31%; loss = 0.820630  (0.700301 s/it)
Iteration 13390: accuracy_at_1 = 75.00%; accuracy_at_5 = 92.19%; loss = 0.851650  (0.700033 s/it)
Iteration 13400: accuracy_at_1 = 74.61%; accuracy_at_5 = 92.58%; loss = 0.834915  (0.700177 s/it)
Iteration 13410: accuracy_at_1 = 67.97%; accuracy_at_5 = 93.36%; loss = 0.946235  (0.700610 s/it)
Iteration 13420: accuracy_at_1 = 69.92%; accuracy_at_5 = 94.14%; loss = 0.949498  (0.700853 s/it)
Iteration 13430: accuracy_at_1 = 68.36%; accuracy_at_5 = 91.41%; loss = 1.013721  (0.699931 s/it)
Iteration 13440: accuracy_at_1 = 68.75%; accuracy_at_5 = 93.75%; loss = 0.970538  (0.701014 s/it)
Iteration 13450: accuracy_at_1 = 68.75%; accuracy_at_5 = 93.36%; loss = 0.956153  (0.700964 s/it)
Iteration 13460: accuracy_at_1 = 75.39%; accuracy_at_5 = 94.53%; loss = 0.890492  (0.701055 s/it)
Iteration 13470: accuracy_at_1 = 67.19%; accuracy_at_5 = 92.58%; loss = 0.956724  (0.701305 s/it)
Iteration 13480: accuracy_at_1 = 66.02%; accuracy_at_5 = 92.58%; loss = 1.094245  (0.701691 s/it)
Iteration 13490: accuracy_at_1 = 70.31%; accuracy_at_5 = 93.36%; loss = 0.921046  (0.701001 s/it)
Iteration 13500: accuracy_at_1 = 65.23%; accuracy_at_5 = 91.80%; loss = 1.049608  (0.701015 s/it)
Iteration 13510: accuracy_at_1 = 71.88%; accuracy_at_5 = 94.53%; loss = 0.929612  (0.700363 s/it)
Iteration 13520: accuracy_at_1 = 72.66%; accuracy_at_5 = 94.53%; loss = 0.887124  (0.700578 s/it)
Iteration 13530: accuracy_at_1 = 68.75%; accuracy_at_5 = 94.14%; loss = 0.903190  (0.700277 s/it)
Iteration 13540: accuracy_at_1 = 70.70%; accuracy_at_5 = 93.36%; loss = 0.958331  (0.700876 s/it)
Iteration 13550: accuracy_at_1 = 68.75%; accuracy_at_5 = 92.19%; loss = 1.039491  (0.700064 s/it)
Iteration 13560: accuracy_at_1 = 69.14%; accuracy_at_5 = 95.31%; loss = 0.927471  (0.700181 s/it)
Iteration 13570: accuracy_at_1 = 73.44%; accuracy_at_5 = 92.19%; loss = 0.989123  (0.701152 s/it)
Iteration 13580: accuracy_at_1 = 67.97%; accuracy_at_5 = 92.97%; loss = 1.034012  (0.701069 s/it)
Iteration 13590: accuracy_at_1 = 71.09%; accuracy_at_5 = 94.92%; loss = 0.890407  (0.701318 s/it)
Iteration 13600: accuracy_at_1 = 70.31%; accuracy_at_5 = 93.36%; loss = 0.939060  (0.701425 s/it)
Iteration 13610: accuracy_at_1 = 67.97%; accuracy_at_5 = 92.97%; loss = 1.018735  (0.701141 s/it)
Iteration 13620: accuracy_at_1 = 66.80%; accuracy_at_5 = 92.19%; loss = 1.033229  (0.702147 s/it)
Iteration 13630: accuracy_at_1 = 69.53%; accuracy_at_5 = 91.02%; loss = 1.069317  (0.702465 s/it)
Iteration 13640: accuracy_at_1 = 70.31%; accuracy_at_5 = 92.19%; loss = 0.975616  (0.700148 s/it)
Iteration 13650: accuracy_at_1 = 69.92%; accuracy_at_5 = 92.58%; loss = 0.943734  (0.700979 s/it)
Iteration 13660: accuracy_at_1 = 71.48%; accuracy_at_5 = 95.31%; loss = 0.932239  (0.700059 s/it)
Iteration 13670: accuracy_at_1 = 70.70%; accuracy_at_5 = 90.23%; loss = 0.980487  (0.701403 s/it)
Iteration 13680: accuracy_at_1 = 70.31%; accuracy_at_5 = 95.70%; loss = 0.915892  (0.700096 s/it)
Iteration 13690: accuracy_at_1 = 74.22%; accuracy_at_5 = 95.31%; loss = 0.776160  (0.700237 s/it)
Iteration 13700: accuracy_at_1 = 73.83%; accuracy_at_5 = 94.53%; loss = 0.845253  (0.701154 s/it)
Iteration 13710: accuracy_at_1 = 74.22%; accuracy_at_5 = 95.70%; loss = 0.786063  (0.701517 s/it)
Iteration 13720: accuracy_at_1 = 68.36%; accuracy_at_5 = 92.97%; loss = 0.965338  (0.702043 s/it)
Iteration 13730: accuracy_at_1 = 71.88%; accuracy_at_5 = 93.36%; loss = 0.982176  (0.701584 s/it)
Iteration 13740: accuracy_at_1 = 70.70%; accuracy_at_5 = 92.19%; loss = 0.967444  (0.702392 s/it)
Iteration 13750: accuracy_at_1 = 67.97%; accuracy_at_5 = 92.97%; loss = 0.919268  (0.701178 s/it)
Iteration 13760: accuracy_at_1 = 70.70%; accuracy_at_5 = 92.97%; loss = 0.843091  (0.701646 s/it)
Iteration 13770: accuracy_at_1 = 81.25%; accuracy_at_5 = 96.09%; loss = 0.710795  (0.700399 s/it)
Iteration 13780: accuracy_at_1 = 69.14%; accuracy_at_5 = 94.53%; loss = 0.936188  (0.700297 s/it)
Iteration 13790: accuracy_at_1 = 68.75%; accuracy_at_5 = 92.97%; loss = 0.972207  (0.700296 s/it)
Iteration 13800: accuracy_at_1 = 67.19%; accuracy_at_5 = 91.41%; loss = 1.049297  (0.699934 s/it)
Iteration 13810: accuracy_at_1 = 67.97%; accuracy_at_5 = 93.36%; loss = 1.054722  (0.699603 s/it)
Iteration 13820: accuracy_at_1 = 74.22%; accuracy_at_5 = 94.53%; loss = 0.863291  (0.699914 s/it)
Iteration 13830: accuracy_at_1 = 69.14%; accuracy_at_5 = 92.19%; loss = 0.936736  (0.701553 s/it)
Iteration 13840: accuracy_at_1 = 69.92%; accuracy_at_5 = 93.36%; loss = 0.909337  (0.701284 s/it)
Iteration 13850: accuracy_at_1 = 73.05%; accuracy_at_5 = 95.31%; loss = 0.776624  (0.701143 s/it)
Iteration 13860: accuracy_at_1 = 69.53%; accuracy_at_5 = 94.92%; loss = 0.859672  (0.701569 s/it)
Iteration 13870: accuracy_at_1 = 68.36%; accuracy_at_5 = 94.92%; loss = 0.947878  (0.701700 s/it)
Iteration 13880: accuracy_at_1 = 73.05%; accuracy_at_5 = 95.70%; loss = 0.864411  (0.701268 s/it)
Iteration 13890: accuracy_at_1 = 75.78%; accuracy_at_5 = 94.53%; loss = 0.799405  (0.700813 s/it)
Iteration 13900: accuracy_at_1 = 71.88%; accuracy_at_5 = 94.92%; loss = 0.874486  (0.700001 s/it)
Iteration 13910: accuracy_at_1 = 72.66%; accuracy_at_5 = 94.53%; loss = 0.878996  (0.700000 s/it)
Iteration 13920: accuracy_at_1 = 75.39%; accuracy_at_5 = 96.09%; loss = 0.802497  (0.700313 s/it)
Iteration 13930: accuracy_at_1 = 72.27%; accuracy_at_5 = 94.53%; loss = 0.908672  (0.700555 s/it)
Iteration 13940: accuracy_at_1 = 73.83%; accuracy_at_5 = 94.92%; loss = 0.828612  (0.700077 s/it)
Iteration 13950: accuracy_at_1 = 73.05%; accuracy_at_5 = 92.58%; loss = 0.908525  (0.700584 s/it)
Iteration 13960: accuracy_at_1 = 69.53%; accuracy_at_5 = 91.80%; loss = 0.978171  (0.702112 s/it)
Iteration 13970: accuracy_at_1 = 70.70%; accuracy_at_5 = 94.92%; loss = 0.899472  (0.700840 s/it)
Iteration 13980: accuracy_at_1 = 71.88%; accuracy_at_5 = 92.58%; loss = 0.956285  (0.701483 s/it)
Iteration 13990: accuracy_at_1 = 73.05%; accuracy_at_5 = 96.48%; loss = 0.906590  (0.701555 s/it)
Iteration 14000: accuracy_at_1 = 65.23%; accuracy_at_5 = 93.75%; loss = 0.985331  (0.701447 s/it)
Iteration 14010: accuracy_at_1 = 67.97%; accuracy_at_5 = 94.92%; loss = 0.993523  (0.701082 s/it)
Iteration 14020: accuracy_at_1 = 73.05%; accuracy_at_5 = 92.19%; loss = 0.928795  (0.700713 s/it)
Iteration 14030: accuracy_at_1 = 64.45%; accuracy_at_5 = 93.75%; loss = 1.014320  (0.700219 s/it)
Iteration 14040: accuracy_at_1 = 71.88%; accuracy_at_5 = 93.36%; loss = 0.931725  (0.700103 s/it)
Iteration 14050: accuracy_at_1 = 69.53%; accuracy_at_5 = 94.14%; loss = 0.933949  (0.699807 s/it)
Iteration 14060: accuracy_at_1 = 70.31%; accuracy_at_5 = 93.75%; loss = 0.946644  (0.701193 s/it)
Iteration 14070: accuracy_at_1 = 73.05%; accuracy_at_5 = 94.92%; loss = 0.747897  (0.702305 s/it)
Iteration 14080: accuracy_at_1 = 71.88%; accuracy_at_5 = 93.36%; loss = 0.934070  (0.700653 s/it)
Iteration 14090: accuracy_at_1 = 78.12%; accuracy_at_5 = 96.88%; loss = 0.679075  (0.701328 s/it)
Iteration 14100: accuracy_at_1 = 71.48%; accuracy_at_5 = 92.19%; loss = 0.935339  (0.701493 s/it)
Iteration 14110: accuracy_at_1 = 73.44%; accuracy_at_5 = 96.48%; loss = 0.797644  (0.701546 s/it)
Iteration 14120: accuracy_at_1 = 78.12%; accuracy_at_5 = 96.09%; loss = 0.727701  (0.701329 s/it)
Iteration 14130: accuracy_at_1 = 74.61%; accuracy_at_5 = 95.70%; loss = 0.783311  (0.701360 s/it)
Iteration 14140: accuracy_at_1 = 74.22%; accuracy_at_5 = 95.70%; loss = 0.883843  (0.701464 s/it)
Iteration 14150: accuracy_at_1 = 73.05%; accuracy_at_5 = 95.70%; loss = 0.808884  (0.700684 s/it)
Iteration 14160: accuracy_at_1 = 73.05%; accuracy_at_5 = 96.48%; loss = 0.843051  (0.700097 s/it)
Iteration 14170: accuracy_at_1 = 79.69%; accuracy_at_5 = 94.53%; loss = 0.746749  (0.699671 s/it)
Iteration 14180: accuracy_at_1 = 71.48%; accuracy_at_5 = 93.75%; loss = 0.842739  (0.701307 s/it)
Iteration 14190: accuracy_at_1 = 72.27%; accuracy_at_5 = 93.36%; loss = 0.852251  (0.700681 s/it)
Iteration 14200: accuracy_at_1 = 79.30%; accuracy_at_5 = 96.88%; loss = 0.721336  (0.701181 s/it)
Iteration 14210: accuracy_at_1 = 75.78%; accuracy_at_5 = 94.53%; loss = 0.803527  (0.700422 s/it)
Iteration 14220: accuracy_at_1 = 74.61%; accuracy_at_5 = 96.88%; loss = 0.726745  (0.701766 s/it)
Iteration 14230: accuracy_at_1 = 71.88%; accuracy_at_5 = 96.48%; loss = 0.830586  (0.701193 s/it)
Iteration 14240: accuracy_at_1 = 70.70%; accuracy_at_5 = 93.36%; loss = 0.907402  (0.701086 s/it)
Iteration 14250: accuracy_at_1 = 69.14%; accuracy_at_5 = 93.36%; loss = 0.908188  (0.702774 s/it)
Iteration 14260: accuracy_at_1 = 73.83%; accuracy_at_5 = 95.70%; loss = 0.762603  (0.701141 s/it)
Iteration 14270: accuracy_at_1 = 69.53%; accuracy_at_5 = 95.70%; loss = 0.893854  (0.701978 s/it)
Iteration 14280: accuracy_at_1 = 76.56%; accuracy_at_5 = 93.36%; loss = 0.837531  (0.700115 s/it)
Iteration 14290: accuracy_at_1 = 73.05%; accuracy_at_5 = 92.58%; loss = 0.826571  (0.701064 s/it)
Iteration 14300: accuracy_at_1 = 72.66%; accuracy_at_5 = 90.23%; loss = 0.969656  (0.701275 s/it)
Iteration 14310: accuracy_at_1 = 73.05%; accuracy_at_5 = 94.14%; loss = 0.833684  (0.700377 s/it)
Iteration 14320: accuracy_at_1 = 76.17%; accuracy_at_5 = 94.53%; loss = 0.754162  (0.700676 s/it)
Iteration 14330: accuracy_at_1 = 71.88%; accuracy_at_5 = 93.36%; loss = 0.919827  (0.699905 s/it)
Iteration 14340: accuracy_at_1 = 71.88%; accuracy_at_5 = 93.36%; loss = 0.878347  (0.700576 s/it)
Iteration 14350: accuracy_at_1 = 70.31%; accuracy_at_5 = 94.14%; loss = 0.908024  (0.701326 s/it)
Iteration 14360: accuracy_at_1 = 72.27%; accuracy_at_5 = 91.80%; loss = 0.911821  (0.701471 s/it)
Iteration 14370: accuracy_at_1 = 76.56%; accuracy_at_5 = 94.92%; loss = 0.758535  (0.700894 s/it)
Iteration 14380: accuracy_at_1 = 71.09%; accuracy_at_5 = 94.53%; loss = 0.963051  (0.701427 s/it)
Iteration 14390: accuracy_at_1 = 73.44%; accuracy_at_5 = 92.97%; loss = 0.929143  (0.701343 s/it)
Iteration 14400: accuracy_at_1 = 67.58%; accuracy_at_5 = 92.97%; loss = 0.964826  (0.701887 s/it)
Iteration 14410: accuracy_at_1 = 75.00%; accuracy_at_5 = 96.88%; loss = 0.771385  (0.700103 s/it)
Iteration 14420: accuracy_at_1 = 77.34%; accuracy_at_5 = 95.70%; loss = 0.774021  (0.700442 s/it)
Iteration 14430: accuracy_at_1 = 74.22%; accuracy_at_5 = 94.92%; loss = 0.839851  (0.702244 s/it)
Iteration 14440: accuracy_at_1 = 71.09%; accuracy_at_5 = 92.19%; loss = 0.930995  (0.700988 s/it)
Iteration 14450: accuracy_at_1 = 67.97%; accuracy_at_5 = 95.31%; loss = 0.956709  (0.701562 s/it)
Iteration 14460: accuracy_at_1 = 79.30%; accuracy_at_5 = 96.48%; loss = 0.693244  (0.699658 s/it)
Iteration 14470: accuracy_at_1 = 79.30%; accuracy_at_5 = 96.88%; loss = 0.661643  (0.701834 s/it)
Iteration 14480: accuracy_at_1 = 77.34%; accuracy_at_5 = 94.53%; loss = 0.753873  (0.701696 s/it)
Iteration 14490: accuracy_at_1 = 78.52%; accuracy_at_5 = 95.70%; loss = 0.747407  (0.700870 s/it)
Iteration 14500: accuracy_at_1 = 78.91%; accuracy_at_5 = 95.70%; loss = 0.689853  (0.700984 s/it)
Iteration 14510: accuracy_at_1 = 73.44%; accuracy_at_5 = 96.09%; loss = 0.784487  (0.703321 s/it)
Iteration 14520: accuracy_at_1 = 75.39%; accuracy_at_5 = 93.75%; loss = 0.840068  (0.701299 s/it)
Iteration 14530: accuracy_at_1 = 75.00%; accuracy_at_5 = 94.92%; loss = 0.728959  (0.700735 s/it)
Iteration 14540: accuracy_at_1 = 80.08%; accuracy_at_5 = 97.27%; loss = 0.623776  (0.699990 s/it)
Iteration 14550: accuracy_at_1 = 74.22%; accuracy_at_5 = 94.92%; loss = 0.809647  (0.699939 s/it)
Iteration 14560: accuracy_at_1 = 79.30%; accuracy_at_5 = 94.92%; loss = 0.680946  (0.699970 s/it)
Iteration 14570: accuracy_at_1 = 76.95%; accuracy_at_5 = 96.88%; loss = 0.747809  (0.700871 s/it)
Iteration 14580: accuracy_at_1 = 74.61%; accuracy_at_5 = 96.48%; loss = 0.676303  (0.700151 s/it)
Iteration 14590: accuracy_at_1 = 73.83%; accuracy_at_5 = 94.92%; loss = 0.831647  (0.700518 s/it)
Iteration 14600: accuracy_at_1 = 74.22%; accuracy_at_5 = 95.70%; loss = 0.767644  (0.701874 s/it)
Iteration 14610: accuracy_at_1 = 78.91%; accuracy_at_5 = 98.05%; loss = 0.618510  (0.701785 s/it)
Iteration 14620: accuracy_at_1 = 73.44%; accuracy_at_5 = 96.09%; loss = 0.803242  (0.701313 s/it)
Iteration 14630: accuracy_at_1 = 76.17%; accuracy_at_5 = 95.31%; loss = 0.755369  (0.701798 s/it)
Iteration 14640: accuracy_at_1 = 78.91%; accuracy_at_5 = 94.53%; loss = 0.755765  (0.701372 s/it)
Iteration 14650: accuracy_at_1 = 74.61%; accuracy_at_5 = 98.05%; loss = 0.778745  (0.701308 s/it)
Iteration 14660: accuracy_at_1 = 77.73%; accuracy_at_5 = 95.70%; loss = 0.770691  (0.700854 s/it)
Iteration 14670: accuracy_at_1 = 78.52%; accuracy_at_5 = 97.66%; loss = 0.660372  (0.700669 s/it)
Iteration 14680: accuracy_at_1 = 71.88%; accuracy_at_5 = 95.31%; loss = 0.855473  (0.700350 s/it)
Iteration 14690: accuracy_at_1 = 74.61%; accuracy_at_5 = 94.14%; loss = 0.877706  (0.700316 s/it)
Iteration 14700: accuracy_at_1 = 76.17%; accuracy_at_5 = 94.53%; loss = 0.749524  (0.700475 s/it)
Iteration 14710: accuracy_at_1 = 75.39%; accuracy_at_5 = 95.31%; loss = 0.811312  (0.700634 s/it)
Iteration 14720: accuracy_at_1 = 69.92%; accuracy_at_5 = 93.36%; loss = 0.930523  (0.700928 s/it)
Iteration 14730: accuracy_at_1 = 70.70%; accuracy_at_5 = 94.53%; loss = 0.864356  (0.702217 s/it)
Iteration 14740: accuracy_at_1 = 75.78%; accuracy_at_5 = 96.88%; loss = 0.744030  (0.702133 s/it)
Iteration 14750: accuracy_at_1 = 75.39%; accuracy_at_5 = 96.48%; loss = 0.801509  (0.701564 s/it)
Iteration 14760: accuracy_at_1 = 76.56%; accuracy_at_5 = 96.48%; loss = 0.757837  (0.701342 s/it)
Iteration 14770: accuracy_at_1 = 75.00%; accuracy_at_5 = 95.70%; loss = 0.775019  (0.700962 s/it)
Iteration 14780: accuracy_at_1 = 75.39%; accuracy_at_5 = 96.48%; loss = 0.826344  (0.701925 s/it)
Iteration 14790: accuracy_at_1 = 75.00%; accuracy_at_5 = 98.05%; loss = 0.787049  (0.700027 s/it)
Iteration 14800: accuracy_at_1 = 72.27%; accuracy_at_5 = 93.75%; loss = 0.845233  (0.699800 s/it)
Iteration 14810: accuracy_at_1 = 72.27%; accuracy_at_5 = 97.27%; loss = 0.797853  (0.700052 s/it)
Iteration 14820: accuracy_at_1 = 74.22%; accuracy_at_5 = 95.70%; loss = 0.818747  (0.700381 s/it)
Iteration 14830: accuracy_at_1 = 76.17%; accuracy_at_5 = 95.70%; loss = 0.715435  (0.701119 s/it)
Iteration 14840: accuracy_at_1 = 72.27%; accuracy_at_5 = 92.97%; loss = 0.866208  (0.701339 s/it)
Iteration 14850: accuracy_at_1 = 77.73%; accuracy_at_5 = 96.88%; loss = 0.678364  (0.701271 s/it)
Iteration 14860: accuracy_at_1 = 76.95%; accuracy_at_5 = 96.09%; loss = 0.685373  (0.702088 s/it)
Iteration 14870: accuracy_at_1 = 77.34%; accuracy_at_5 = 95.70%; loss = 0.736802  (0.701647 s/it)
Iteration 14880: accuracy_at_1 = 80.47%; accuracy_at_5 = 97.66%; loss = 0.601392  (0.701336 s/it)
Iteration 14890: accuracy_at_1 = 77.73%; accuracy_at_5 = 97.66%; loss = 0.648659  (0.703001 s/it)
Iteration 14900: accuracy_at_1 = 76.17%; accuracy_at_5 = 96.09%; loss = 0.726591  (0.702365 s/it)
Iteration 14910: accuracy_at_1 = 79.69%; accuracy_at_5 = 98.05%; loss = 0.606224  (0.703908 s/it)
Iteration 14920: accuracy_at_1 = 80.08%; accuracy_at_5 = 98.05%; loss = 0.636410  (0.704769 s/it)
Iteration 14930: accuracy_at_1 = 77.73%; accuracy_at_5 = 98.44%; loss = 0.720212  (0.701226 s/it)
Iteration 14940: accuracy_at_1 = 75.78%; accuracy_at_5 = 98.44%; loss = 0.706627  (0.701735 s/it)
Iteration 14950: accuracy_at_1 = 80.47%; accuracy_at_5 = 97.27%; loss = 0.615406  (0.702175 s/it)
Iteration 14960: accuracy_at_1 = 79.30%; accuracy_at_5 = 97.66%; loss = 0.704422  (0.702465 s/it)
Iteration 14970: accuracy_at_1 = 76.56%; accuracy_at_5 = 96.88%; loss = 0.685280  (0.703183 s/it)
Iteration 14980: accuracy_at_1 = 76.95%; accuracy_at_5 = 97.27%; loss = 0.753950  (0.703680 s/it)
Iteration 14990: accuracy_at_1 = 73.83%; accuracy_at_5 = 96.09%; loss = 0.787914  (0.701893 s/it)
Iteration 15000: accuracy_at_1 = 76.17%; accuracy_at_5 = 96.88%; loss = 0.761090  (0.714541 s/it)
Iteration 15010: accuracy_at_1 = 71.48%; accuracy_at_5 = 94.53%; loss = 0.823787  (0.699987 s/it)
Iteration 15020: accuracy_at_1 = 79.30%; accuracy_at_5 = 96.48%; loss = 0.645826  (0.701531 s/it)
Iteration 15030: accuracy_at_1 = 79.30%; accuracy_at_5 = 97.66%; loss = 0.676299  (0.701120 s/it)
Iteration 15040: accuracy_at_1 = 80.47%; accuracy_at_5 = 98.05%; loss = 0.622254  (0.701291 s/it)
Iteration 15050: accuracy_at_1 = 77.34%; accuracy_at_5 = 97.66%; loss = 0.680592  (0.701384 s/it)
Iteration 15060: accuracy_at_1 = 76.56%; accuracy_at_5 = 97.27%; loss = 0.724182  (0.700451 s/it)
Iteration 15070: accuracy_at_1 = 75.39%; accuracy_at_5 = 96.48%; loss = 0.726520  (0.700876 s/it)
Iteration 15080: accuracy_at_1 = 77.34%; accuracy_at_5 = 95.70%; loss = 0.721079  (0.700793 s/it)
Iteration 15090: accuracy_at_1 = 74.61%; accuracy_at_5 = 96.88%; loss = 0.684128  (0.700239 s/it)
Iteration 15100: accuracy_at_1 = 75.78%; accuracy_at_5 = 96.09%; loss = 0.760342  (0.702112 s/it)
Iteration 15110: accuracy_at_1 = 77.34%; accuracy_at_5 = 95.70%; loss = 0.731519  (0.701173 s/it)
Iteration 15120: accuracy_at_1 = 75.00%; accuracy_at_5 = 95.70%; loss = 0.805863  (0.701879 s/it)
Iteration 15130: accuracy_at_1 = 75.39%; accuracy_at_5 = 95.31%; loss = 0.730063  (0.701853 s/it)
Iteration 15140: accuracy_at_1 = 75.78%; accuracy_at_5 = 96.88%; loss = 0.765893  (0.702279 s/it)
Iteration 15150: accuracy_at_1 = 73.44%; accuracy_at_5 = 94.53%; loss = 0.885509  (0.702047 s/it)
Iteration 15160: accuracy_at_1 = 76.56%; accuracy_at_5 = 94.14%; loss = 0.729893  (0.701925 s/it)
Iteration 15170: accuracy_at_1 = 77.34%; accuracy_at_5 = 97.27%; loss = 0.709558  (0.700886 s/it)
Iteration 15180: accuracy_at_1 = 77.73%; accuracy_at_5 = 97.27%; loss = 0.681863  (0.700033 s/it)
Iteration 15190: accuracy_at_1 = 75.78%; accuracy_at_5 = 95.70%; loss = 0.709243  (0.700216 s/it)
Iteration 15200: accuracy_at_1 = 72.66%; accuracy_at_5 = 94.14%; loss = 0.788442  (0.700743 s/it)
Iteration 15210: accuracy_at_1 = 75.78%; accuracy_at_5 = 96.48%; loss = 0.733778  (0.700347 s/it)
Iteration 15220: accuracy_at_1 = 75.00%; accuracy_at_5 = 97.27%; loss = 0.749139  (0.700289 s/it)
Iteration 15230: accuracy_at_1 = 77.73%; accuracy_at_5 = 97.66%; loss = 0.689327  (0.700857 s/it)
Iteration 15240: accuracy_at_1 = 80.47%; accuracy_at_5 = 96.88%; loss = 0.665017  (0.702357 s/it)
Iteration 15250: accuracy_at_1 = 80.86%; accuracy_at_5 = 97.66%; loss = 0.617364  (0.701396 s/it)
Iteration 15260: accuracy_at_1 = 73.44%; accuracy_at_5 = 97.27%; loss = 0.761338  (0.702020 s/it)
Iteration 15270: accuracy_at_1 = 79.69%; accuracy_at_5 = 97.66%; loss = 0.655550  (0.702073 s/it)
Iteration 15280: accuracy_at_1 = 82.42%; accuracy_at_5 = 98.83%; loss = 0.539916  (0.701415 s/it)
Iteration 15290: accuracy_at_1 = 82.03%; accuracy_at_5 = 98.44%; loss = 0.518124  (0.703180 s/it)
Iteration 15300: accuracy_at_1 = 80.08%; accuracy_at_5 = 98.05%; loss = 0.599530  (0.701579 s/it)
Iteration 15310: accuracy_at_1 = 75.00%; accuracy_at_5 = 96.88%; loss = 0.757006  (0.700417 s/it)
Iteration 15320: accuracy_at_1 = 75.39%; accuracy_at_5 = 96.88%; loss = 0.659504  (0.700172 s/it)
Iteration 15330: accuracy_at_1 = 78.52%; accuracy_at_5 = 96.48%; loss = 0.658942  (0.700630 s/it)
Iteration 15340: accuracy_at_1 = 80.47%; accuracy_at_5 = 96.88%; loss = 0.618231  (0.699980 s/it)
Iteration 15350: accuracy_at_1 = 79.30%; accuracy_at_5 = 96.09%; loss = 0.665646  (0.700410 s/it)
Iteration 15360: accuracy_at_1 = 78.52%; accuracy_at_5 = 96.88%; loss = 0.662862  (0.701450 s/it)
Iteration 15370: accuracy_at_1 = 77.34%; accuracy_at_5 = 97.66%; loss = 0.699377  (0.701502 s/it)
Iteration 15380: accuracy_at_1 = 78.12%; accuracy_at_5 = 98.05%; loss = 0.656400  (0.702530 s/it)
Iteration 15390: accuracy_at_1 = 77.73%; accuracy_at_5 = 98.05%; loss = 0.690385  (0.701993 s/it)
Iteration 15400: accuracy_at_1 = 80.47%; accuracy_at_5 = 96.09%; loss = 0.701981  (0.702449 s/it)
Iteration 15410: accuracy_at_1 = 77.34%; accuracy_at_5 = 96.48%; loss = 0.662176  (0.701630 s/it)
Iteration 15420: accuracy_at_1 = 82.81%; accuracy_at_5 = 96.09%; loss = 0.630311  (0.701212 s/it)
Iteration 15430: accuracy_at_1 = 81.64%; accuracy_at_5 = 99.22%; loss = 0.531627  (0.701500 s/it)
Iteration 15440: accuracy_at_1 = 79.69%; accuracy_at_5 = 98.05%; loss = 0.661923  (0.699874 s/it)
Iteration 15450: accuracy_at_1 = 80.47%; accuracy_at_5 = 96.09%; loss = 0.621002  (0.700365 s/it)
Iteration 15460: accuracy_at_1 = 78.52%; accuracy_at_5 = 97.66%; loss = 0.609612  (0.700077 s/it)
Iteration 15470: accuracy_at_1 = 76.56%; accuracy_at_5 = 94.53%; loss = 0.796620  (0.700313 s/it)
Iteration 15480: accuracy_at_1 = 76.17%; accuracy_at_5 = 98.05%; loss = 0.662442  (0.700203 s/it)
Iteration 15490: accuracy_at_1 = 77.34%; accuracy_at_5 = 96.09%; loss = 0.712432  (0.701154 s/it)
Iteration 15500: accuracy_at_1 = 76.56%; accuracy_at_5 = 94.92%; loss = 0.751310  (0.702180 s/it)
Iteration 15510: accuracy_at_1 = 76.17%; accuracy_at_5 = 95.70%; loss = 0.684839  (0.701041 s/it)
Iteration 15520: accuracy_at_1 = 71.09%; accuracy_at_5 = 95.31%; loss = 0.843938  (0.701047 s/it)
Iteration 15530: accuracy_at_1 = 76.56%; accuracy_at_5 = 96.09%; loss = 0.698952  (0.701707 s/it)
Iteration 15540: accuracy_at_1 = 77.73%; accuracy_at_5 = 95.70%; loss = 0.802981  (0.701730 s/it)
Iteration 15550: accuracy_at_1 = 81.64%; accuracy_at_5 = 95.70%; loss = 0.724294  (0.701824 s/it)
Iteration 15560: accuracy_at_1 = 78.91%; accuracy_at_5 = 97.27%; loss = 0.712523  (0.700693 s/it)
Iteration 15570: accuracy_at_1 = 77.34%; accuracy_at_5 = 95.31%; loss = 0.778063  (0.700402 s/it)
Iteration 15580: accuracy_at_1 = 79.30%; accuracy_at_5 = 97.27%; loss = 0.669178  (0.699755 s/it)
Iteration 15590: accuracy_at_1 = 78.12%; accuracy_at_5 = 92.58%; loss = 0.755598  (0.700251 s/it)
Iteration 15600: accuracy_at_1 = 81.25%; accuracy_at_5 = 97.27%; loss = 0.582935  (0.700113 s/it)
Iteration 15610: accuracy_at_1 = 79.69%; accuracy_at_5 = 96.09%; loss = 0.669006  (0.700288 s/it)
Iteration 15620: accuracy_at_1 = 76.95%; accuracy_at_5 = 95.70%; loss = 0.742774  (0.701358 s/it)
Iteration 15630: accuracy_at_1 = 83.98%; accuracy_at_5 = 98.44%; loss = 0.507482  (0.702649 s/it)
Iteration 15640: accuracy_at_1 = 80.47%; accuracy_at_5 = 97.66%; loss = 0.671166  (0.701544 s/it)
Iteration 15650: accuracy_at_1 = 82.03%; accuracy_at_5 = 97.66%; loss = 0.539297  (0.701242 s/it)
Iteration 15660: accuracy_at_1 = 76.17%; accuracy_at_5 = 96.48%; loss = 0.667893  (0.701253 s/it)
Iteration 15670: accuracy_at_1 = 77.73%; accuracy_at_5 = 96.48%; loss = 0.663536  (0.701141 s/it)
Iteration 15680: accuracy_at_1 = 79.69%; accuracy_at_5 = 97.27%; loss = 0.599735  (0.701306 s/it)
Iteration 15690: accuracy_at_1 = 79.69%; accuracy_at_5 = 98.05%; loss = 0.607648  (0.700477 s/it)
Iteration 15700: accuracy_at_1 = 81.64%; accuracy_at_5 = 96.48%; loss = 0.652908  (0.700389 s/it)
Iteration 15710: accuracy_at_1 = 78.12%; accuracy_at_5 = 97.66%; loss = 0.609735  (0.701571 s/it)
Iteration 15720: accuracy_at_1 = 78.91%; accuracy_at_5 = 96.48%; loss = 0.629899  (0.700811 s/it)
Iteration 15730: accuracy_at_1 = 80.47%; accuracy_at_5 = 97.66%; loss = 0.654211  (0.700955 s/it)
Iteration 15740: accuracy_at_1 = 78.12%; accuracy_at_5 = 96.88%; loss = 0.606106  (0.700885 s/it)
Iteration 15750: accuracy_at_1 = 79.69%; accuracy_at_5 = 97.66%; loss = 0.602569  (0.701433 s/it)
Iteration 15760: accuracy_at_1 = 78.12%; accuracy_at_5 = 94.53%; loss = 0.695271  (0.701775 s/it)
Iteration 15770: accuracy_at_1 = 75.00%; accuracy_at_5 = 93.75%; loss = 0.791486  (0.701479 s/it)
Iteration 15780: accuracy_at_1 = 80.08%; accuracy_at_5 = 96.88%; loss = 0.639818  (0.701618 s/it)
Iteration 15790: accuracy_at_1 = 78.52%; accuracy_at_5 = 95.31%; loss = 0.727239  (0.701652 s/it)
Iteration 15800: accuracy_at_1 = 76.56%; accuracy_at_5 = 97.27%; loss = 0.695437  (0.701158 s/it)
Iteration 15810: accuracy_at_1 = 78.52%; accuracy_at_5 = 96.48%; loss = 0.606800  (0.700950 s/it)
Iteration 15820: accuracy_at_1 = 80.47%; accuracy_at_5 = 97.27%; loss = 0.598913  (0.700645 s/it)
Iteration 15830: accuracy_at_1 = 81.25%; accuracy_at_5 = 97.27%; loss = 0.545309  (0.699881 s/it)
Iteration 15840: accuracy_at_1 = 78.12%; accuracy_at_5 = 99.22%; loss = 0.599762  (0.701052 s/it)
Iteration 15850: accuracy_at_1 = 80.47%; accuracy_at_5 = 98.05%; loss = 0.564363  (0.701938 s/it)
Iteration 15860: accuracy_at_1 = 82.42%; accuracy_at_5 = 96.88%; loss = 0.568679  (0.700692 s/it)
Iteration 15870: accuracy_at_1 = 82.03%; accuracy_at_5 = 95.70%; loss = 0.627775  (0.700580 s/it)
Iteration 15880: accuracy_at_1 = 78.91%; accuracy_at_5 = 96.48%; loss = 0.683352  (0.702281 s/it)
Iteration 15890: accuracy_at_1 = 82.42%; accuracy_at_5 = 96.88%; loss = 0.649703  (0.701419 s/it)
Iteration 15900: accuracy_at_1 = 78.12%; accuracy_at_5 = 97.66%; loss = 0.682148  (0.701902 s/it)
Iteration 15910: accuracy_at_1 = 82.81%; accuracy_at_5 = 97.27%; loss = 0.597893  (0.701281 s/it)
Iteration 15920: accuracy_at_1 = 82.81%; accuracy_at_5 = 98.05%; loss = 0.614752  (0.702123 s/it)
Iteration 15930: accuracy_at_1 = 80.86%; accuracy_at_5 = 97.66%; loss = 0.581512  (0.701971 s/it)
Iteration 15940: accuracy_at_1 = 76.17%; accuracy_at_5 = 96.09%; loss = 0.728686  (0.700747 s/it)
Iteration 15950: accuracy_at_1 = 77.34%; accuracy_at_5 = 96.48%; loss = 0.677490  (0.700534 s/it)
Iteration 15960: accuracy_at_1 = 83.20%; accuracy_at_5 = 99.22%; loss = 0.563290  (0.700934 s/it)
Iteration 15970: accuracy_at_1 = 83.20%; accuracy_at_5 = 97.27%; loss = 0.606297  (0.700558 s/it)
Iteration 15980: accuracy_at_1 = 78.52%; accuracy_at_5 = 94.53%; loss = 0.662732  (0.700538 s/it)
Iteration 15990: accuracy_at_1 = 80.08%; accuracy_at_5 = 96.09%; loss = 0.576420  (0.699901 s/it)
Iteration 16000: accuracy_at_1 = 80.47%; accuracy_at_5 = 94.92%; loss = 0.633810  (0.700627 s/it)
Iteration 16010: accuracy_at_1 = 80.47%; accuracy_at_5 = 98.05%; loss = 0.570449  (0.701404 s/it)
Iteration 16020: accuracy_at_1 = 80.47%; accuracy_at_5 = 96.48%; loss = 0.663419  (0.702473 s/it)
Iteration 16030: accuracy_at_1 = 80.86%; accuracy_at_5 = 99.22%; loss = 0.494036  (0.702285 s/it)
Iteration 16040: accuracy_at_1 = 87.11%; accuracy_at_5 = 97.66%; loss = 0.517922  (0.701501 s/it)
Iteration 16050: accuracy_at_1 = 81.64%; accuracy_at_5 = 98.83%; loss = 0.532218  (0.701619 s/it)
Iteration 16060: accuracy_at_1 = 79.69%; accuracy_at_5 = 98.05%; loss = 0.620566  (0.702028 s/it)
Iteration 16070: accuracy_at_1 = 85.16%; accuracy_at_5 = 98.05%; loss = 0.519849  (0.701093 s/it)
Iteration 16080: accuracy_at_1 = 81.25%; accuracy_at_5 = 97.66%; loss = 0.564411  (0.701097 s/it)
Iteration 16090: accuracy_at_1 = 80.86%; accuracy_at_5 = 98.44%; loss = 0.553030  (0.700655 s/it)
Iteration 16100: accuracy_at_1 = 79.69%; accuracy_at_5 = 99.22%; loss = 0.540325  (0.700321 s/it)
Iteration 16110: accuracy_at_1 = 84.77%; accuracy_at_5 = 96.88%; loss = 0.509844  (0.700213 s/it)
Iteration 16120: accuracy_at_1 = 81.64%; accuracy_at_5 = 98.44%; loss = 0.589098  (0.700098 s/it)
Iteration 16130: accuracy_at_1 = 84.38%; accuracy_at_5 = 96.88%; loss = 0.532980  (0.701589 s/it)
Iteration 16140: accuracy_at_1 = 83.98%; accuracy_at_5 = 98.05%; loss = 0.532624  (0.702011 s/it)
Iteration 16150: accuracy_at_1 = 80.86%; accuracy_at_5 = 98.83%; loss = 0.523615  (0.701573 s/it)
Iteration 16160: accuracy_at_1 = 80.08%; accuracy_at_5 = 97.27%; loss = 0.673408  (0.701857 s/it)
Iteration 16170: accuracy_at_1 = 80.47%; accuracy_at_5 = 97.27%; loss = 0.609980  (0.701554 s/it)
Iteration 16180: accuracy_at_1 = 80.86%; accuracy_at_5 = 96.88%; loss = 0.720030  (0.701739 s/it)
Iteration 16190: accuracy_at_1 = 78.52%; accuracy_at_5 = 96.88%; loss = 0.624809  (0.702144 s/it)
Iteration 16200: accuracy_at_1 = 80.08%; accuracy_at_5 = 96.48%; loss = 0.619249  (0.699954 s/it)
Iteration 16210: accuracy_at_1 = 76.17%; accuracy_at_5 = 96.88%; loss = 0.694229  (0.700086 s/it)
Iteration 16220: accuracy_at_1 = 80.47%; accuracy_at_5 = 98.44%; loss = 0.508855  (0.699964 s/it)
Iteration 16230: accuracy_at_1 = 83.20%; accuracy_at_5 = 98.44%; loss = 0.559476  (0.700047 s/it)
Iteration 16240: accuracy_at_1 = 78.91%; accuracy_at_5 = 98.05%; loss = 0.610552  (0.700380 s/it)
Iteration 16250: accuracy_at_1 = 79.30%; accuracy_at_5 = 96.88%; loss = 0.646364  (0.702269 s/it)
Iteration 16260: accuracy_at_1 = 83.20%; accuracy_at_5 = 98.44%; loss = 0.489805  (0.701397 s/it)
Iteration 16270: accuracy_at_1 = 82.81%; accuracy_at_5 = 97.66%; loss = 0.570897  (0.701553 s/it)
Iteration 16280: accuracy_at_1 = 83.59%; accuracy_at_5 = 98.05%; loss = 0.551767  (0.703665 s/it)
Iteration 16290: accuracy_at_1 = 80.47%; accuracy_at_5 = 98.83%; loss = 0.598069  (0.701734 s/it)
Iteration 16300: accuracy_at_1 = 75.78%; accuracy_at_5 = 96.88%; loss = 0.692054  (0.702298 s/it)
Iteration 16310: accuracy_at_1 = 76.95%; accuracy_at_5 = 98.83%; loss = 0.625496  (0.700937 s/it)
Iteration 16320: accuracy_at_1 = 78.12%; accuracy_at_5 = 98.05%; loss = 0.677304  (0.701372 s/it)
Iteration 16330: accuracy_at_1 = 83.59%; accuracy_at_5 = 98.44%; loss = 0.542569  (0.700639 s/it)
Iteration 16340: accuracy_at_1 = 83.20%; accuracy_at_5 = 96.09%; loss = 0.587996  (0.700457 s/it)
Iteration 16350: accuracy_at_1 = 78.91%; accuracy_at_5 = 96.48%; loss = 0.611026  (0.700168 s/it)
Iteration 16360: accuracy_at_1 = 76.95%; accuracy_at_5 = 97.27%; loss = 0.689581  (0.700634 s/it)
Iteration 16370: accuracy_at_1 = 81.64%; accuracy_at_5 = 98.83%; loss = 0.508570  (0.700166 s/it)
Iteration 16380: accuracy_at_1 = 82.03%; accuracy_at_5 = 97.66%; loss = 0.553610  (0.700261 s/it)
Iteration 16390: accuracy_at_1 = 80.86%; accuracy_at_5 = 97.27%; loss = 0.603243  (0.701724 s/it)
Iteration 16400: accuracy_at_1 = 82.03%; accuracy_at_5 = 96.88%; loss = 0.570349  (0.702441 s/it)
Iteration 16410: accuracy_at_1 = 83.59%; accuracy_at_5 = 99.22%; loss = 0.502218  (0.703281 s/it)
Iteration 16420: accuracy_at_1 = 82.03%; accuracy_at_5 = 96.88%; loss = 0.563155  (0.702579 s/it)
Iteration 16430: accuracy_at_1 = 80.08%; accuracy_at_5 = 97.66%; loss = 0.591685  (0.702122 s/it)
Iteration 16440: accuracy_at_1 = 82.81%; accuracy_at_5 = 99.22%; loss = 0.490042  (0.701495 s/it)
Iteration 16450: accuracy_at_1 = 85.16%; accuracy_at_5 = 98.83%; loss = 0.472093  (0.701550 s/it)
Iteration 16460: accuracy_at_1 = 77.73%; accuracy_at_5 = 97.27%; loss = 0.610716  (0.700205 s/it)
Iteration 16470: accuracy_at_1 = 83.59%; accuracy_at_5 = 98.05%; loss = 0.512900  (0.700619 s/it)
Iteration 16480: accuracy_at_1 = 82.42%; accuracy_at_5 = 97.27%; loss = 0.563058  (0.700537 s/it)
Iteration 16490: accuracy_at_1 = 86.72%; accuracy_at_5 = 98.83%; loss = 0.431212  (0.701300 s/it)
Iteration 16500: accuracy_at_1 = 83.59%; accuracy_at_5 = 98.44%; loss = 0.526714  (0.700876 s/it)
Iteration 16510: accuracy_at_1 = 83.59%; accuracy_at_5 = 97.66%; loss = 0.505091  (0.700972 s/it)
Iteration 16520: accuracy_at_1 = 75.00%; accuracy_at_5 = 96.88%; loss = 0.672253  (0.701838 s/it)
Iteration 16530: accuracy_at_1 = 82.81%; accuracy_at_5 = 97.66%; loss = 0.572846  (0.701877 s/it)
Iteration 16540: accuracy_at_1 = 78.12%; accuracy_at_5 = 96.48%; loss = 0.599416  (0.701135 s/it)
Iteration 16550: accuracy_at_1 = 77.34%; accuracy_at_5 = 96.88%; loss = 0.720323  (0.701396 s/it)
Iteration 16560: accuracy_at_1 = 87.89%; accuracy_at_5 = 98.05%; loss = 0.416580  (0.701478 s/it)
Iteration 16570: accuracy_at_1 = 86.33%; accuracy_at_5 = 97.66%; loss = 0.503799  (0.701763 s/it)
Iteration 16580: accuracy_at_1 = 82.81%; accuracy_at_5 = 96.88%; loss = 0.587305  (0.701138 s/it)
Iteration 16590: accuracy_at_1 = 84.38%; accuracy_at_5 = 95.70%; loss = 0.553003  (0.699919 s/it)
Iteration 16600: accuracy_at_1 = 85.55%; accuracy_at_5 = 96.09%; loss = 0.545031  (0.700713 s/it)
Iteration 16610: accuracy_at_1 = 76.17%; accuracy_at_5 = 97.66%; loss = 0.651994  (0.700261 s/it)
Iteration 16620: accuracy_at_1 = 78.52%; accuracy_at_5 = 98.83%; loss = 0.677154  (0.700774 s/it)
Iteration 16630: accuracy_at_1 = 82.03%; accuracy_at_5 = 98.44%; loss = 0.544041  (0.700803 s/it)
Iteration 16640: accuracy_at_1 = 86.33%; accuracy_at_5 = 99.61%; loss = 0.405001  (0.700518 s/it)
Iteration 16650: accuracy_at_1 = 83.59%; accuracy_at_5 = 98.44%; loss = 0.508829  (0.701499 s/it)
Iteration 16660: accuracy_at_1 = 85.55%; accuracy_at_5 = 98.83%; loss = 0.429953  (0.702176 s/it)
Iteration 16670: accuracy_at_1 = 85.16%; accuracy_at_5 = 98.83%; loss = 0.497177  (0.702463 s/it)
Iteration 16680: accuracy_at_1 = 80.86%; accuracy_at_5 = 95.31%; loss = 0.632970  (0.701889 s/it)
Iteration 16690: accuracy_at_1 = 82.42%; accuracy_at_5 = 97.27%; loss = 0.538579  (0.701460 s/it)
Iteration 16700: accuracy_at_1 = 79.30%; accuracy_at_5 = 96.88%; loss = 0.601662  (0.701424 s/it)
Iteration 16710: accuracy_at_1 = 80.08%; accuracy_at_5 = 96.88%; loss = 0.618272  (0.701207 s/it)
Iteration 16720: accuracy_at_1 = 77.73%; accuracy_at_5 = 97.27%; loss = 0.656848  (0.700720 s/it)
Iteration 16730: accuracy_at_1 = 85.94%; accuracy_at_5 = 99.22%; loss = 0.425043  (0.700953 s/it)
Iteration 16740: accuracy_at_1 = 80.08%; accuracy_at_5 = 94.92%; loss = 0.635669  (0.700627 s/it)
Iteration 16750: accuracy_at_1 = 83.98%; accuracy_at_5 = 98.05%; loss = 0.508560  (0.701063 s/it)
Iteration 16760: accuracy_at_1 = 80.47%; accuracy_at_5 = 96.48%; loss = 0.596025  (0.700617 s/it)
Iteration 16770: accuracy_at_1 = 86.33%; accuracy_at_5 = 96.88%; loss = 0.471097  (0.700882 s/it)
Iteration 16780: accuracy_at_1 = 83.59%; accuracy_at_5 = 98.05%; loss = 0.505054  (0.701919 s/it)
Iteration 16790: accuracy_at_1 = 82.42%; accuracy_at_5 = 98.05%; loss = 0.503510  (0.701839 s/it)
Iteration 16800: accuracy_at_1 = 83.20%; accuracy_at_5 = 99.22%; loss = 0.468812  (0.704317 s/it)
Iteration 16810: accuracy_at_1 = 84.38%; accuracy_at_5 = 98.44%; loss = 0.463504  (0.702908 s/it)
Iteration 16820: accuracy_at_1 = 85.94%; accuracy_at_5 = 98.83%; loss = 0.436191  (0.702807 s/it)
Iteration 16830: accuracy_at_1 = 87.11%; accuracy_at_5 = 99.61%; loss = 0.382649  (0.701336 s/it)
Iteration 16840: accuracy_at_1 = 83.98%; accuracy_at_5 = 98.83%; loss = 0.520750  (0.700937 s/it)
Iteration 16850: accuracy_at_1 = 84.77%; accuracy_at_5 = 98.44%; loss = 0.449861  (0.700154 s/it)
Iteration 16860: accuracy_at_1 = 82.42%; accuracy_at_5 = 98.05%; loss = 0.504927  (0.699469 s/it)
Iteration 16870: accuracy_at_1 = 83.98%; accuracy_at_5 = 98.44%; loss = 0.457371  (0.699985 s/it)
Iteration 16880: accuracy_at_1 = 83.98%; accuracy_at_5 = 98.83%; loss = 0.481280  (0.699834 s/it)
Iteration 16890: accuracy_at_1 = 82.81%; accuracy_at_5 = 98.44%; loss = 0.524373  (0.700064 s/it)
Iteration 16900: accuracy_at_1 = 83.20%; accuracy_at_5 = 98.83%; loss = 0.485532  (0.701294 s/it)
Iteration 16910: accuracy_at_1 = 85.94%; accuracy_at_5 = 99.22%; loss = 0.452730  (0.701530 s/it)
Iteration 16920: accuracy_at_1 = 80.86%; accuracy_at_5 = 97.66%; loss = 0.539786  (0.701474 s/it)
Iteration 16930: accuracy_at_1 = 84.77%; accuracy_at_5 = 98.44%; loss = 0.439263  (0.702204 s/it)
Iteration 16940: accuracy_at_1 = 82.42%; accuracy_at_5 = 98.44%; loss = 0.511715  (0.702022 s/it)
Iteration 16950: accuracy_at_1 = 80.08%; accuracy_at_5 = 98.83%; loss = 0.564435  (0.701271 s/it)
Iteration 16960: accuracy_at_1 = 83.59%; accuracy_at_5 = 99.22%; loss = 0.461897  (0.702430 s/it)
Iteration 16970: accuracy_at_1 = 81.64%; accuracy_at_5 = 98.44%; loss = 0.584712  (0.701145 s/it)
Iteration 16980: accuracy_at_1 = 83.20%; accuracy_at_5 = 99.61%; loss = 0.421851  (0.700386 s/it)
Iteration 16990: accuracy_at_1 = 82.03%; accuracy_at_5 = 97.27%; loss = 0.516828  (0.700268 s/it)
Iteration 17000: accuracy_at_1 = 84.38%; accuracy_at_5 = 98.05%; loss = 0.490357  (0.700283 s/it)
Iteration 17010: accuracy_at_1 = 83.20%; accuracy_at_5 = 97.66%; loss = 0.516262  (0.700260 s/it)
Iteration 17020: accuracy_at_1 = 84.38%; accuracy_at_5 = 98.05%; loss = 0.465326  (0.700989 s/it)
Iteration 17030: accuracy_at_1 = 83.20%; accuracy_at_5 = 96.88%; loss = 0.514261  (0.701510 s/it)
Iteration 17040: accuracy_at_1 = 84.77%; accuracy_at_5 = 98.44%; loss = 0.509301  (0.701418 s/it)
Iteration 17050: accuracy_at_1 = 79.69%; accuracy_at_5 = 98.83%; loss = 0.558145  (0.701751 s/it)
Iteration 17060: accuracy_at_1 = 83.59%; accuracy_at_5 = 98.44%; loss = 0.485736  (0.701849 s/it)
Iteration 17070: accuracy_at_1 = 84.38%; accuracy_at_5 = 98.44%; loss = 0.460749  (0.702130 s/it)
Iteration 17080: accuracy_at_1 = 79.30%; accuracy_at_5 = 97.66%; loss = 0.614834  (0.701895 s/it)
Iteration 17090: accuracy_at_1 = 83.59%; accuracy_at_5 = 98.05%; loss = 0.508726  (0.701249 s/it)
Iteration 17100: accuracy_at_1 = 82.42%; accuracy_at_5 = 97.66%; loss = 0.527079  (0.699924 s/it)
Iteration 17110: accuracy_at_1 = 85.16%; accuracy_at_5 = 98.83%; loss = 0.423208  (0.700823 s/it)
Iteration 17120: accuracy_at_1 = 80.08%; accuracy_at_5 = 97.27%; loss = 0.603859  (0.700473 s/it)
Iteration 17130: accuracy_at_1 = 80.08%; accuracy_at_5 = 98.44%; loss = 0.574391  (0.700673 s/it)
Iteration 17140: accuracy_at_1 = 84.38%; accuracy_at_5 = 98.83%; loss = 0.471757  (0.700382 s/it)
Iteration 17150: accuracy_at_1 = 84.77%; accuracy_at_5 = 98.44%; loss = 0.481918  (0.700977 s/it)
Iteration 17160: accuracy_at_1 = 85.16%; accuracy_at_5 = 97.66%; loss = 0.510909  (0.702327 s/it)
Iteration 17170: accuracy_at_1 = 80.47%; accuracy_at_5 = 97.66%; loss = 0.596703  (0.701178 s/it)
Iteration 17180: accuracy_at_1 = 85.94%; accuracy_at_5 = 98.44%; loss = 0.489901  (0.702027 s/it)
Iteration 17190: accuracy_at_1 = 85.55%; accuracy_at_5 = 99.22%; loss = 0.383422  (0.702905 s/it)
Iteration 17200: accuracy_at_1 = 82.81%; accuracy_at_5 = 98.44%; loss = 0.480205  (0.701899 s/it)
Iteration 17210: accuracy_at_1 = 88.28%; accuracy_at_5 = 99.22%; loss = 0.370682  (0.702172 s/it)
Iteration 17220: accuracy_at_1 = 86.72%; accuracy_at_5 = 99.22%; loss = 0.424207  (0.701321 s/it)
Iteration 17230: accuracy_at_1 = 80.86%; accuracy_at_5 = 98.05%; loss = 0.551651  (0.701096 s/it)
Iteration 17240: accuracy_at_1 = 85.94%; accuracy_at_5 = 98.83%; loss = 0.454902  (0.700297 s/it)
Iteration 17250: accuracy_at_1 = 82.81%; accuracy_at_5 = 98.83%; loss = 0.551816  (0.700524 s/it)
Iteration 17260: accuracy_at_1 = 84.38%; accuracy_at_5 = 98.05%; loss = 0.491644  (0.700156 s/it)
Iteration 17270: accuracy_at_1 = 83.59%; accuracy_at_5 = 99.61%; loss = 0.478731  (0.701052 s/it)
Iteration 17280: accuracy_at_1 = 87.89%; accuracy_at_5 = 98.83%; loss = 0.435641  (0.701574 s/it)
Iteration 17290: accuracy_at_1 = 81.25%; accuracy_at_5 = 98.83%; loss = 0.527400  (0.701711 s/it)
Iteration 17300: accuracy_at_1 = 84.77%; accuracy_at_5 = 98.83%; loss = 0.430292  (0.701606 s/it)
Iteration 17310: accuracy_at_1 = 83.20%; accuracy_at_5 = 98.44%; loss = 0.504729  (0.701126 s/it)
Iteration 17320: accuracy_at_1 = 85.55%; accuracy_at_5 = 99.61%; loss = 0.447580  (0.701347 s/it)
Iteration 17330: accuracy_at_1 = 82.42%; accuracy_at_5 = 97.66%; loss = 0.525677  (0.701698 s/it)
Iteration 17340: accuracy_at_1 = 85.94%; accuracy_at_5 = 98.05%; loss = 0.447063  (0.702770 s/it)
Iteration 17350: accuracy_at_1 = 86.33%; accuracy_at_5 = 98.05%; loss = 0.382858  (0.700952 s/it)
Iteration 17360: accuracy_at_1 = 87.11%; accuracy_at_5 = 99.22%; loss = 0.456831  (0.700857 s/it)
Iteration 17370: accuracy_at_1 = 86.33%; accuracy_at_5 = 99.22%; loss = 0.432555  (0.700816 s/it)
Iteration 17380: accuracy_at_1 = 83.59%; accuracy_at_5 = 99.61%; loss = 0.508665  (0.700580 s/it)
Iteration 17390: accuracy_at_1 = 86.33%; accuracy_at_5 = 99.61%; loss = 0.417232  (0.700066 s/it)
Iteration 17400: accuracy_at_1 = 86.72%; accuracy_at_5 = 97.66%; loss = 0.476404  (0.700685 s/it)
Iteration 17410: accuracy_at_1 = 83.98%; accuracy_at_5 = 100.00%; loss = 0.449262  (0.700726 s/it)
Iteration 17420: accuracy_at_1 = 84.77%; accuracy_at_5 = 99.22%; loss = 0.455059  (0.701186 s/it)
Iteration 17430: accuracy_at_1 = 83.59%; accuracy_at_5 = 100.00%; loss = 0.494620  (0.701960 s/it)
Iteration 17440: accuracy_at_1 = 84.38%; accuracy_at_5 = 98.44%; loss = 0.520668  (0.701094 s/it)
Iteration 17450: accuracy_at_1 = 89.45%; accuracy_at_5 = 99.61%; loss = 0.393629  (0.701788 s/it)
Iteration 17460: accuracy_at_1 = 86.72%; accuracy_at_5 = 99.22%; loss = 0.380934  (0.701823 s/it)
Iteration 17470: accuracy_at_1 = 85.94%; accuracy_at_5 = 98.83%; loss = 0.452494  (0.702196 s/it)
Iteration 17480: accuracy_at_1 = 84.38%; accuracy_at_5 = 98.44%; loss = 0.475907  (0.700670 s/it)
Iteration 17490: accuracy_at_1 = 87.89%; accuracy_at_5 = 97.66%; loss = 0.461334  (0.700559 s/it)
Iteration 17500: accuracy_at_1 = 84.38%; accuracy_at_5 = 98.83%; loss = 0.502658  (0.700308 s/it)
Iteration 17510: accuracy_at_1 = 86.72%; accuracy_at_5 = 96.48%; loss = 0.543756  (0.699923 s/it)
Iteration 17520: accuracy_at_1 = 86.72%; accuracy_at_5 = 97.66%; loss = 0.437154  (0.701848 s/it)
Iteration 17530: accuracy_at_1 = 86.72%; accuracy_at_5 = 99.22%; loss = 0.395778  (0.700215 s/it)
Iteration 17540: accuracy_at_1 = 85.55%; accuracy_at_5 = 97.27%; loss = 0.540907  (0.701215 s/it)
Iteration 17550: accuracy_at_1 = 88.28%; accuracy_at_5 = 99.22%; loss = 0.406243  (0.701263 s/it)
Iteration 17560: accuracy_at_1 = 82.81%; accuracy_at_5 = 98.05%; loss = 0.512112  (0.702031 s/it)
Iteration 17570: accuracy_at_1 = 84.38%; accuracy_at_5 = 98.83%; loss = 0.479558  (0.701373 s/it)
Iteration 17580: accuracy_at_1 = 87.50%; accuracy_at_5 = 97.66%; loss = 0.440840  (0.702862 s/it)
Iteration 17590: accuracy_at_1 = 86.33%; accuracy_at_5 = 98.83%; loss = 0.420238  (0.701759 s/it)
Iteration 17600: accuracy_at_1 = 87.11%; accuracy_at_5 = 98.44%; loss = 0.408794  (0.702202 s/it)
Iteration 17610: accuracy_at_1 = 83.59%; accuracy_at_5 = 97.66%; loss = 0.460275  (0.699693 s/it)
Iteration 17620: accuracy_at_1 = 84.77%; accuracy_at_5 = 98.83%; loss = 0.424810  (0.700693 s/it)
Iteration 17630: accuracy_at_1 = 85.16%; accuracy_at_5 = 99.22%; loss = 0.446487  (0.700445 s/it)
Iteration 17640: accuracy_at_1 = 90.62%; accuracy_at_5 = 99.22%; loss = 0.322947  (0.699910 s/it)
Iteration 17650: accuracy_at_1 = 88.67%; accuracy_at_5 = 100.00%; loss = 0.377375  (0.700507 s/it)
Iteration 17660: accuracy_at_1 = 89.45%; accuracy_at_5 = 98.44%; loss = 0.383598  (0.700707 s/it)
Iteration 17670: accuracy_at_1 = 85.94%; accuracy_at_5 = 99.22%; loss = 0.449355  (0.702057 s/it)
Iteration 17680: accuracy_at_1 = 85.16%; accuracy_at_5 = 100.00%; loss = 0.370300  (0.700729 s/it)
Iteration 17690: accuracy_at_1 = 85.55%; accuracy_at_5 = 98.83%; loss = 0.413470  (0.701409 s/it)
Iteration 17700: accuracy_at_1 = 87.11%; accuracy_at_5 = 98.05%; loss = 0.450623  (0.701406 s/it)
Iteration 17710: accuracy_at_1 = 84.38%; accuracy_at_5 = 98.44%; loss = 0.481288  (0.701861 s/it)
Iteration 17720: accuracy_at_1 = 87.11%; accuracy_at_5 = 98.44%; loss = 0.438532  (0.701343 s/it)
Iteration 17730: accuracy_at_1 = 84.77%; accuracy_at_5 = 100.00%; loss = 0.456422  (0.701531 s/it)
Iteration 17740: accuracy_at_1 = 86.33%; accuracy_at_5 = 98.83%; loss = 0.431244  (0.701073 s/it)
Iteration 17750: accuracy_at_1 = 83.98%; accuracy_at_5 = 97.27%; loss = 0.533013  (0.699749 s/it)
Iteration 17760: accuracy_at_1 = 81.64%; accuracy_at_5 = 95.70%; loss = 0.602127  (0.700011 s/it)
Iteration 17770: accuracy_at_1 = 84.38%; accuracy_at_5 = 97.66%; loss = 0.522985  (0.700288 s/it)
Iteration 17780: accuracy_at_1 = 85.55%; accuracy_at_5 = 98.83%; loss = 0.421716  (0.700739 s/it)
Iteration 17790: accuracy_at_1 = 85.55%; accuracy_at_5 = 99.22%; loss = 0.412097  (0.700289 s/it)
Iteration 17800: accuracy_at_1 = 82.03%; accuracy_at_5 = 98.05%; loss = 0.512138  (0.700946 s/it)
Iteration 17810: accuracy_at_1 = 87.11%; accuracy_at_5 = 98.83%; loss = 0.406035  (0.701369 s/it)
Iteration 17820: accuracy_at_1 = 85.55%; accuracy_at_5 = 99.61%; loss = 0.412650  (0.701656 s/it)
Iteration 17830: accuracy_at_1 = 82.03%; accuracy_at_5 = 98.05%; loss = 0.541770  (0.701758 s/it)
Iteration 17840: accuracy_at_1 = 81.64%; accuracy_at_5 = 98.83%; loss = 0.481172  (0.701431 s/it)
Iteration 17850: accuracy_at_1 = 85.94%; accuracy_at_5 = 98.83%; loss = 0.420792  (0.701482 s/it)
Iteration 17860: accuracy_at_1 = 86.33%; accuracy_at_5 = 98.83%; loss = 0.467551  (0.701232 s/it)
Iteration 17870: accuracy_at_1 = 84.77%; accuracy_at_5 = 98.05%; loss = 0.467586  (0.700747 s/it)
Iteration 17880: accuracy_at_1 = 82.42%; accuracy_at_5 = 100.00%; loss = 0.477219  (0.699943 s/it)
Iteration 17890: accuracy_at_1 = 85.94%; accuracy_at_5 = 98.05%; loss = 0.489108  (0.701459 s/it)
Iteration 17900: accuracy_at_1 = 85.94%; accuracy_at_5 = 98.83%; loss = 0.394612  (0.700524 s/it)
Iteration 17910: accuracy_at_1 = 88.28%; accuracy_at_5 = 98.83%; loss = 0.370014  (0.700283 s/it)
Iteration 17920: accuracy_at_1 = 83.59%; accuracy_at_5 = 98.83%; loss = 0.498372  (0.700674 s/it)
Iteration 17930: accuracy_at_1 = 85.16%; accuracy_at_5 = 98.83%; loss = 0.441787  (0.701553 s/it)
Iteration 17940: accuracy_at_1 = 83.20%; accuracy_at_5 = 98.83%; loss = 0.527810  (0.701972 s/it)
Iteration 17950: accuracy_at_1 = 88.28%; accuracy_at_5 = 99.61%; loss = 0.401118  (0.701709 s/it)
Iteration 17960: accuracy_at_1 = 84.77%; accuracy_at_5 = 97.66%; loss = 0.455405  (0.701001 s/it)
Iteration 17970: accuracy_at_1 = 85.94%; accuracy_at_5 = 99.22%; loss = 0.395476  (0.702831 s/it)
Iteration 17980: accuracy_at_1 = 86.33%; accuracy_at_5 = 98.83%; loss = 0.433445  (0.700813 s/it)
Iteration 17990: accuracy_at_1 = 88.67%; accuracy_at_5 = 99.61%; loss = 0.352809  (0.700270 s/it)
Iteration 18000: accuracy_at_1 = 85.55%; accuracy_at_5 = 98.83%; loss = 0.402485  (0.700820 s/it)
Iteration 18010: accuracy_at_1 = 88.28%; accuracy_at_5 = 99.22%; loss = 0.372473  (0.700313 s/it)
Iteration 18020: accuracy_at_1 = 88.28%; accuracy_at_5 = 98.83%; loss = 0.363516  (0.700159 s/it)
Iteration 18030: accuracy_at_1 = 89.45%; accuracy_at_5 = 99.61%; loss = 0.317016  (0.700032 s/it)
Iteration 18040: accuracy_at_1 = 90.23%; accuracy_at_5 = 98.05%; loss = 0.396265  (0.700050 s/it)
Iteration 18050: accuracy_at_1 = 85.94%; accuracy_at_5 = 98.44%; loss = 0.442355  (0.700706 s/it)
Iteration 18060: accuracy_at_1 = 89.06%; accuracy_at_5 = 99.22%; loss = 0.345355  (0.701397 s/it)
Iteration 18070: accuracy_at_1 = 86.33%; accuracy_at_5 = 100.00%; loss = 0.404983  (0.702038 s/it)
Iteration 18080: accuracy_at_1 = 90.23%; accuracy_at_5 = 98.83%; loss = 0.338010  (0.702693 s/it)
Iteration 18090: accuracy_at_1 = 85.94%; accuracy_at_5 = 99.22%; loss = 0.437423  (0.701678 s/it)
Iteration 18100: accuracy_at_1 = 87.89%; accuracy_at_5 = 98.05%; loss = 0.431892  (0.700998 s/it)
Iteration 18110: accuracy_at_1 = 85.16%; accuracy_at_5 = 100.00%; loss = 0.389134  (0.701884 s/it)
Iteration 18120: accuracy_at_1 = 86.72%; accuracy_at_5 = 99.61%; loss = 0.398317  (0.700654 s/it)
Iteration 18130: accuracy_at_1 = 87.50%; accuracy_at_5 = 98.83%; loss = 0.381608  (0.700852 s/it)
Iteration 18140: accuracy_at_1 = 87.89%; accuracy_at_5 = 98.83%; loss = 0.384798  (0.700746 s/it)
Iteration 18150: accuracy_at_1 = 84.38%; accuracy_at_5 = 99.22%; loss = 0.463365  (0.699685 s/it)
Iteration 18160: accuracy_at_1 = 89.06%; accuracy_at_5 = 99.22%; loss = 0.341947  (0.699571 s/it)
Iteration 18170: accuracy_at_1 = 87.11%; accuracy_at_5 = 98.83%; loss = 0.417685  (0.699819 s/it)
Iteration 18180: accuracy_at_1 = 86.33%; accuracy_at_5 = 98.83%; loss = 0.387519  (0.701257 s/it)
Iteration 18190: accuracy_at_1 = 86.72%; accuracy_at_5 = 99.22%; loss = 0.356687  (0.701721 s/it)
Iteration 18200: accuracy_at_1 = 80.86%; accuracy_at_5 = 97.66%; loss = 0.551543  (0.701431 s/it)
Iteration 18210: accuracy_at_1 = 84.38%; accuracy_at_5 = 97.66%; loss = 0.458685  (0.701486 s/it)
Iteration 18220: accuracy_at_1 = 87.50%; accuracy_at_5 = 99.22%; loss = 0.423868  (0.702713 s/it)
Iteration 18230: accuracy_at_1 = 86.33%; accuracy_at_5 = 98.83%; loss = 0.459033  (0.701500 s/it)
Iteration 18240: accuracy_at_1 = 84.77%; accuracy_at_5 = 98.83%; loss = 0.419272  (0.701213 s/it)
Iteration 18250: accuracy_at_1 = 84.77%; accuracy_at_5 = 98.83%; loss = 0.452339  (0.700633 s/it)
Iteration 18260: accuracy_at_1 = 83.98%; accuracy_at_5 = 99.22%; loss = 0.444068  (0.700503 s/it)
Iteration 18270: accuracy_at_1 = 89.06%; accuracy_at_5 = 98.44%; loss = 0.361046  (0.700168 s/it)
Iteration 18280: accuracy_at_1 = 89.45%; accuracy_at_5 = 98.83%; loss = 0.374439  (0.700396 s/it)
Iteration 18290: accuracy_at_1 = 86.72%; accuracy_at_5 = 98.83%; loss = 0.384546  (0.700428 s/it)
Iteration 18300: accuracy_at_1 = 87.89%; accuracy_at_5 = 99.61%; loss = 0.410842  (0.700364 s/it)
Iteration 18310: accuracy_at_1 = 83.98%; accuracy_at_5 = 99.61%; loss = 0.435980  (0.702016 s/it)
Iteration 18320: accuracy_at_1 = 87.11%; accuracy_at_5 = 98.44%; loss = 0.495288  (0.701291 s/it)
Iteration 18330: accuracy_at_1 = 88.67%; accuracy_at_5 = 99.61%; loss = 0.366191  (0.700909 s/it)
Iteration 18340: accuracy_at_1 = 84.77%; accuracy_at_5 = 98.05%; loss = 0.525732  (0.701815 s/it)
Iteration 18350: accuracy_at_1 = 86.33%; accuracy_at_5 = 99.61%; loss = 0.374403  (0.701568 s/it)
Iteration 18360: accuracy_at_1 = 89.45%; accuracy_at_5 = 99.22%; loss = 0.372343  (0.702056 s/it)
Iteration 18370: accuracy_at_1 = 84.38%; accuracy_at_5 = 98.44%; loss = 0.494766  (0.700565 s/it)
Iteration 18380: accuracy_at_1 = 87.89%; accuracy_at_5 = 99.22%; loss = 0.391948  (0.700240 s/it)
Iteration 18390: accuracy_at_1 = 86.33%; accuracy_at_5 = 99.61%; loss = 0.407561  (0.700522 s/it)
Iteration 18400: accuracy_at_1 = 87.89%; accuracy_at_5 = 99.22%; loss = 0.386929  (0.699959 s/it)
Iteration 18410: accuracy_at_1 = 89.45%; accuracy_at_5 = 99.61%; loss = 0.344441  (0.700744 s/it)
Iteration 18420: accuracy_at_1 = 87.89%; accuracy_at_5 = 98.05%; loss = 0.422040  (0.700928 s/it)
Iteration 18430: accuracy_at_1 = 86.33%; accuracy_at_5 = 99.61%; loss = 0.344133  (0.701093 s/it)
Iteration 18440: accuracy_at_1 = 84.77%; accuracy_at_5 = 97.27%; loss = 0.514322  (0.701855 s/it)
Iteration 18450: accuracy_at_1 = 90.62%; accuracy_at_5 = 100.00%; loss = 0.281390  (0.702567 s/it)
Iteration 18460: accuracy_at_1 = 90.23%; accuracy_at_5 = 99.61%; loss = 0.312650  (0.701079 s/it)
Iteration 18470: accuracy_at_1 = 88.28%; accuracy_at_5 = 99.61%; loss = 0.332596  (0.701400 s/it)
Iteration 18480: accuracy_at_1 = 88.28%; accuracy_at_5 = 99.22%; loss = 0.389433  (0.701435 s/it)
Iteration 18490: accuracy_at_1 = 85.94%; accuracy_at_5 = 99.22%; loss = 0.425105  (0.701426 s/it)
Iteration 18500: accuracy_at_1 = 85.94%; accuracy_at_5 = 98.83%; loss = 0.376258  (0.701219 s/it)
Iteration 18510: accuracy_at_1 = 87.11%; accuracy_at_5 = 99.61%; loss = 0.377442  (0.700135 s/it)
Iteration 18520: accuracy_at_1 = 89.06%; accuracy_at_5 = 98.44%; loss = 0.365066  (0.700059 s/it)
Iteration 18530: accuracy_at_1 = 87.89%; accuracy_at_5 = 98.44%; loss = 0.438105  (0.700270 s/it)
Iteration 18540: accuracy_at_1 = 84.77%; accuracy_at_5 = 98.83%; loss = 0.425503  (0.700001 s/it)
Iteration 18550: accuracy_at_1 = 88.67%; accuracy_at_5 = 100.00%; loss = 0.337981  (0.700711 s/it)
Iteration 18560: accuracy_at_1 = 88.28%; accuracy_at_5 = 99.61%; loss = 0.359692  (0.701187 s/it)
Iteration 18570: accuracy_at_1 = 87.11%; accuracy_at_5 = 98.83%; loss = 0.420964  (0.701787 s/it)
Iteration 18580: accuracy_at_1 = 85.16%; accuracy_at_5 = 98.05%; loss = 0.453825  (0.701613 s/it)
Iteration 18590: accuracy_at_1 = 87.11%; accuracy_at_5 = 99.61%; loss = 0.341007  (0.701997 s/it)
Iteration 18600: accuracy_at_1 = 80.86%; accuracy_at_5 = 98.83%; loss = 0.486109  (0.701458 s/it)
Iteration 18610: accuracy_at_1 = 90.23%; accuracy_at_5 = 98.83%; loss = 0.367933  (0.701355 s/it)
Iteration 18620: accuracy_at_1 = 88.28%; accuracy_at_5 = 99.22%; loss = 0.368344  (0.701825 s/it)
Iteration 18630: accuracy_at_1 = 87.89%; accuracy_at_5 = 99.22%; loss = 0.369906  (0.700621 s/it)
Iteration 18640: accuracy_at_1 = 87.11%; accuracy_at_5 = 98.83%; loss = 0.399188  (0.701433 s/it)
Iteration 18650: accuracy_at_1 = 89.45%; accuracy_at_5 = 99.61%; loss = 0.305837  (0.701699 s/it)
Iteration 18660: accuracy_at_1 = 87.89%; accuracy_at_5 = 98.44%; loss = 0.415359  (0.701160 s/it)
Iteration 18670: accuracy_at_1 = 86.72%; accuracy_at_5 = 98.83%; loss = 0.385573  (0.700297 s/it)
Iteration 18680: accuracy_at_1 = 83.20%; accuracy_at_5 = 98.44%; loss = 0.442242  (0.699913 s/it)
Iteration 18690: accuracy_at_1 = 87.50%; accuracy_at_5 = 98.44%; loss = 0.411930  (0.700693 s/it)
Iteration 18700: accuracy_at_1 = 88.28%; accuracy_at_5 = 98.44%; loss = 0.367063  (0.700866 s/it)
Iteration 18710: accuracy_at_1 = 87.89%; accuracy_at_5 = 99.61%; loss = 0.365556  (0.701570 s/it)
Iteration 18720: accuracy_at_1 = 89.06%; accuracy_at_5 = 99.61%; loss = 0.364286  (0.701821 s/it)
Iteration 18730: accuracy_at_1 = 85.55%; accuracy_at_5 = 98.83%; loss = 0.397583  (0.701619 s/it)
Iteration 18740: accuracy_at_1 = 89.45%; accuracy_at_5 = 99.61%; loss = 0.340089  (0.701161 s/it)
Iteration 18750: accuracy_at_1 = 89.06%; accuracy_at_5 = 99.22%; loss = 0.387357  (0.702726 s/it)
Iteration 18760: accuracy_at_1 = 89.45%; accuracy_at_5 = 98.83%; loss = 0.350919  (0.700575 s/it)
Iteration 18770: accuracy_at_1 = 89.45%; accuracy_at_5 = 98.05%; loss = 0.353091  (0.700453 s/it)
Iteration 18780: accuracy_at_1 = 89.45%; accuracy_at_5 = 100.00%; loss = 0.290916  (0.700646 s/it)
Iteration 18790: accuracy_at_1 = 89.45%; accuracy_at_5 = 99.61%; loss = 0.340797  (0.700105 s/it)
Iteration 18800: accuracy_at_1 = 88.28%; accuracy_at_5 = 98.83%; loss = 0.365648  (0.700475 s/it)
Iteration 18810: accuracy_at_1 = 87.11%; accuracy_at_5 = 99.22%; loss = 0.355010  (0.700803 s/it)
Iteration 18820: accuracy_at_1 = 89.84%; accuracy_at_5 = 99.61%; loss = 0.333687  (0.701371 s/it)
Iteration 18830: accuracy_at_1 = 83.59%; accuracy_at_5 = 99.22%; loss = 0.380396  (0.701067 s/it)
Iteration 18840: accuracy_at_1 = 91.41%; accuracy_at_5 = 100.00%; loss = 0.277133  (0.701205 s/it)
Iteration 18850: accuracy_at_1 = 90.23%; accuracy_at_5 = 99.22%; loss = 0.404123  (0.701528 s/it)
Iteration 18860: accuracy_at_1 = 88.67%; accuracy_at_5 = 99.61%; loss = 0.347503  (0.701333 s/it)
Iteration 18870: accuracy_at_1 = 91.80%; accuracy_at_5 = 99.61%; loss = 0.282499  (0.701882 s/it)
Iteration 18880: accuracy_at_1 = 88.28%; accuracy_at_5 = 99.61%; loss = 0.304665  (0.701238 s/it)
Iteration 18890: accuracy_at_1 = 88.28%; accuracy_at_5 = 100.00%; loss = 0.331846  (0.700336 s/it)
Iteration 18900: accuracy_at_1 = 91.02%; accuracy_at_5 = 99.61%; loss = 0.321012  (0.700810 s/it)
Iteration 18910: accuracy_at_1 = 91.02%; accuracy_at_5 = 99.61%; loss = 0.328004  (0.701044 s/it)
Iteration 18920: accuracy_at_1 = 87.89%; accuracy_at_5 = 99.22%; loss = 0.355296  (0.700225 s/it)
Iteration 18930: accuracy_at_1 = 90.23%; accuracy_at_5 = 99.22%; loss = 0.342022  (0.699986 s/it)
Iteration 18940: accuracy_at_1 = 85.16%; accuracy_at_5 = 99.22%; loss = 0.389164  (0.700033 s/it)
Iteration 18950: accuracy_at_1 = 89.45%; accuracy_at_5 = 100.00%; loss = 0.329472  (0.701509 s/it)
Iteration 18960: accuracy_at_1 = 87.50%; accuracy_at_5 = 98.05%; loss = 0.398445  (0.701698 s/it)
Iteration 18970: accuracy_at_1 = 88.67%; accuracy_at_5 = 98.44%; loss = 0.381747  (0.701412 s/it)
Iteration 18980: accuracy_at_1 = 85.94%; accuracy_at_5 = 98.83%; loss = 0.427850  (0.702323 s/it)
Iteration 18990: accuracy_at_1 = 91.02%; accuracy_at_5 = 98.83%; loss = 0.337870  (0.701452 s/it)
Iteration 19000: accuracy_at_1 = 88.28%; accuracy_at_5 = 99.22%; loss = 0.384970  (0.702050 s/it)
Iteration 19010: accuracy_at_1 = 89.06%; accuracy_at_5 = 99.22%; loss = 0.355389  (0.701099 s/it)
Iteration 19020: accuracy_at_1 = 86.72%; accuracy_at_5 = 98.83%; loss = 0.385185  (0.700492 s/it)
Iteration 19030: accuracy_at_1 = 89.84%; accuracy_at_5 = 99.61%; loss = 0.350275  (0.700185 s/it)
Iteration 19040: accuracy_at_1 = 87.11%; accuracy_at_5 = 99.61%; loss = 0.368818  (0.700055 s/it)
Iteration 19050: accuracy_at_1 = 87.50%; accuracy_at_5 = 99.61%; loss = 0.373671  (0.700946 s/it)
Iteration 19060: accuracy_at_1 = 87.50%; accuracy_at_5 = 99.61%; loss = 0.405626  (0.700744 s/it)
Iteration 19070: accuracy_at_1 = 90.62%; accuracy_at_5 = 99.61%; loss = 0.301528  (0.701145 s/it)
Iteration 19080: accuracy_at_1 = 87.89%; accuracy_at_5 = 98.44%; loss = 0.397600  (0.701472 s/it)
Iteration 19090: accuracy_at_1 = 87.89%; accuracy_at_5 = 99.61%; loss = 0.347172  (0.701773 s/it)
Iteration 19100: accuracy_at_1 = 87.50%; accuracy_at_5 = 99.22%; loss = 0.374381  (0.701692 s/it)
Iteration 19110: accuracy_at_1 = 87.89%; accuracy_at_5 = 99.61%; loss = 0.354187  (0.700975 s/it)
Iteration 19120: accuracy_at_1 = 87.89%; accuracy_at_5 = 98.83%; loss = 0.368117  (0.701883 s/it)
Iteration 19130: accuracy_at_1 = 85.94%; accuracy_at_5 = 99.61%; loss = 0.380116  (0.701631 s/it)
Iteration 19140: accuracy_at_1 = 88.28%; accuracy_at_5 = 99.22%; loss = 0.359139  (0.702011 s/it)
Iteration 19150: accuracy_at_1 = 87.50%; accuracy_at_5 = 99.22%; loss = 0.344086  (0.700516 s/it)
Iteration 19160: accuracy_at_1 = 92.58%; accuracy_at_5 = 99.61%; loss = 0.258999  (0.700369 s/it)
Iteration 19170: accuracy_at_1 = 89.84%; accuracy_at_5 = 100.00%; loss = 0.300276  (0.700765 s/it)
Iteration 19180: accuracy_at_1 = 91.41%; accuracy_at_5 = 99.61%; loss = 0.312966  (0.700071 s/it)
Iteration 19190: accuracy_at_1 = 87.50%; accuracy_at_5 = 99.61%; loss = 0.388177  (0.699949 s/it)
Iteration 19200: accuracy_at_1 = 89.45%; accuracy_at_5 = 100.00%; loss = 0.317239  (0.702164 s/it)
Iteration 19210: accuracy_at_1 = 88.67%; accuracy_at_5 = 98.83%; loss = 0.404247  (0.701884 s/it)
Iteration 19220: accuracy_at_1 = 87.50%; accuracy_at_5 = 98.83%; loss = 0.354347  (0.701307 s/it)
Iteration 19230: accuracy_at_1 = 89.84%; accuracy_at_5 = 99.61%; loss = 0.276414  (0.701558 s/it)
Iteration 19240: accuracy_at_1 = 92.97%; accuracy_at_5 = 98.83%; loss = 0.260200  (0.701629 s/it)
Iteration 19250: accuracy_at_1 = 87.11%; accuracy_at_5 = 99.22%; loss = 0.402621  (0.701306 s/it)
Iteration 19260: accuracy_at_1 = 88.28%; accuracy_at_5 = 99.61%; loss = 0.326529  (0.701820 s/it)
Iteration 19270: accuracy_at_1 = 90.62%; accuracy_at_5 = 100.00%; loss = 0.285095  (0.700535 s/it)
Iteration 19280: accuracy_at_1 = 89.45%; accuracy_at_5 = 98.44%; loss = 0.334036  (0.699777 s/it)
Iteration 19290: accuracy_at_1 = 91.02%; accuracy_at_5 = 98.83%; loss = 0.337016  (0.699560 s/it)
Iteration 19300: accuracy_at_1 = 91.02%; accuracy_at_5 = 99.61%; loss = 0.303992  (0.699918 s/it)
Iteration 19310: accuracy_at_1 = 87.11%; accuracy_at_5 = 99.22%; loss = 0.359794  (0.700280 s/it)
Iteration 19320: accuracy_at_1 = 89.84%; accuracy_at_5 = 99.22%; loss = 0.274692  (0.699956 s/it)
Iteration 19330: accuracy_at_1 = 91.80%; accuracy_at_5 = 99.22%; loss = 0.300909  (0.700686 s/it)
Iteration 19340: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.22%; loss = 0.319742  (0.701714 s/it)
Iteration 19350: accuracy_at_1 = 88.28%; accuracy_at_5 = 99.22%; loss = 0.400644  (0.701415 s/it)
Iteration 19360: accuracy_at_1 = 87.89%; accuracy_at_5 = 99.61%; loss = 0.318935  (0.701044 s/it)
Iteration 19370: accuracy_at_1 = 88.67%; accuracy_at_5 = 100.00%; loss = 0.331304  (0.701701 s/it)
Iteration 19380: accuracy_at_1 = 86.72%; accuracy_at_5 = 99.61%; loss = 0.345213  (0.700857 s/it)
Iteration 19390: accuracy_at_1 = 91.02%; accuracy_at_5 = 98.44%; loss = 0.317032  (0.701608 s/it)
Iteration 19400: accuracy_at_1 = 89.06%; accuracy_at_5 = 99.61%; loss = 0.331668  (0.700046 s/it)
Iteration 19410: accuracy_at_1 = 88.28%; accuracy_at_5 = 98.05%; loss = 0.390668  (0.700013 s/it)
Iteration 19420: accuracy_at_1 = 89.45%; accuracy_at_5 = 98.83%; loss = 0.331003  (0.700389 s/it)
Iteration 19430: accuracy_at_1 = 89.84%; accuracy_at_5 = 99.22%; loss = 0.351973  (0.700488 s/it)
Iteration 19440: accuracy_at_1 = 87.89%; accuracy_at_5 = 100.00%; loss = 0.378196  (0.700467 s/it)
Iteration 19450: accuracy_at_1 = 88.67%; accuracy_at_5 = 100.00%; loss = 0.325589  (0.699990 s/it)
Iteration 19460: accuracy_at_1 = 84.38%; accuracy_at_5 = 99.22%; loss = 0.430626  (0.701147 s/it)
Iteration 19470: accuracy_at_1 = 88.28%; accuracy_at_5 = 99.22%; loss = 0.358113  (0.701123 s/it)
Iteration 19480: accuracy_at_1 = 89.84%; accuracy_at_5 = 99.61%; loss = 0.321530  (0.701573 s/it)
Iteration 19490: accuracy_at_1 = 87.89%; accuracy_at_5 = 99.61%; loss = 0.332043  (0.701356 s/it)
Iteration 19500: accuracy_at_1 = 83.98%; accuracy_at_5 = 98.44%; loss = 0.434705  (0.700925 s/it)
Iteration 19510: accuracy_at_1 = 87.11%; accuracy_at_5 = 98.83%; loss = 0.418175  (0.701348 s/it)
Iteration 19520: accuracy_at_1 = 87.11%; accuracy_at_5 = 98.44%; loss = 0.372500  (0.701052 s/it)
Iteration 19530: accuracy_at_1 = 89.06%; accuracy_at_5 = 98.44%; loss = 0.358570  (0.702273 s/it)
Iteration 19540: accuracy_at_1 = 89.06%; accuracy_at_5 = 98.44%; loss = 0.375957  (0.701176 s/it)
Iteration 19550: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.260223  (0.699856 s/it)
Iteration 19560: accuracy_at_1 = 91.02%; accuracy_at_5 = 98.83%; loss = 0.266689  (0.699721 s/it)
Iteration 19570: accuracy_at_1 = 87.89%; accuracy_at_5 = 98.44%; loss = 0.340908  (0.700183 s/it)
Iteration 19580: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.199451  (0.700418 s/it)
Iteration 19590: accuracy_at_1 = 87.89%; accuracy_at_5 = 99.61%; loss = 0.309986  (0.700698 s/it)
Iteration 19600: accuracy_at_1 = 87.11%; accuracy_at_5 = 99.22%; loss = 0.358560  (0.701161 s/it)
Iteration 19610: accuracy_at_1 = 92.19%; accuracy_at_5 = 99.22%; loss = 0.255972  (0.701531 s/it)
Iteration 19620: accuracy_at_1 = 90.23%; accuracy_at_5 = 99.22%; loss = 0.292772  (0.701678 s/it)
Iteration 19630: accuracy_at_1 = 94.92%; accuracy_at_5 = 99.61%; loss = 0.235376  (0.701916 s/it)
Iteration 19640: accuracy_at_1 = 92.58%; accuracy_at_5 = 100.00%; loss = 0.252500  (0.701832 s/it)
Iteration 19650: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.247256  (0.701127 s/it)
Iteration 19660: accuracy_at_1 = 89.45%; accuracy_at_5 = 98.83%; loss = 0.334893  (0.700247 s/it)
Iteration 19670: accuracy_at_1 = 93.36%; accuracy_at_5 = 98.83%; loss = 0.250229  (0.700541 s/it)
Iteration 19680: accuracy_at_1 = 88.67%; accuracy_at_5 = 100.00%; loss = 0.319111  (0.700742 s/it)
Iteration 19690: accuracy_at_1 = 87.50%; accuracy_at_5 = 98.83%; loss = 0.398521  (0.700351 s/it)
Iteration 19700: accuracy_at_1 = 86.33%; accuracy_at_5 = 100.00%; loss = 0.370621  (0.700128 s/it)
Iteration 19710: accuracy_at_1 = 89.45%; accuracy_at_5 = 99.61%; loss = 0.337169  (0.700717 s/it)
Iteration 19720: accuracy_at_1 = 85.94%; accuracy_at_5 = 98.83%; loss = 0.442861  (0.701434 s/it)
Iteration 19730: accuracy_at_1 = 86.33%; accuracy_at_5 = 99.22%; loss = 0.419805  (0.701420 s/it)
Iteration 19740: accuracy_at_1 = 89.06%; accuracy_at_5 = 98.83%; loss = 0.365041  (0.701751 s/it)
Iteration 19750: accuracy_at_1 = 89.84%; accuracy_at_5 = 98.44%; loss = 0.300331  (0.701837 s/it)
Iteration 19760: accuracy_at_1 = 91.41%; accuracy_at_5 = 100.00%; loss = 0.294612  (0.703408 s/it)
Iteration 19770: accuracy_at_1 = 91.41%; accuracy_at_5 = 100.00%; loss = 0.238984  (0.701304 s/it)
Iteration 19780: accuracy_at_1 = 87.89%; accuracy_at_5 = 99.22%; loss = 0.387760  (0.700670 s/it)
Iteration 19790: accuracy_at_1 = 86.72%; accuracy_at_5 = 100.00%; loss = 0.402652  (0.700681 s/it)
Iteration 19800: accuracy_at_1 = 89.45%; accuracy_at_5 = 98.83%; loss = 0.343621  (0.700207 s/it)
Iteration 19810: accuracy_at_1 = 89.45%; accuracy_at_5 = 100.00%; loss = 0.286173  (0.700303 s/it)
Iteration 19820: accuracy_at_1 = 90.62%; accuracy_at_5 = 100.00%; loss = 0.303122  (0.700612 s/it)
Iteration 19830: accuracy_at_1 = 89.45%; accuracy_at_5 = 99.22%; loss = 0.346320  (0.699827 s/it)
Iteration 19840: accuracy_at_1 = 86.33%; accuracy_at_5 = 98.83%; loss = 0.389731  (0.700094 s/it)
Iteration 19850: accuracy_at_1 = 87.89%; accuracy_at_5 = 100.00%; loss = 0.335127  (0.701824 s/it)
Iteration 19860: accuracy_at_1 = 89.06%; accuracy_at_5 = 99.61%; loss = 0.334319  (0.701740 s/it)
Iteration 19870: accuracy_at_1 = 87.50%; accuracy_at_5 = 99.22%; loss = 0.332265  (0.702072 s/it)
Iteration 19880: accuracy_at_1 = 87.11%; accuracy_at_5 = 99.22%; loss = 0.359033  (0.701981 s/it)
Iteration 19890: accuracy_at_1 = 85.16%; accuracy_at_5 = 99.61%; loss = 0.366816  (0.701699 s/it)
Iteration 19900: accuracy_at_1 = 87.50%; accuracy_at_5 = 99.22%; loss = 0.351532  (0.701929 s/it)
Iteration 19910: accuracy_at_1 = 85.16%; accuracy_at_5 = 99.61%; loss = 0.403774  (0.701173 s/it)
Iteration 19920: accuracy_at_1 = 88.28%; accuracy_at_5 = 99.61%; loss = 0.305909  (0.701455 s/it)
Iteration 19930: accuracy_at_1 = 87.89%; accuracy_at_5 = 100.00%; loss = 0.310882  (0.700768 s/it)
Iteration 19940: accuracy_at_1 = 89.45%; accuracy_at_5 = 100.00%; loss = 0.262495  (0.700597 s/it)
Iteration 19950: accuracy_at_1 = 90.23%; accuracy_at_5 = 99.61%; loss = 0.307008  (0.700517 s/it)
Iteration 19960: accuracy_at_1 = 91.41%; accuracy_at_5 = 99.61%; loss = 0.246932  (0.700841 s/it)
Iteration 19970: accuracy_at_1 = 93.36%; accuracy_at_5 = 99.22%; loss = 0.269724  (0.701138 s/it)
Iteration 19980: accuracy_at_1 = 92.19%; accuracy_at_5 = 99.22%; loss = 0.256216  (0.701899 s/it)
Iteration 19990: accuracy_at_1 = 92.58%; accuracy_at_5 = 99.61%; loss = 0.236618  (0.701332 s/it)
Iteration 20000: accuracy_at_1 = 93.36%; accuracy_at_5 = 99.61%; loss = 0.252974  (0.714269 s/it)
Iteration 20010: accuracy_at_1 = 92.19%; accuracy_at_5 = 99.22%; loss = 0.279385  (0.700305 s/it)
Iteration 20020: accuracy_at_1 = 89.45%; accuracy_at_5 = 100.00%; loss = 0.317520  (0.701611 s/it)
Iteration 20030: accuracy_at_1 = 89.84%; accuracy_at_5 = 99.61%; loss = 0.292610  (0.701740 s/it)
Iteration 20040: accuracy_at_1 = 92.19%; accuracy_at_5 = 99.61%; loss = 0.231283  (0.700183 s/it)
Iteration 20050: accuracy_at_1 = 88.28%; accuracy_at_5 = 100.00%; loss = 0.280224  (0.700415 s/it)
Iteration 20060: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.218193  (0.700264 s/it)
Iteration 20070: accuracy_at_1 = 91.41%; accuracy_at_5 = 99.22%; loss = 0.277185  (0.700491 s/it)
Iteration 20080: accuracy_at_1 = 92.58%; accuracy_at_5 = 100.00%; loss = 0.255385  (0.700572 s/it)
Iteration 20090: accuracy_at_1 = 91.41%; accuracy_at_5 = 99.61%; loss = 0.263183  (0.700205 s/it)
Iteration 20100: accuracy_at_1 = 90.62%; accuracy_at_5 = 100.00%; loss = 0.251495  (0.701161 s/it)
Iteration 20110: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.205895  (0.701875 s/it)
Iteration 20120: accuracy_at_1 = 89.45%; accuracy_at_5 = 99.22%; loss = 0.320243  (0.701138 s/it)
Iteration 20130: accuracy_at_1 = 91.80%; accuracy_at_5 = 99.61%; loss = 0.273597  (0.702012 s/it)
Iteration 20140: accuracy_at_1 = 91.41%; accuracy_at_5 = 100.00%; loss = 0.247444  (0.701399 s/it)
Iteration 20150: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.22%; loss = 0.264781  (0.701478 s/it)
Iteration 20160: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.224207  (0.700865 s/it)
Iteration 20170: accuracy_at_1 = 91.02%; accuracy_at_5 = 99.22%; loss = 0.280539  (0.700633 s/it)
Iteration 20180: accuracy_at_1 = 89.06%; accuracy_at_5 = 99.22%; loss = 0.333042  (0.700903 s/it)
Iteration 20190: accuracy_at_1 = 93.36%; accuracy_at_5 = 99.22%; loss = 0.241334  (0.700226 s/it)
Iteration 20200: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.212988  (0.700436 s/it)
Iteration 20210: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.61%; loss = 0.217265  (0.700365 s/it)
Iteration 20220: accuracy_at_1 = 89.84%; accuracy_at_5 = 99.22%; loss = 0.314749  (0.701006 s/it)
Iteration 20230: accuracy_at_1 = 94.53%; accuracy_at_5 = 98.83%; loss = 0.207068  (0.701114 s/it)
Iteration 20240: accuracy_at_1 = 91.80%; accuracy_at_5 = 100.00%; loss = 0.247464  (0.700985 s/it)
Iteration 20250: accuracy_at_1 = 93.36%; accuracy_at_5 = 99.61%; loss = 0.224668  (0.701539 s/it)
Iteration 20260: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.207109  (0.700971 s/it)
Iteration 20270: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.191005  (0.701766 s/it)
Iteration 20280: accuracy_at_1 = 93.36%; accuracy_at_5 = 99.61%; loss = 0.248973  (0.701668 s/it)
Iteration 20290: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.201363  (0.702419 s/it)
Iteration 20300: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.214732  (0.700482 s/it)
Iteration 20310: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.214678  (0.702128 s/it)
Iteration 20320: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.61%; loss = 0.221742  (0.702167 s/it)
Iteration 20330: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.260682  (0.700240 s/it)
Iteration 20340: accuracy_at_1 = 91.02%; accuracy_at_5 = 100.00%; loss = 0.244078  (0.699747 s/it)
Iteration 20350: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.221846  (0.700999 s/it)
Iteration 20360: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.169608  (0.701615 s/it)
Iteration 20370: accuracy_at_1 = 91.02%; accuracy_at_5 = 100.00%; loss = 0.231834  (0.701618 s/it)
Iteration 20380: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.61%; loss = 0.229295  (0.701317 s/it)
Iteration 20390: accuracy_at_1 = 90.23%; accuracy_at_5 = 99.61%; loss = 0.274490  (0.700882 s/it)
Iteration 20400: accuracy_at_1 = 92.19%; accuracy_at_5 = 99.61%; loss = 0.241371  (0.701771 s/it)
Iteration 20410: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.198018  (0.701398 s/it)
Iteration 20420: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.232228  (0.700594 s/it)
Iteration 20430: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.197959  (0.700216 s/it)
Iteration 20440: accuracy_at_1 = 92.19%; accuracy_at_5 = 99.61%; loss = 0.221964  (0.700093 s/it)
Iteration 20450: accuracy_at_1 = 94.14%; accuracy_at_5 = 98.83%; loss = 0.211139  (0.700517 s/it)
Iteration 20460: accuracy_at_1 = 95.70%; accuracy_at_5 = 99.61%; loss = 0.174546  (0.700452 s/it)
Iteration 20470: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.223484  (0.700366 s/it)
Iteration 20480: accuracy_at_1 = 91.80%; accuracy_at_5 = 100.00%; loss = 0.223226  (0.700645 s/it)
Iteration 20490: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.209095  (0.701461 s/it)
Iteration 20500: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.250764  (0.701513 s/it)
Iteration 20510: accuracy_at_1 = 91.02%; accuracy_at_5 = 99.22%; loss = 0.243751  (0.701729 s/it)
Iteration 20520: accuracy_at_1 = 91.41%; accuracy_at_5 = 99.61%; loss = 0.257181  (0.701531 s/it)
Iteration 20530: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.230883  (0.701670 s/it)
Iteration 20540: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.61%; loss = 0.185145  (0.701390 s/it)
Iteration 20550: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.188180  (0.701235 s/it)
Iteration 20560: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.202360  (0.700307 s/it)
Iteration 20570: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.193149  (0.700750 s/it)
Iteration 20580: accuracy_at_1 = 92.58%; accuracy_at_5 = 100.00%; loss = 0.238583  (0.700363 s/it)
Iteration 20590: accuracy_at_1 = 93.36%; accuracy_at_5 = 99.61%; loss = 0.247145  (0.700834 s/it)
Iteration 20600: accuracy_at_1 = 92.19%; accuracy_at_5 = 98.83%; loss = 0.268835  (0.700456 s/it)
Iteration 20610: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.218960  (0.701857 s/it)
Iteration 20620: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.193885  (0.703586 s/it)
Iteration 20630: accuracy_at_1 = 91.02%; accuracy_at_5 = 99.61%; loss = 0.259482  (0.701947 s/it)
Iteration 20640: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.199756  (0.701629 s/it)
Iteration 20650: accuracy_at_1 = 91.02%; accuracy_at_5 = 100.00%; loss = 0.253932  (0.701778 s/it)
Iteration 20660: accuracy_at_1 = 91.41%; accuracy_at_5 = 100.00%; loss = 0.287271  (0.701871 s/it)
Iteration 20670: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.207013  (0.701881 s/it)
Iteration 20680: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.224955  (0.701079 s/it)
Iteration 20690: accuracy_at_1 = 92.58%; accuracy_at_5 = 100.00%; loss = 0.239564  (0.700901 s/it)
Iteration 20700: accuracy_at_1 = 91.02%; accuracy_at_5 = 100.00%; loss = 0.260662  (0.701502 s/it)
Iteration 20710: accuracy_at_1 = 92.58%; accuracy_at_5 = 99.61%; loss = 0.263518  (0.700250 s/it)
Iteration 20720: accuracy_at_1 = 91.41%; accuracy_at_5 = 99.22%; loss = 0.275472  (0.700892 s/it)
Iteration 20730: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.61%; loss = 0.170372  (0.700361 s/it)
Iteration 20740: accuracy_at_1 = 91.02%; accuracy_at_5 = 99.22%; loss = 0.263080  (0.701783 s/it)
Iteration 20750: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.221967  (0.701626 s/it)
Iteration 20760: accuracy_at_1 = 92.58%; accuracy_at_5 = 99.61%; loss = 0.217823  (0.701931 s/it)
Iteration 20770: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.195877  (0.701470 s/it)
Iteration 20780: accuracy_at_1 = 91.02%; accuracy_at_5 = 99.61%; loss = 0.288040  (0.701096 s/it)
Iteration 20790: accuracy_at_1 = 91.80%; accuracy_at_5 = 99.61%; loss = 0.219784  (0.701049 s/it)
Iteration 20800: accuracy_at_1 = 94.92%; accuracy_at_5 = 99.61%; loss = 0.182437  (0.701359 s/it)
Iteration 20810: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.179389  (0.699853 s/it)
Iteration 20820: accuracy_at_1 = 92.58%; accuracy_at_5 = 100.00%; loss = 0.202496  (0.700183 s/it)
Iteration 20830: accuracy_at_1 = 91.80%; accuracy_at_5 = 99.61%; loss = 0.275611  (0.700105 s/it)
Iteration 20840: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.234757  (0.700019 s/it)
Iteration 20850: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.61%; loss = 0.188927  (0.699992 s/it)
Iteration 20860: accuracy_at_1 = 90.23%; accuracy_at_5 = 99.22%; loss = 0.272701  (0.700272 s/it)
Iteration 20870: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.61%; loss = 0.202020  (0.703057 s/it)
Iteration 20880: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.177636  (0.701760 s/it)
Iteration 20890: accuracy_at_1 = 90.23%; accuracy_at_5 = 99.61%; loss = 0.286894  (0.701905 s/it)
Iteration 20900: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.142844  (0.702411 s/it)
Iteration 20910: accuracy_at_1 = 93.36%; accuracy_at_5 = 99.22%; loss = 0.247144  (0.701269 s/it)
Iteration 20920: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.190777  (0.702111 s/it)
Iteration 20930: accuracy_at_1 = 92.19%; accuracy_at_5 = 99.61%; loss = 0.259196  (0.701156 s/it)
Iteration 20940: accuracy_at_1 = 94.92%; accuracy_at_5 = 99.61%; loss = 0.199343  (0.700991 s/it)
Iteration 20950: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.162595  (0.700900 s/it)
Iteration 20960: accuracy_at_1 = 91.41%; accuracy_at_5 = 100.00%; loss = 0.228845  (0.700949 s/it)
Iteration 20970: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.164498  (0.700254 s/it)
Iteration 20980: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.61%; loss = 0.231246  (0.701325 s/it)
Iteration 20990: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.22%; loss = 0.210594  (0.701022 s/it)
Iteration 21000: accuracy_at_1 = 89.06%; accuracy_at_5 = 100.00%; loss = 0.296014  (0.701669 s/it)
Iteration 21010: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.224284  (0.701379 s/it)
Iteration 21020: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.22%; loss = 0.176562  (0.701361 s/it)
Iteration 21030: accuracy_at_1 = 92.19%; accuracy_at_5 = 99.61%; loss = 0.226973  (0.702071 s/it)
Iteration 21040: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.204460  (0.701759 s/it)
Iteration 21050: accuracy_at_1 = 90.62%; accuracy_at_5 = 100.00%; loss = 0.248031  (0.702274 s/it)
Iteration 21060: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.22%; loss = 0.229949  (0.701088 s/it)
Iteration 21070: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.184168  (0.700624 s/it)
Iteration 21080: accuracy_at_1 = 91.80%; accuracy_at_5 = 100.00%; loss = 0.238908  (0.700442 s/it)
Iteration 21090: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.189773  (0.701218 s/it)
Iteration 21100: accuracy_at_1 = 91.41%; accuracy_at_5 = 100.00%; loss = 0.273928  (0.699734 s/it)
Iteration 21110: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.199012  (0.700733 s/it)
Iteration 21120: accuracy_at_1 = 92.58%; accuracy_at_5 = 99.61%; loss = 0.270542  (0.700553 s/it)
Iteration 21130: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.213914  (0.701570 s/it)
Iteration 21140: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.61%; loss = 0.247837  (0.701107 s/it)
Iteration 21150: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.182375  (0.701262 s/it)
Iteration 21160: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.212833  (0.701732 s/it)
Iteration 21170: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.22%; loss = 0.224189  (0.701850 s/it)
Iteration 21180: accuracy_at_1 = 90.62%; accuracy_at_5 = 99.22%; loss = 0.254372  (0.701278 s/it)
Iteration 21190: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.208902  (0.700476 s/it)
Iteration 21200: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.157756  (0.700173 s/it)
Iteration 21210: accuracy_at_1 = 89.84%; accuracy_at_5 = 100.00%; loss = 0.288175  (0.700567 s/it)
Iteration 21220: accuracy_at_1 = 94.92%; accuracy_at_5 = 99.61%; loss = 0.212722  (0.699939 s/it)
Iteration 21230: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.223228  (0.700250 s/it)
Iteration 21240: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.61%; loss = 0.202227  (0.700201 s/it)
Iteration 21250: accuracy_at_1 = 90.62%; accuracy_at_5 = 99.22%; loss = 0.252341  (0.700616 s/it)
Iteration 21260: accuracy_at_1 = 92.58%; accuracy_at_5 = 100.00%; loss = 0.225424  (0.701293 s/it)
Iteration 21270: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.203410  (0.702485 s/it)
Iteration 21280: accuracy_at_1 = 91.41%; accuracy_at_5 = 100.00%; loss = 0.288782  (0.701384 s/it)
Iteration 21290: accuracy_at_1 = 89.84%; accuracy_at_5 = 99.22%; loss = 0.282490  (0.701145 s/it)
Iteration 21300: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.203438  (0.701236 s/it)
Iteration 21310: accuracy_at_1 = 89.84%; accuracy_at_5 = 99.22%; loss = 0.274492  (0.702209 s/it)
Iteration 21320: accuracy_at_1 = 91.02%; accuracy_at_5 = 100.00%; loss = 0.241792  (0.700286 s/it)
Iteration 21330: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.226996  (0.700511 s/it)
Iteration 21340: accuracy_at_1 = 91.41%; accuracy_at_5 = 99.61%; loss = 0.216888  (0.700417 s/it)
Iteration 21350: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.182722  (0.700499 s/it)
Iteration 21360: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.205115  (0.700005 s/it)
Iteration 21370: accuracy_at_1 = 90.23%; accuracy_at_5 = 99.61%; loss = 0.305869  (0.700383 s/it)
Iteration 21380: accuracy_at_1 = 92.58%; accuracy_at_5 = 99.61%; loss = 0.209197  (0.701732 s/it)
Iteration 21390: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.189381  (0.701656 s/it)
Iteration 21400: accuracy_at_1 = 91.02%; accuracy_at_5 = 99.22%; loss = 0.258709  (0.701375 s/it)
Iteration 21410: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.61%; loss = 0.220754  (0.701696 s/it)
Iteration 21420: accuracy_at_1 = 91.02%; accuracy_at_5 = 99.61%; loss = 0.273854  (0.701437 s/it)
Iteration 21430: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.183462  (0.702313 s/it)
Iteration 21440: accuracy_at_1 = 96.88%; accuracy_at_5 = 99.61%; loss = 0.140809  (0.701050 s/it)
Iteration 21450: accuracy_at_1 = 92.19%; accuracy_at_5 = 99.22%; loss = 0.255298  (0.700461 s/it)
Iteration 21460: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.200398  (0.700044 s/it)
Iteration 21470: accuracy_at_1 = 93.36%; accuracy_at_5 = 99.61%; loss = 0.201002  (0.700868 s/it)
Iteration 21480: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.217664  (0.700451 s/it)
Iteration 21490: accuracy_at_1 = 89.45%; accuracy_at_5 = 99.61%; loss = 0.302142  (0.701617 s/it)
Iteration 21500: accuracy_at_1 = 90.62%; accuracy_at_5 = 99.61%; loss = 0.205159  (0.700381 s/it)
Iteration 21510: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.161422  (0.701837 s/it)
Iteration 21520: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.211144  (0.701673 s/it)
Iteration 21530: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.61%; loss = 0.265007  (0.701126 s/it)
Iteration 21540: accuracy_at_1 = 89.84%; accuracy_at_5 = 100.00%; loss = 0.258932  (0.701401 s/it)
Iteration 21550: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.195736  (0.702001 s/it)
Iteration 21560: accuracy_at_1 = 91.80%; accuracy_at_5 = 100.00%; loss = 0.218940  (0.701937 s/it)
Iteration 21570: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.188735  (0.700605 s/it)
Iteration 21580: accuracy_at_1 = 90.23%; accuracy_at_5 = 100.00%; loss = 0.295921  (0.700358 s/it)
Iteration 21590: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.211106  (0.700651 s/it)
Iteration 21600: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.195348  (0.701232 s/it)
Iteration 21610: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.184295  (0.700007 s/it)
Iteration 21620: accuracy_at_1 = 92.58%; accuracy_at_5 = 99.22%; loss = 0.238850  (0.700903 s/it)
Iteration 21630: accuracy_at_1 = 91.80%; accuracy_at_5 = 99.61%; loss = 0.209842  (0.700000 s/it)
Iteration 21640: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.196909  (0.700784 s/it)
Iteration 21650: accuracy_at_1 = 96.09%; accuracy_at_5 = 99.61%; loss = 0.150529  (0.701448 s/it)
Iteration 21660: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.201363  (0.700780 s/it)
Iteration 21670: accuracy_at_1 = 90.23%; accuracy_at_5 = 100.00%; loss = 0.281244  (0.700976 s/it)
Iteration 21680: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.187741  (0.700839 s/it)
Iteration 21690: accuracy_at_1 = 91.02%; accuracy_at_5 = 100.00%; loss = 0.229827  (0.701245 s/it)
Iteration 21700: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.180864  (0.700363 s/it)
Iteration 21710: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.172651  (0.701987 s/it)
Iteration 21720: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.61%; loss = 0.216177  (0.700412 s/it)
Iteration 21730: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.228729  (0.700366 s/it)
Iteration 21740: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.246852  (0.700777 s/it)
Iteration 21750: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.210122  (0.700094 s/it)
Iteration 21760: accuracy_at_1 = 91.80%; accuracy_at_5 = 99.61%; loss = 0.262100  (0.701246 s/it)
Iteration 21770: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.22%; loss = 0.221494  (0.701724 s/it)
Iteration 21780: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.22%; loss = 0.200068  (0.702064 s/it)
Iteration 21790: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.61%; loss = 0.143132  (0.701960 s/it)
Iteration 21800: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.143298  (0.701760 s/it)
Iteration 21810: accuracy_at_1 = 97.27%; accuracy_at_5 = 100.00%; loss = 0.122650  (0.701288 s/it)
Iteration 21820: accuracy_at_1 = 91.80%; accuracy_at_5 = 100.00%; loss = 0.217318  (0.701771 s/it)
Iteration 21830: accuracy_at_1 = 92.19%; accuracy_at_5 = 99.61%; loss = 0.240295  (0.700675 s/it)
Iteration 21840: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.216229  (0.699545 s/it)
Iteration 21850: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.139341  (0.699810 s/it)
Iteration 21860: accuracy_at_1 = 89.06%; accuracy_at_5 = 100.00%; loss = 0.299291  (0.700252 s/it)
Iteration 21870: accuracy_at_1 = 92.19%; accuracy_at_5 = 99.22%; loss = 0.216407  (0.699941 s/it)
Iteration 21880: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.165243  (0.701208 s/it)
Iteration 21890: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.61%; loss = 0.201582  (0.701281 s/it)
Iteration 21900: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.207269  (0.701667 s/it)
Iteration 21910: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.205167  (0.702028 s/it)
Iteration 21920: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.221765  (0.701263 s/it)
Iteration 21930: accuracy_at_1 = 93.36%; accuracy_at_5 = 99.61%; loss = 0.231592  (0.701688 s/it)
Iteration 21940: accuracy_at_1 = 96.09%; accuracy_at_5 = 99.61%; loss = 0.173428  (0.701428 s/it)
Iteration 21950: accuracy_at_1 = 91.80%; accuracy_at_5 = 98.83%; loss = 0.265144  (0.701409 s/it)
Iteration 21960: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.195343  (0.700067 s/it)
Iteration 21970: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.61%; loss = 0.201243  (0.700076 s/it)
Iteration 21980: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.144975  (0.701209 s/it)
Iteration 21990: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.22%; loss = 0.203851  (0.701055 s/it)
Iteration 22000: accuracy_at_1 = 91.80%; accuracy_at_5 = 99.22%; loss = 0.216301  (0.700463 s/it)
Iteration 22010: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.61%; loss = 0.246386  (0.700717 s/it)
Iteration 22020: accuracy_at_1 = 91.02%; accuracy_at_5 = 98.83%; loss = 0.273625  (0.701361 s/it)
Iteration 22030: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.191215  (0.701931 s/it)
Iteration 22040: accuracy_at_1 = 94.92%; accuracy_at_5 = 99.61%; loss = 0.183628  (0.702160 s/it)
Iteration 22050: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.204804  (0.701929 s/it)
Iteration 22060: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.206209  (0.701561 s/it)
Iteration 22070: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.198096  (0.701829 s/it)
Iteration 22080: accuracy_at_1 = 91.02%; accuracy_at_5 = 99.61%; loss = 0.235726  (0.701430 s/it)
Iteration 22090: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.248833  (0.700281 s/it)
Iteration 22100: accuracy_at_1 = 94.92%; accuracy_at_5 = 99.61%; loss = 0.186471  (0.700344 s/it)
Iteration 22110: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.246442  (0.700116 s/it)
Iteration 22120: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.195488  (0.700238 s/it)
Iteration 22130: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.180276  (0.700184 s/it)
Iteration 22140: accuracy_at_1 = 92.58%; accuracy_at_5 = 99.61%; loss = 0.250679  (0.699943 s/it)
Iteration 22150: accuracy_at_1 = 93.36%; accuracy_at_5 = 99.61%; loss = 0.207360  (0.701758 s/it)
Iteration 22160: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.211626  (0.701684 s/it)
Iteration 22170: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.218585  (0.701192 s/it)
Iteration 22180: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.197744  (0.701450 s/it)
Iteration 22190: accuracy_at_1 = 92.19%; accuracy_at_5 = 99.22%; loss = 0.243865  (0.701158 s/it)
Iteration 22200: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.175311  (0.701473 s/it)
Iteration 22210: accuracy_at_1 = 91.80%; accuracy_at_5 = 100.00%; loss = 0.224124  (0.700832 s/it)
Iteration 22220: accuracy_at_1 = 92.58%; accuracy_at_5 = 99.61%; loss = 0.211046  (0.700537 s/it)
Iteration 22230: accuracy_at_1 = 93.36%; accuracy_at_5 = 99.61%; loss = 0.201443  (0.700200 s/it)
Iteration 22240: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.165570  (0.699945 s/it)
Iteration 22250: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.229738  (0.700489 s/it)
Iteration 22260: accuracy_at_1 = 94.92%; accuracy_at_5 = 99.61%; loss = 0.169377  (0.700853 s/it)
Iteration 22270: accuracy_at_1 = 91.41%; accuracy_at_5 = 100.00%; loss = 0.228197  (0.702068 s/it)
Iteration 22280: accuracy_at_1 = 91.80%; accuracy_at_5 = 100.00%; loss = 0.221662  (0.702513 s/it)
Iteration 22290: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.160522  (0.701880 s/it)
Iteration 22300: accuracy_at_1 = 91.80%; accuracy_at_5 = 99.61%; loss = 0.204214  (0.702451 s/it)
Iteration 22310: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.189256  (0.702123 s/it)
Iteration 22320: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.164477  (0.701434 s/it)
Iteration 22330: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.165468  (0.701895 s/it)
Iteration 22340: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.202949  (0.701545 s/it)
Iteration 22350: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.196423  (0.700321 s/it)
Iteration 22360: accuracy_at_1 = 92.58%; accuracy_at_5 = 99.61%; loss = 0.224737  (0.700417 s/it)
Iteration 22370: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.205824  (0.700300 s/it)
Iteration 22380: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.198644  (0.700089 s/it)
Iteration 22390: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.219238  (0.700527 s/it)
Iteration 22400: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.196281  (0.701856 s/it)
Iteration 22410: accuracy_at_1 = 90.23%; accuracy_at_5 = 98.83%; loss = 0.267368  (0.702234 s/it)
Iteration 22420: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.201624  (0.701896 s/it)
Iteration 22430: accuracy_at_1 = 94.92%; accuracy_at_5 = 99.61%; loss = 0.195413  (0.701605 s/it)
Iteration 22440: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.195771  (0.701230 s/it)
Iteration 22450: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.201214  (0.701096 s/it)
Iteration 22460: accuracy_at_1 = 92.58%; accuracy_at_5 = 99.61%; loss = 0.200730  (0.701115 s/it)
Iteration 22470: accuracy_at_1 = 91.41%; accuracy_at_5 = 100.00%; loss = 0.225815  (0.700294 s/it)
Iteration 22480: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.61%; loss = 0.157966  (0.701126 s/it)
Iteration 22490: accuracy_at_1 = 92.58%; accuracy_at_5 = 99.22%; loss = 0.222254  (0.699836 s/it)
Iteration 22500: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.218611  (0.700173 s/it)
Iteration 22510: accuracy_at_1 = 92.58%; accuracy_at_5 = 100.00%; loss = 0.198996  (0.700022 s/it)
Iteration 22520: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.155927  (0.700530 s/it)
Iteration 22530: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.22%; loss = 0.201390  (0.701612 s/it)
Iteration 22540: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.186524  (0.702975 s/it)
Iteration 22550: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.229652  (0.701821 s/it)
Iteration 22560: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.185497  (0.700918 s/it)
Iteration 22570: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.201090  (0.701433 s/it)
Iteration 22580: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.231865  (0.701757 s/it)
Iteration 22590: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.175497  (0.701486 s/it)
Iteration 22600: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.61%; loss = 0.192738  (0.700227 s/it)
Iteration 22610: accuracy_at_1 = 92.58%; accuracy_at_5 = 99.61%; loss = 0.202845  (0.700093 s/it)
Iteration 22620: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.205393  (0.699970 s/it)
Iteration 22630: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.61%; loss = 0.219381  (0.700096 s/it)
Iteration 22640: accuracy_at_1 = 92.58%; accuracy_at_5 = 100.00%; loss = 0.217402  (0.700288 s/it)
Iteration 22650: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.169688  (0.700671 s/it)
Iteration 22660: accuracy_at_1 = 91.41%; accuracy_at_5 = 99.61%; loss = 0.229605  (0.701870 s/it)
Iteration 22670: accuracy_at_1 = 91.80%; accuracy_at_5 = 99.61%; loss = 0.262819  (0.701334 s/it)
Iteration 22680: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.193764  (0.701047 s/it)
Iteration 22690: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.182001  (0.702112 s/it)
Iteration 22700: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.178553  (0.701873 s/it)
Iteration 22710: accuracy_at_1 = 91.41%; accuracy_at_5 = 99.61%; loss = 0.222754  (0.701429 s/it)
Iteration 22720: accuracy_at_1 = 90.62%; accuracy_at_5 = 100.00%; loss = 0.258100  (0.701264 s/it)
Iteration 22730: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.186086  (0.700320 s/it)
Iteration 22740: accuracy_at_1 = 92.58%; accuracy_at_5 = 100.00%; loss = 0.208994  (0.700505 s/it)
Iteration 22750: accuracy_at_1 = 92.19%; accuracy_at_5 = 99.61%; loss = 0.256722  (0.699810 s/it)
Iteration 22760: accuracy_at_1 = 93.36%; accuracy_at_5 = 99.61%; loss = 0.232689  (0.700041 s/it)
Iteration 22770: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.174530  (0.700052 s/it)
Iteration 22780: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.142840  (0.700288 s/it)
Iteration 22790: accuracy_at_1 = 93.36%; accuracy_at_5 = 99.22%; loss = 0.214796  (0.701894 s/it)
Iteration 22800: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.211559  (0.702617 s/it)
Iteration 22810: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.152909  (0.702050 s/it)
Iteration 22820: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.22%; loss = 0.198247  (0.702135 s/it)
Iteration 22830: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.22%; loss = 0.221009  (0.702017 s/it)
Iteration 22840: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.217422  (0.701871 s/it)
Iteration 22850: accuracy_at_1 = 92.58%; accuracy_at_5 = 100.00%; loss = 0.206484  (0.701268 s/it)
Iteration 22860: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.204886  (0.700648 s/it)
Iteration 22870: accuracy_at_1 = 93.36%; accuracy_at_5 = 99.61%; loss = 0.225911  (0.700829 s/it)
Iteration 22880: accuracy_at_1 = 96.09%; accuracy_at_5 = 99.61%; loss = 0.145236  (0.700639 s/it)
Iteration 22890: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.207878  (0.701274 s/it)
Iteration 22900: accuracy_at_1 = 97.66%; accuracy_at_5 = 99.61%; loss = 0.131822  (0.700572 s/it)
Iteration 22910: accuracy_at_1 = 97.27%; accuracy_at_5 = 100.00%; loss = 0.105501  (0.701425 s/it)
Iteration 22920: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.168025  (0.701517 s/it)
Iteration 22930: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.206202  (0.702306 s/it)
Iteration 22940: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.197423  (0.701745 s/it)
Iteration 22950: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.199014  (0.701340 s/it)
Iteration 22960: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.185519  (0.702341 s/it)
Iteration 22970: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.192509  (0.702156 s/it)
Iteration 22980: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.205446  (0.701052 s/it)
Iteration 22990: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.61%; loss = 0.178086  (0.700550 s/it)
Iteration 23000: accuracy_at_1 = 91.80%; accuracy_at_5 = 99.22%; loss = 0.257273  (0.700892 s/it)
Iteration 23010: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.177083  (0.701265 s/it)
Iteration 23020: accuracy_at_1 = 94.92%; accuracy_at_5 = 99.61%; loss = 0.196085  (0.700479 s/it)
Iteration 23030: accuracy_at_1 = 92.19%; accuracy_at_5 = 99.61%; loss = 0.209871  (0.700465 s/it)
Iteration 23040: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.61%; loss = 0.233070  (0.701178 s/it)
Iteration 23050: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.61%; loss = 0.221702  (0.703229 s/it)
Iteration 23060: accuracy_at_1 = 93.36%; accuracy_at_5 = 99.61%; loss = 0.183885  (0.701695 s/it)
Iteration 23070: accuracy_at_1 = 91.02%; accuracy_at_5 = 100.00%; loss = 0.252327  (0.701956 s/it)
Iteration 23080: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.192389  (0.701592 s/it)
Iteration 23090: accuracy_at_1 = 92.19%; accuracy_at_5 = 99.61%; loss = 0.232654  (0.702190 s/it)
Iteration 23100: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.184764  (0.703465 s/it)
Iteration 23110: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.206199  (0.701521 s/it)
Iteration 23120: accuracy_at_1 = 93.75%; accuracy_at_5 = 98.83%; loss = 0.227151  (0.700196 s/it)
Iteration 23130: accuracy_at_1 = 94.92%; accuracy_at_5 = 99.61%; loss = 0.157772  (0.700974 s/it)
Iteration 23140: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.142067  (0.700506 s/it)
Iteration 23150: accuracy_at_1 = 96.09%; accuracy_at_5 = 99.61%; loss = 0.142587  (0.700196 s/it)
Iteration 23160: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.61%; loss = 0.214765  (0.701069 s/it)
Iteration 23170: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.174377  (0.700766 s/it)
Iteration 23180: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.61%; loss = 0.227758  (0.701161 s/it)
Iteration 23190: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.178210  (0.701834 s/it)
Iteration 23200: accuracy_at_1 = 92.58%; accuracy_at_5 = 100.00%; loss = 0.219670  (0.701812 s/it)
Iteration 23210: accuracy_at_1 = 92.58%; accuracy_at_5 = 99.61%; loss = 0.221853  (0.701865 s/it)
Iteration 23220: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.162312  (0.701287 s/it)
Iteration 23230: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.177840  (0.701305 s/it)
Iteration 23240: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.159950  (0.700890 s/it)
Iteration 23250: accuracy_at_1 = 92.19%; accuracy_at_5 = 99.61%; loss = 0.251449  (0.700324 s/it)
Iteration 23260: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.195557  (0.699899 s/it)
Iteration 23270: accuracy_at_1 = 94.92%; accuracy_at_5 = 99.61%; loss = 0.204193  (0.700006 s/it)
Iteration 23280: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.209217  (0.700496 s/it)
Iteration 23290: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.167054  (0.700439 s/it)
Iteration 23300: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.178192  (0.701664 s/it)
Iteration 23310: accuracy_at_1 = 92.58%; accuracy_at_5 = 99.22%; loss = 0.203002  (0.701328 s/it)
Iteration 23320: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.207523  (0.701821 s/it)
Iteration 23330: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.145132  (0.701780 s/it)
Iteration 23340: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.211257  (0.702227 s/it)
Iteration 23350: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.144923  (0.701670 s/it)
Iteration 23360: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.142732  (0.701075 s/it)
Iteration 23370: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.151478  (0.700289 s/it)
Iteration 23380: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.197869  (0.699794 s/it)
Iteration 23390: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.204323  (0.700893 s/it)
Iteration 23400: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.225939  (0.700466 s/it)
Iteration 23410: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.193769  (0.699899 s/it)
Iteration 23420: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.168019  (0.700167 s/it)
Iteration 23430: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.191857  (0.701509 s/it)
Iteration 23440: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.187852  (0.702789 s/it)
Iteration 23450: accuracy_at_1 = 97.27%; accuracy_at_5 = 99.61%; loss = 0.198759  (0.701512 s/it)
Iteration 23460: accuracy_at_1 = 97.66%; accuracy_at_5 = 100.00%; loss = 0.110986  (0.700937 s/it)
Iteration 23470: accuracy_at_1 = 96.48%; accuracy_at_5 = 99.61%; loss = 0.144427  (0.702263 s/it)
Iteration 23480: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.165224  (0.700979 s/it)
Iteration 23490: accuracy_at_1 = 91.41%; accuracy_at_5 = 99.61%; loss = 0.260436  (0.700703 s/it)
Iteration 23500: accuracy_at_1 = 96.88%; accuracy_at_5 = 100.00%; loss = 0.126297  (0.700566 s/it)
Iteration 23510: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.145505  (0.700213 s/it)
Iteration 23520: accuracy_at_1 = 91.41%; accuracy_at_5 = 100.00%; loss = 0.196063  (0.700119 s/it)
Iteration 23530: accuracy_at_1 = 92.58%; accuracy_at_5 = 99.22%; loss = 0.212356  (0.700352 s/it)
Iteration 23540: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.147060  (0.700711 s/it)
Iteration 23550: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.175649  (0.700865 s/it)
Iteration 23560: accuracy_at_1 = 93.36%; accuracy_at_5 = 98.83%; loss = 0.229171  (0.702300 s/it)
Iteration 23570: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.165414  (0.701773 s/it)
Iteration 23580: accuracy_at_1 = 96.09%; accuracy_at_5 = 99.61%; loss = 0.188404  (0.701669 s/it)
Iteration 23590: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.179149  (0.701829 s/it)
Iteration 23600: accuracy_at_1 = 91.02%; accuracy_at_5 = 99.22%; loss = 0.235596  (0.701744 s/it)
Iteration 23610: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.169562  (0.700922 s/it)
Iteration 23620: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.235932  (0.701027 s/it)
Iteration 23630: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.182505  (0.700604 s/it)
Iteration 23640: accuracy_at_1 = 92.19%; accuracy_at_5 = 99.22%; loss = 0.234072  (0.700009 s/it)
Iteration 23650: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.177807  (0.701202 s/it)
Iteration 23660: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.214591  (0.700910 s/it)
Iteration 23670: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.150472  (0.700375 s/it)
Iteration 23680: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.179930  (0.700465 s/it)
Iteration 23690: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.199252  (0.701647 s/it)
Iteration 23700: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.150653  (0.702199 s/it)
Iteration 23710: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.22%; loss = 0.224309  (0.701727 s/it)
Iteration 23720: accuracy_at_1 = 92.58%; accuracy_at_5 = 99.61%; loss = 0.195940  (0.701346 s/it)
Iteration 23730: accuracy_at_1 = 91.80%; accuracy_at_5 = 99.61%; loss = 0.204442  (0.701707 s/it)
Iteration 23740: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.172484  (0.701656 s/it)
Iteration 23750: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.182005  (0.701280 s/it)
Iteration 23760: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.165614  (0.700253 s/it)
Iteration 23770: accuracy_at_1 = 91.80%; accuracy_at_5 = 100.00%; loss = 0.252136  (0.700950 s/it)
Iteration 23780: accuracy_at_1 = 90.23%; accuracy_at_5 = 100.00%; loss = 0.238130  (0.700747 s/it)
Iteration 23790: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.218937  (0.700021 s/it)
Iteration 23800: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.161460  (0.700438 s/it)
Iteration 23810: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.61%; loss = 0.197591  (0.700728 s/it)
Iteration 23820: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.154697  (0.701364 s/it)
Iteration 23830: accuracy_at_1 = 96.88%; accuracy_at_5 = 100.00%; loss = 0.138582  (0.701953 s/it)
Iteration 23840: accuracy_at_1 = 92.97%; accuracy_at_5 = 98.83%; loss = 0.237663  (0.701412 s/it)
Iteration 23850: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.219651  (0.701927 s/it)
Iteration 23860: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.157369  (0.701217 s/it)
Iteration 23870: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.135219  (0.701113 s/it)
Iteration 23880: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.61%; loss = 0.184038  (0.699956 s/it)
Iteration 23890: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.240456  (0.700256 s/it)
Iteration 23900: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.219196  (0.700701 s/it)
Iteration 23910: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.132225  (0.700675 s/it)
Iteration 23920: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.210477  (0.700387 s/it)
Iteration 23930: accuracy_at_1 = 93.36%; accuracy_at_5 = 98.83%; loss = 0.211208  (0.699970 s/it)
Iteration 23940: accuracy_at_1 = 91.41%; accuracy_at_5 = 98.83%; loss = 0.258771  (0.701093 s/it)
Iteration 23950: accuracy_at_1 = 91.41%; accuracy_at_5 = 99.61%; loss = 0.244704  (0.701750 s/it)
Iteration 23960: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.61%; loss = 0.214346  (0.701368 s/it)
Iteration 23970: accuracy_at_1 = 92.58%; accuracy_at_5 = 99.61%; loss = 0.237006  (0.701689 s/it)
Iteration 23980: accuracy_at_1 = 96.09%; accuracy_at_5 = 99.61%; loss = 0.172588  (0.701523 s/it)
Iteration 23990: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.187275  (0.701725 s/it)
Iteration 24000: accuracy_at_1 = 97.66%; accuracy_at_5 = 100.00%; loss = 0.118803  (0.701896 s/it)
Iteration 24010: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.202476  (0.700579 s/it)
Iteration 24020: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.169931  (0.699930 s/it)
Iteration 24030: accuracy_at_1 = 91.80%; accuracy_at_5 = 99.22%; loss = 0.198175  (0.699867 s/it)
Iteration 24040: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.257176  (0.700350 s/it)
Iteration 24050: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.174838  (0.700662 s/it)
Iteration 24060: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.164451  (0.700164 s/it)
Iteration 24070: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.178150  (0.702051 s/it)
Iteration 24080: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.167736  (0.701332 s/it)
Iteration 24090: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.22%; loss = 0.229203  (0.701738 s/it)
Iteration 24100: accuracy_at_1 = 93.36%; accuracy_at_5 = 98.83%; loss = 0.212612  (0.701396 s/it)
Iteration 24110: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.156542  (0.700737 s/it)
Iteration 24120: accuracy_at_1 = 96.09%; accuracy_at_5 = 99.61%; loss = 0.156694  (0.702372 s/it)
Iteration 24130: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.186826  (0.701071 s/it)
Iteration 24140: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.182172  (0.699999 s/it)
Iteration 24150: accuracy_at_1 = 93.75%; accuracy_at_5 = 98.83%; loss = 0.206549  (0.700923 s/it)
Iteration 24160: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.22%; loss = 0.232409  (0.699897 s/it)
Iteration 24170: accuracy_at_1 = 95.70%; accuracy_at_5 = 99.61%; loss = 0.182086  (0.699949 s/it)
Iteration 24180: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.61%; loss = 0.190818  (0.699680 s/it)
Iteration 24190: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.194953  (0.701077 s/it)
Iteration 24200: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.200929  (0.702336 s/it)
Iteration 24210: accuracy_at_1 = 91.80%; accuracy_at_5 = 99.61%; loss = 0.226518  (0.703432 s/it)
Iteration 24220: accuracy_at_1 = 96.09%; accuracy_at_5 = 99.61%; loss = 0.150082  (0.703203 s/it)
Iteration 24230: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.188535  (0.701436 s/it)
Iteration 24240: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.154329  (0.701636 s/it)
Iteration 24250: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.61%; loss = 0.197001  (0.701709 s/it)
Iteration 24260: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.208883  (0.700904 s/it)
Iteration 24270: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.162777  (0.700797 s/it)
Iteration 24280: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.186715  (0.700609 s/it)
Iteration 24290: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.181843  (0.700097 s/it)
Iteration 24300: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.22%; loss = 0.194105  (0.699898 s/it)
Iteration 24310: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.155726  (0.700028 s/it)
Iteration 24320: accuracy_at_1 = 93.36%; accuracy_at_5 = 98.83%; loss = 0.178915  (0.700467 s/it)
Iteration 24330: accuracy_at_1 = 96.88%; accuracy_at_5 = 100.00%; loss = 0.147637  (0.702601 s/it)
Iteration 24340: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.169094  (0.701180 s/it)
Iteration 24350: accuracy_at_1 = 96.88%; accuracy_at_5 = 100.00%; loss = 0.122544  (0.701305 s/it)
Iteration 24360: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.198495  (0.701730 s/it)
Iteration 24370: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.174041  (0.701225 s/it)
Iteration 24380: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.187438  (0.701108 s/it)
Iteration 24390: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.213512  (0.700343 s/it)
Iteration 24400: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.151408  (0.700748 s/it)
Iteration 24410: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.171138  (0.700103 s/it)
Iteration 24420: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.167070  (0.700624 s/it)
Iteration 24430: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.143469  (0.700401 s/it)
Iteration 24440: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.165544  (0.700123 s/it)
Iteration 24450: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.61%; loss = 0.190919  (0.700797 s/it)
Iteration 24460: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.187580  (0.702040 s/it)
Iteration 24470: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.172086  (0.701331 s/it)
Iteration 24480: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.131196  (0.701330 s/it)
Iteration 24490: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.185100  (0.701267 s/it)
Iteration 24500: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.167620  (0.701114 s/it)
Iteration 24510: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.172257  (0.701487 s/it)
Iteration 24520: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.225701  (0.699896 s/it)
Iteration 24530: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.156452  (0.700528 s/it)
Iteration 24540: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.200797  (0.700050 s/it)
Iteration 24550: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.193889  (0.700159 s/it)
Iteration 24560: accuracy_at_1 = 92.19%; accuracy_at_5 = 99.61%; loss = 0.212749  (0.700663 s/it)
Iteration 24570: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.116645  (0.700320 s/it)
Iteration 24580: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.179740  (0.701148 s/it)
Iteration 24590: accuracy_at_1 = 90.62%; accuracy_at_5 = 100.00%; loss = 0.217026  (0.701518 s/it)
Iteration 24600: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.148347  (0.701572 s/it)
Iteration 24610: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.165730  (0.702333 s/it)
Iteration 24620: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.197847  (0.702172 s/it)
Iteration 24630: accuracy_at_1 = 96.88%; accuracy_at_5 = 100.00%; loss = 0.117955  (0.701268 s/it)
Iteration 24640: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.154644  (0.701719 s/it)
Iteration 24650: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.173438  (0.699714 s/it)
Iteration 24660: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.158750  (0.701584 s/it)
Iteration 24670: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.237209  (0.699831 s/it)
Iteration 24680: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.147058  (0.700283 s/it)
Iteration 24690: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.22%; loss = 0.223511  (0.700222 s/it)
Iteration 24700: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.136303  (0.700312 s/it)
Iteration 24710: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.187289  (0.701801 s/it)
Iteration 24720: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.214231  (0.701346 s/it)
Iteration 24730: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.170006  (0.701490 s/it)
Iteration 24740: accuracy_at_1 = 94.92%; accuracy_at_5 = 99.61%; loss = 0.144151  (0.701572 s/it)
Iteration 24750: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.182119  (0.701660 s/it)
Iteration 24760: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.172695  (0.702647 s/it)
Iteration 24770: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.206874  (0.703232 s/it)
Iteration 24780: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.194305  (0.700770 s/it)
Iteration 24790: accuracy_at_1 = 96.09%; accuracy_at_5 = 99.61%; loss = 0.143843  (0.700733 s/it)
Iteration 24800: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.61%; loss = 0.214473  (0.700257 s/it)
Iteration 24810: accuracy_at_1 = 95.70%; accuracy_at_5 = 99.61%; loss = 0.172788  (0.701123 s/it)
Iteration 24820: accuracy_at_1 = 96.48%; accuracy_at_5 = 99.61%; loss = 0.173116  (0.700019 s/it)
Iteration 24830: accuracy_at_1 = 93.36%; accuracy_at_5 = 99.61%; loss = 0.206929  (0.700377 s/it)
Iteration 24840: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.61%; loss = 0.233913  (0.701574 s/it)
Iteration 24850: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.139063  (0.701919 s/it)
Iteration 24860: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.168160  (0.701263 s/it)
Iteration 24870: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.149362  (0.701662 s/it)
Iteration 24880: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.187245  (0.701713 s/it)
Iteration 24890: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.184653  (0.701918 s/it)
Iteration 24900: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.179755  (0.700976 s/it)
Iteration 24910: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.22%; loss = 0.183673  (0.700370 s/it)
Iteration 24920: accuracy_at_1 = 93.75%; accuracy_at_5 = 98.83%; loss = 0.196463  (0.700821 s/it)
Iteration 24930: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.195749  (0.701284 s/it)
Iteration 24940: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.61%; loss = 0.191601  (0.699914 s/it)
Iteration 24950: accuracy_at_1 = 98.44%; accuracy_at_5 = 100.00%; loss = 0.119214  (0.700761 s/it)
Iteration 24960: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.218912  (0.701926 s/it)
Iteration 24970: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.166896  (0.702658 s/it)
Iteration 24980: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.145504  (0.702989 s/it)
Iteration 24990: accuracy_at_1 = 93.36%; accuracy_at_5 = 99.22%; loss = 0.212968  (0.703956 s/it)
Iteration 25000: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.132965  (0.717081 s/it)
Iteration 25010: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.145690  (0.702044 s/it)
Iteration 25020: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.162973  (0.702020 s/it)
Iteration 25030: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.167282  (0.702003 s/it)
Iteration 25040: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.156325  (0.702039 s/it)
Iteration 25050: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.131394  (0.702122 s/it)
Iteration 25060: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.152730  (0.701814 s/it)
Iteration 25070: accuracy_at_1 = 89.84%; accuracy_at_5 = 99.61%; loss = 0.216389  (0.700939 s/it)
Iteration 25080: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.22%; loss = 0.193256  (0.700995 s/it)
Iteration 25090: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.170636  (0.701708 s/it)
Iteration 25100: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.165837  (0.702860 s/it)
Iteration 25110: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.167946  (0.702008 s/it)
Iteration 25120: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.61%; loss = 0.174889  (0.701353 s/it)
Iteration 25130: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.150523  (0.701525 s/it)
Iteration 25140: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.165333  (0.701132 s/it)
Iteration 25150: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.148920  (0.701367 s/it)
Iteration 25160: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.167844  (0.700484 s/it)
Iteration 25170: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.156427  (0.700718 s/it)
Iteration 25180: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.192951  (0.700567 s/it)
Iteration 25190: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.200853  (0.700340 s/it)
Iteration 25200: accuracy_at_1 = 92.19%; accuracy_at_5 = 99.61%; loss = 0.236278  (0.699978 s/it)
Iteration 25210: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.188677  (0.700738 s/it)
Iteration 25220: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.207356  (0.701519 s/it)
Iteration 25230: accuracy_at_1 = 95.70%; accuracy_at_5 = 99.61%; loss = 0.188157  (0.701031 s/it)
Iteration 25240: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.146385  (0.701496 s/it)
Iteration 25250: accuracy_at_1 = 92.58%; accuracy_at_5 = 100.00%; loss = 0.206796  (0.701768 s/it)
Iteration 25260: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.153254  (0.701935 s/it)
Iteration 25270: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.147542  (0.701859 s/it)
Iteration 25280: accuracy_at_1 = 96.88%; accuracy_at_5 = 100.00%; loss = 0.141971  (0.701427 s/it)
Iteration 25290: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.172512  (0.700262 s/it)
Iteration 25300: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.122120  (0.699848 s/it)
Iteration 25310: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.186692  (0.701051 s/it)
Iteration 25320: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.22%; loss = 0.178253  (0.701981 s/it)
Iteration 25330: accuracy_at_1 = 97.27%; accuracy_at_5 = 100.00%; loss = 0.132123  (0.700967 s/it)
Iteration 25340: accuracy_at_1 = 96.88%; accuracy_at_5 = 100.00%; loss = 0.147211  (0.700489 s/it)
Iteration 25350: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.61%; loss = 0.219364  (0.701857 s/it)
Iteration 25360: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.176611  (0.701738 s/it)
Iteration 25370: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.149786  (0.702297 s/it)
Iteration 25380: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.169518  (0.701960 s/it)
Iteration 25390: accuracy_at_1 = 96.88%; accuracy_at_5 = 99.22%; loss = 0.134270  (0.702734 s/it)
Iteration 25400: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.144286  (0.701346 s/it)
Iteration 25410: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.175234  (0.701051 s/it)
Iteration 25420: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.147078  (0.700663 s/it)
Iteration 25430: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.152420  (0.700444 s/it)
Iteration 25440: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.22%; loss = 0.169141  (0.700872 s/it)
Iteration 25450: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.61%; loss = 0.245192  (0.700680 s/it)
Iteration 25460: accuracy_at_1 = 91.80%; accuracy_at_5 = 100.00%; loss = 0.202569  (0.700461 s/it)
Iteration 25470: accuracy_at_1 = 94.92%; accuracy_at_5 = 99.61%; loss = 0.169745  (0.700717 s/it)
Iteration 25480: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.158086  (0.701825 s/it)
Iteration 25490: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.146713  (0.701693 s/it)
Iteration 25500: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.22%; loss = 0.194564  (0.701958 s/it)
Iteration 25510: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.185457  (0.701674 s/it)
Iteration 25520: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.219089  (0.701121 s/it)
Iteration 25530: accuracy_at_1 = 96.09%; accuracy_at_5 = 99.61%; loss = 0.170687  (0.701666 s/it)
Iteration 25540: accuracy_at_1 = 97.27%; accuracy_at_5 = 100.00%; loss = 0.154190  (0.700932 s/it)
Iteration 25550: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.174312  (0.700814 s/it)
Iteration 25560: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.61%; loss = 0.206232  (0.700700 s/it)
Iteration 25570: accuracy_at_1 = 92.58%; accuracy_at_5 = 99.61%; loss = 0.213043  (0.699729 s/it)
Iteration 25580: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.219330  (0.700016 s/it)
Iteration 25590: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.169250  (0.700595 s/it)
Iteration 25600: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.145589  (0.700834 s/it)
Iteration 25610: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.162333  (0.701278 s/it)
Iteration 25620: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.22%; loss = 0.216831  (0.701244 s/it)
Iteration 25630: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.167811  (0.701601 s/it)
Iteration 25640: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.129866  (0.701797 s/it)
Iteration 25650: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.233454  (0.701243 s/it)
Iteration 25660: accuracy_at_1 = 91.41%; accuracy_at_5 = 100.00%; loss = 0.235605  (0.701563 s/it)
Iteration 25670: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.171342  (0.700398 s/it)
Iteration 25680: accuracy_at_1 = 97.27%; accuracy_at_5 = 100.00%; loss = 0.118444  (0.700052 s/it)
Iteration 25690: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.185449  (0.700067 s/it)
Iteration 25700: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.156076  (0.700119 s/it)
Iteration 25710: accuracy_at_1 = 92.58%; accuracy_at_5 = 99.22%; loss = 0.216516  (0.700057 s/it)
Iteration 25720: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.170814  (0.700308 s/it)
Iteration 25730: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.61%; loss = 0.203425  (0.701362 s/it)
Iteration 25740: accuracy_at_1 = 97.27%; accuracy_at_5 = 100.00%; loss = 0.126768  (0.702396 s/it)
Iteration 25750: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.186974  (0.701642 s/it)
Iteration 25760: accuracy_at_1 = 95.70%; accuracy_at_5 = 99.61%; loss = 0.152437  (0.701830 s/it)
Iteration 25770: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.171611  (0.701884 s/it)
Iteration 25780: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.132738  (0.702823 s/it)
Iteration 25790: accuracy_at_1 = 94.53%; accuracy_at_5 = 98.83%; loss = 0.182801  (0.701504 s/it)
Iteration 25800: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.197672  (0.700652 s/it)
Iteration 25810: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.22%; loss = 0.227237  (0.699962 s/it)
Iteration 25820: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.159812  (0.700143 s/it)
Iteration 25830: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.184540  (0.700623 s/it)
Iteration 25840: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.183871  (0.701006 s/it)
Iteration 25850: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.189753  (0.701233 s/it)
Iteration 25860: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.170315  (0.702321 s/it)
Iteration 25870: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.181443  (0.701499 s/it)
Iteration 25880: accuracy_at_1 = 94.92%; accuracy_at_5 = 99.61%; loss = 0.167434  (0.703540 s/it)
Iteration 25890: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.176431  (0.701998 s/it)
Iteration 25900: accuracy_at_1 = 97.27%; accuracy_at_5 = 100.00%; loss = 0.146488  (0.701675 s/it)
Iteration 25910: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.138887  (0.701720 s/it)
Iteration 25920: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.123987  (0.701348 s/it)
Iteration 25930: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.61%; loss = 0.167352  (0.700538 s/it)
Iteration 25940: accuracy_at_1 = 96.88%; accuracy_at_5 = 100.00%; loss = 0.129166  (0.700162 s/it)
Iteration 25950: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.123278  (0.700521 s/it)
Iteration 25960: accuracy_at_1 = 96.88%; accuracy_at_5 = 100.00%; loss = 0.161974  (0.700489 s/it)
Iteration 25970: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.156539  (0.700916 s/it)
Iteration 25980: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.61%; loss = 0.171124  (0.700776 s/it)
Iteration 25990: accuracy_at_1 = 96.88%; accuracy_at_5 = 100.00%; loss = 0.141746  (0.702677 s/it)
Iteration 26000: accuracy_at_1 = 91.80%; accuracy_at_5 = 100.00%; loss = 0.259081  (0.703103 s/it)
Iteration 26010: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.176235  (0.701614 s/it)
Iteration 26020: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.190103  (0.701537 s/it)
Iteration 26030: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.144677  (0.701387 s/it)
Iteration 26040: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.185634  (0.701870 s/it)
Iteration 26050: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.145251  (0.701086 s/it)
Iteration 26060: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.196987  (0.700464 s/it)
Iteration 26070: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.130726  (0.700802 s/it)
Iteration 26080: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.185658  (0.702009 s/it)
Iteration 26090: accuracy_at_1 = 93.36%; accuracy_at_5 = 99.61%; loss = 0.213241  (0.699804 s/it)
Iteration 26100: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.137397  (0.700592 s/it)
Iteration 26110: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.162980  (0.700883 s/it)
Iteration 26120: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.212052  (0.701682 s/it)
Iteration 26130: accuracy_at_1 = 92.58%; accuracy_at_5 = 100.00%; loss = 0.177981  (0.701798 s/it)
Iteration 26140: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.61%; loss = 0.143583  (0.701686 s/it)
Iteration 26150: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.146015  (0.701915 s/it)
Iteration 26160: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.182133  (0.701810 s/it)
Iteration 26170: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.140705  (0.702463 s/it)
Iteration 26180: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.206798  (0.700598 s/it)
Iteration 26190: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.22%; loss = 0.206382  (0.701432 s/it)
Iteration 26200: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.172998  (0.700538 s/it)
Iteration 26210: accuracy_at_1 = 91.02%; accuracy_at_5 = 99.22%; loss = 0.231604  (0.700539 s/it)
Iteration 26220: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.61%; loss = 0.202497  (0.700936 s/it)
Iteration 26230: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.155616  (0.700230 s/it)
Iteration 26240: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.156103  (0.700850 s/it)
Iteration 26250: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.61%; loss = 0.173505  (0.700908 s/it)
Iteration 26260: accuracy_at_1 = 92.58%; accuracy_at_5 = 100.00%; loss = 0.232618  (0.701803 s/it)
Iteration 26270: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.222358  (0.701832 s/it)
Iteration 26280: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.155523  (0.701232 s/it)
Iteration 26290: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.145001  (0.701329 s/it)
Iteration 26300: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.171739  (0.701843 s/it)
Iteration 26310: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.132057  (0.700688 s/it)
Iteration 26320: accuracy_at_1 = 91.41%; accuracy_at_5 = 100.00%; loss = 0.205841  (0.700349 s/it)
Iteration 26330: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.171116  (0.699639 s/it)
Iteration 26340: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.112936  (0.700229 s/it)
Iteration 26350: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.131157  (0.700380 s/it)
Iteration 26360: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.163667  (0.701134 s/it)
Iteration 26370: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.168511  (0.700816 s/it)
Iteration 26380: accuracy_at_1 = 94.92%; accuracy_at_5 = 99.61%; loss = 0.151575  (0.701071 s/it)
Iteration 26390: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.163177  (0.701700 s/it)
Iteration 26400: accuracy_at_1 = 92.58%; accuracy_at_5 = 99.61%; loss = 0.220387  (0.702104 s/it)
Iteration 26410: accuracy_at_1 = 92.58%; accuracy_at_5 = 100.00%; loss = 0.206438  (0.701748 s/it)
Iteration 26420: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.175006  (0.700959 s/it)
Iteration 26430: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.157733  (0.702234 s/it)
Iteration 26440: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.147113  (0.701710 s/it)
Iteration 26450: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.159805  (0.700610 s/it)
Iteration 26460: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.173070  (0.700238 s/it)
Iteration 26470: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.158026  (0.699699 s/it)
Iteration 26480: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.22%; loss = 0.209313  (0.700056 s/it)
Iteration 26490: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.184184  (0.700337 s/it)
Iteration 26500: accuracy_at_1 = 92.58%; accuracy_at_5 = 99.61%; loss = 0.213442  (0.701159 s/it)
Iteration 26510: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.183875  (0.701674 s/it)
Iteration 26520: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.152018  (0.702336 s/it)
Iteration 26530: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.61%; loss = 0.154820  (0.701252 s/it)
Iteration 26540: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.119822  (0.701383 s/it)
Iteration 26550: accuracy_at_1 = 92.19%; accuracy_at_5 = 99.61%; loss = 0.204357  (0.701326 s/it)
Iteration 26560: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.154033  (0.702410 s/it)
Iteration 26570: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.139263  (0.700078 s/it)
Iteration 26580: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.128341  (0.700164 s/it)
Iteration 26590: accuracy_at_1 = 92.19%; accuracy_at_5 = 99.61%; loss = 0.209239  (0.700153 s/it)
Iteration 26600: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.148125  (0.701284 s/it)
Iteration 26610: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.148631  (0.700863 s/it)
Iteration 26620: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.182026  (0.700581 s/it)
Iteration 26630: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.22%; loss = 0.213190  (0.702868 s/it)
Iteration 26640: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.61%; loss = 0.192445  (0.701565 s/it)
Iteration 26650: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.204452  (0.701579 s/it)
Iteration 26660: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.202200  (0.701577 s/it)
Iteration 26670: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.213980  (0.701540 s/it)
Iteration 26680: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.136460  (0.701309 s/it)
Iteration 26690: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.201190  (0.700737 s/it)
Iteration 26700: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.22%; loss = 0.192658  (0.701027 s/it)
Iteration 26710: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.192196  (0.700250 s/it)
Iteration 26720: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.133056  (0.700313 s/it)
Iteration 26730: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.187858  (0.700497 s/it)
Iteration 26740: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.151165  (0.701129 s/it)
Iteration 26750: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.143438  (0.700341 s/it)
Iteration 26760: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.123903  (0.701266 s/it)
Iteration 26770: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.168908  (0.701311 s/it)
Iteration 26780: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.160309  (0.701751 s/it)
Iteration 26790: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.150171  (0.702081 s/it)
Iteration 26800: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.162953  (0.702557 s/it)
Iteration 26810: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.177467  (0.702891 s/it)
Iteration 26820: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.145572  (0.701257 s/it)
Iteration 26830: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.61%; loss = 0.163846  (0.700614 s/it)
Iteration 26840: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.61%; loss = 0.199753  (0.700483 s/it)
Iteration 26850: accuracy_at_1 = 95.70%; accuracy_at_5 = 99.61%; loss = 0.170545  (0.700599 s/it)
Iteration 26860: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.115244  (0.700925 s/it)
Iteration 26870: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.184985  (0.700056 s/it)
Iteration 26880: accuracy_at_1 = 96.88%; accuracy_at_5 = 99.61%; loss = 0.134550  (0.700998 s/it)
Iteration 26890: accuracy_at_1 = 96.88%; accuracy_at_5 = 100.00%; loss = 0.159299  (0.701552 s/it)
Iteration 26900: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.163020  (0.701469 s/it)
Iteration 26910: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.161222  (0.701266 s/it)
Iteration 26920: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.139232  (0.700638 s/it)
Iteration 26930: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.176187  (0.701503 s/it)
Iteration 26940: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.177710  (0.701704 s/it)
Iteration 26950: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.177684  (0.702467 s/it)
Iteration 26960: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.151461  (0.700966 s/it)
Iteration 26970: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.153906  (0.700693 s/it)
Iteration 26980: accuracy_at_1 = 96.09%; accuracy_at_5 = 99.61%; loss = 0.170690  (0.700500 s/it)
Iteration 26990: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.61%; loss = 0.224879  (0.701623 s/it)
Iteration 27000: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.126563  (0.701877 s/it)
Iteration 27010: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.22%; loss = 0.186957  (0.700986 s/it)
Iteration 27020: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.137948  (0.701910 s/it)
Iteration 27030: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.165450  (0.701707 s/it)
Iteration 27040: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.153140  (0.701586 s/it)
Iteration 27050: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.61%; loss = 0.215760  (0.701735 s/it)
Iteration 27060: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.175850  (0.701383 s/it)
Iteration 27070: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.135560  (0.701602 s/it)
Iteration 27080: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.129657  (0.700976 s/it)
Iteration 27090: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.61%; loss = 0.173288  (0.700341 s/it)
Iteration 27100: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.133773  (0.700383 s/it)
Iteration 27110: accuracy_at_1 = 95.70%; accuracy_at_5 = 99.61%; loss = 0.144335  (0.700296 s/it)
Iteration 27120: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.157880  (0.700580 s/it)
Iteration 27130: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.180780  (0.700737 s/it)
Iteration 27140: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.155715  (0.702785 s/it)
Iteration 27150: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.170652  (0.701567 s/it)
Iteration 27160: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.189123  (0.702112 s/it)
Iteration 27170: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.181096  (0.688700 s/it)
Iteration 27180: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.146935  (0.697709 s/it)
Iteration 27190: accuracy_at_1 = 95.70%; accuracy_at_5 = 99.61%; loss = 0.177796  (0.697424 s/it)
Iteration 27200: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.186808  (0.697296 s/it)
Iteration 27210: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.169685  (0.696544 s/it)
Iteration 27220: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.232026  (0.696776 s/it)
Iteration 27230: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.154300  (0.696258 s/it)
Iteration 27240: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.61%; loss = 0.233954  (0.696469 s/it)
Iteration 27250: accuracy_at_1 = 96.48%; accuracy_at_5 = 99.61%; loss = 0.156766  (0.696344 s/it)
Iteration 27260: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.153617  (0.696439 s/it)
Iteration 27270: accuracy_at_1 = 95.70%; accuracy_at_5 = 99.61%; loss = 0.141038  (0.697878 s/it)
Iteration 27280: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.61%; loss = 0.171445  (0.697561 s/it)
Iteration 27290: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.213940  (0.697279 s/it)
Iteration 27300: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.139615  (0.697825 s/it)
Iteration 27310: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.61%; loss = 0.139150  (0.697202 s/it)
Iteration 27320: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.182323  (0.697434 s/it)
Iteration 27330: accuracy_at_1 = 96.88%; accuracy_at_5 = 100.00%; loss = 0.106323  (0.696813 s/it)
Iteration 27340: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.211489  (0.696020 s/it)
Iteration 27350: accuracy_at_1 = 95.70%; accuracy_at_5 = 99.61%; loss = 0.171952  (0.697070 s/it)
Iteration 27360: accuracy_at_1 = 97.66%; accuracy_at_5 = 100.00%; loss = 0.129650  (0.696601 s/it)
Iteration 27370: accuracy_at_1 = 93.36%; accuracy_at_5 = 99.61%; loss = 0.184623  (0.696481 s/it)
Iteration 27380: accuracy_at_1 = 94.92%; accuracy_at_5 = 99.61%; loss = 0.176400  (0.696530 s/it)
Iteration 27390: accuracy_at_1 = 96.88%; accuracy_at_5 = 100.00%; loss = 0.131631  (0.697426 s/it)
Iteration 27400: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.151179  (0.697629 s/it)
Iteration 27410: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.167849  (0.697812 s/it)
Iteration 27420: accuracy_at_1 = 96.48%; accuracy_at_5 = 99.61%; loss = 0.158382  (0.697361 s/it)
Iteration 27430: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.22%; loss = 0.189882  (0.698263 s/it)
Iteration 27440: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.162301  (0.697366 s/it)
Iteration 27450: accuracy_at_1 = 91.80%; accuracy_at_5 = 99.61%; loss = 0.256229  (0.697306 s/it)
Iteration 27460: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.192180  (0.696846 s/it)
Iteration 27470: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.61%; loss = 0.213942  (0.696668 s/it)
Iteration 27480: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.140090  (0.696354 s/it)
Iteration 27490: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.188704  (0.695662 s/it)
Iteration 27500: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.159759  (0.696389 s/it)
Iteration 27510: accuracy_at_1 = 94.92%; accuracy_at_5 = 99.22%; loss = 0.177091  (0.696469 s/it)
Iteration 27520: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.154724  (0.696079 s/it)
Iteration 27530: accuracy_at_1 = 92.97%; accuracy_at_5 = 99.61%; loss = 0.180810  (0.697756 s/it)
Iteration 27540: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.196350  (0.697783 s/it)
Iteration 27550: accuracy_at_1 = 96.09%; accuracy_at_5 = 99.61%; loss = 0.162453  (0.698101 s/it)
Iteration 27560: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.167934  (0.698505 s/it)
Iteration 27570: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.161272  (0.697764 s/it)
Iteration 27580: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.22%; loss = 0.154056  (0.697279 s/it)
Iteration 27590: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.175739  (0.696607 s/it)
Iteration 27600: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.171662  (0.696229 s/it)
Iteration 27610: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.137909  (0.696905 s/it)
Iteration 27620: accuracy_at_1 = 96.88%; accuracy_at_5 = 100.00%; loss = 0.133776  (0.697127 s/it)
Iteration 27630: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.179432  (0.696210 s/it)
Iteration 27640: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.170085  (0.696301 s/it)
Iteration 27650: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.153329  (0.696348 s/it)
Iteration 27660: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.145051  (0.697862 s/it)
Iteration 27670: accuracy_at_1 = 92.58%; accuracy_at_5 = 100.00%; loss = 0.179257  (0.697426 s/it)
Iteration 27680: accuracy_at_1 = 96.09%; accuracy_at_5 = 99.61%; loss = 0.129906  (0.697685 s/it)
Iteration 27690: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.140408  (0.696824 s/it)
Iteration 27700: accuracy_at_1 = 95.70%; accuracy_at_5 = 99.61%; loss = 0.128920  (0.697378 s/it)
Iteration 27710: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.160150  (0.697221 s/it)
Iteration 27720: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.140242  (0.697278 s/it)
Iteration 27730: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.150840  (0.696253 s/it)
Iteration 27740: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.169235  (0.696649 s/it)
Iteration 27750: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.174201  (0.696249 s/it)
Iteration 27760: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.147245  (0.695794 s/it)
Iteration 27770: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.150744  (0.696384 s/it)
Iteration 27780: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.152480  (0.697014 s/it)
Iteration 27790: accuracy_at_1 = 96.88%; accuracy_at_5 = 100.00%; loss = 0.141825  (0.697185 s/it)
Iteration 27800: accuracy_at_1 = 95.70%; accuracy_at_5 = 99.61%; loss = 0.159664  (0.697520 s/it)
Iteration 27810: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.173545  (0.697651 s/it)
Iteration 27820: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.168431  (0.697246 s/it)
Iteration 27830: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.159293  (0.697608 s/it)
Iteration 27840: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.152963  (0.697022 s/it)
Iteration 27850: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.61%; loss = 0.195647  (0.696634 s/it)
Iteration 27860: accuracy_at_1 = 95.70%; accuracy_at_5 = 99.61%; loss = 0.144664  (0.696029 s/it)
Iteration 27870: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.61%; loss = 0.161221  (0.696561 s/it)
Iteration 27880: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.174578  (0.696196 s/it)
Iteration 27890: accuracy_at_1 = 92.19%; accuracy_at_5 = 99.22%; loss = 0.233433  (0.696385 s/it)
Iteration 27900: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.156342  (0.696094 s/it)
Iteration 27910: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.159725  (0.697689 s/it)
Iteration 27920: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.179694  (0.697395 s/it)
Iteration 27930: accuracy_at_1 = 98.05%; accuracy_at_5 = 100.00%; loss = 0.133489  (0.697899 s/it)
Iteration 27940: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.184718  (0.698195 s/it)
Iteration 27950: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.140111  (0.697410 s/it)
Iteration 27960: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.157414  (0.697021 s/it)
Iteration 27970: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.161762  (0.696768 s/it)
Iteration 27980: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.189838  (0.695850 s/it)
Iteration 27990: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.156887  (0.696377 s/it)
Iteration 28000: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.61%; loss = 0.143544  (0.695992 s/it)
Iteration 28010: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.210083  (0.695966 s/it)
Iteration 28020: accuracy_at_1 = 92.58%; accuracy_at_5 = 100.00%; loss = 0.226837  (0.695673 s/it)
Iteration 28030: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.143604  (0.695699 s/it)
Iteration 28040: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.170474  (0.697020 s/it)
Iteration 28050: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.178652  (0.696603 s/it)
Iteration 28060: accuracy_at_1 = 94.92%; accuracy_at_5 = 99.61%; loss = 0.184996  (0.697496 s/it)
Iteration 28070: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.61%; loss = 0.146163  (0.697322 s/it)
Iteration 28080: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.178618  (0.697614 s/it)
Iteration 28090: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.157349  (0.697535 s/it)
Iteration 28100: accuracy_at_1 = 96.09%; accuracy_at_5 = 99.61%; loss = 0.153900  (0.696378 s/it)
Iteration 28110: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.160891  (0.696545 s/it)
Iteration 28120: accuracy_at_1 = 97.27%; accuracy_at_5 = 100.00%; loss = 0.106070  (0.696446 s/it)
Iteration 28130: accuracy_at_1 = 97.66%; accuracy_at_5 = 100.00%; loss = 0.106615  (0.696646 s/it)
Iteration 28140: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.132112  (0.696134 s/it)
Iteration 28150: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.185148  (0.696805 s/it)
Iteration 28160: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.185157  (0.696243 s/it)
Iteration 28170: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.133419  (0.697191 s/it)
Iteration 28180: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.168276  (0.697133 s/it)
Iteration 28190: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.162310  (0.697236 s/it)
Iteration 28200: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.163245  (0.697398 s/it)
Iteration 28210: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.174021  (0.697154 s/it)
Iteration 28220: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.159537  (0.697278 s/it)
Iteration 28230: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.61%; loss = 0.151787  (0.696152 s/it)
Iteration 28240: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.191592  (0.695243 s/it)
Iteration 28250: accuracy_at_1 = 97.66%; accuracy_at_5 = 99.61%; loss = 0.107503  (0.696579 s/it)
Iteration 28260: accuracy_at_1 = 96.88%; accuracy_at_5 = 99.61%; loss = 0.154174  (0.695300 s/it)
Iteration 28270: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.22%; loss = 0.157721  (0.696507 s/it)
Iteration 28280: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.153090  (0.695963 s/it)
Iteration 28290: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.147156  (0.696441 s/it)
Iteration 28300: accuracy_at_1 = 97.27%; accuracy_at_5 = 100.00%; loss = 0.126781  (0.696674 s/it)
Iteration 28310: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.153257  (0.697255 s/it)
Iteration 28320: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.153300  (0.697044 s/it)
Iteration 28330: accuracy_at_1 = 96.09%; accuracy_at_5 = 99.61%; loss = 0.130345  (0.697236 s/it)
Iteration 28340: accuracy_at_1 = 97.27%; accuracy_at_5 = 100.00%; loss = 0.100084  (0.696943 s/it)
Iteration 28350: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.159017  (0.697506 s/it)
Iteration 28360: accuracy_at_1 = 96.09%; accuracy_at_5 = 99.61%; loss = 0.138634  (0.695473 s/it)
Iteration 28370: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.174500  (0.695722 s/it)
Iteration 28380: accuracy_at_1 = 94.92%; accuracy_at_5 = 99.61%; loss = 0.157743  (0.696134 s/it)
Iteration 28390: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.163681  (0.696041 s/it)
Iteration 28400: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.180597  (0.696705 s/it)
Iteration 28410: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.165867  (0.695618 s/it)
Iteration 28420: accuracy_at_1 = 91.80%; accuracy_at_5 = 99.61%; loss = 0.213493  (0.696439 s/it)
Iteration 28430: accuracy_at_1 = 96.48%; accuracy_at_5 = 99.61%; loss = 0.157638  (0.696692 s/it)
Iteration 28440: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.151589  (0.696890 s/it)
Iteration 28450: accuracy_at_1 = 97.27%; accuracy_at_5 = 99.22%; loss = 0.151090  (0.697032 s/it)
Iteration 28460: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.134805  (0.697254 s/it)
Iteration 28470: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.137219  (0.697008 s/it)
Iteration 28480: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.176130  (0.696774 s/it)
Iteration 28490: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.134360  (0.696319 s/it)
Iteration 28500: accuracy_at_1 = 92.58%; accuracy_at_5 = 100.00%; loss = 0.208815  (0.696417 s/it)
Iteration 28510: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.139794  (0.695851 s/it)
Iteration 28520: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.146421  (0.696842 s/it)
Iteration 28530: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.144707  (0.696014 s/it)
Iteration 28540: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.61%; loss = 0.184370  (0.695659 s/it)
Iteration 28550: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.123551  (0.696638 s/it)
Iteration 28560: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.169275  (0.697356 s/it)
Iteration 28570: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.185070  (0.696610 s/it)
Iteration 28580: accuracy_at_1 = 94.92%; accuracy_at_5 = 99.61%; loss = 0.185599  (0.697581 s/it)
Iteration 28590: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.22%; loss = 0.139937  (0.697068 s/it)
Iteration 28600: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.143734  (0.697155 s/it)
Iteration 28610: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.170106  (0.696811 s/it)
Iteration 28620: accuracy_at_1 = 96.88%; accuracy_at_5 = 100.00%; loss = 0.125898  (0.695532 s/it)
Iteration 28630: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.173754  (0.695768 s/it)
Iteration 28640: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.170687  (0.695425 s/it)
Iteration 28650: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.140055  (0.695901 s/it)
Iteration 28660: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.135321  (0.696210 s/it)
Iteration 28670: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.61%; loss = 0.186903  (0.696921 s/it)
Iteration 28680: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.133080  (0.697942 s/it)
Iteration 28690: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.165913  (0.696987 s/it)
Iteration 28700: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.148935  (0.696750 s/it)
Iteration 28710: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.156614  (0.698681 s/it)
Iteration 28720: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.176180  (0.697641 s/it)
Iteration 28730: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.166223  (0.697968 s/it)
Iteration 28740: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.185387  (0.696785 s/it)
Iteration 28750: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.148618  (0.696372 s/it)
Iteration 28760: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.160097  (0.696137 s/it)
Iteration 28770: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.141645  (0.696455 s/it)
Iteration 28780: accuracy_at_1 = 98.83%; accuracy_at_5 = 100.00%; loss = 0.087837  (0.696225 s/it)
Iteration 28790: accuracy_at_1 = 96.48%; accuracy_at_5 = 99.61%; loss = 0.135171  (0.696158 s/it)
Iteration 28800: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.161103  (0.696559 s/it)
Iteration 28810: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.188985  (0.697522 s/it)
Iteration 28820: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.192521  (0.698561 s/it)
Iteration 28830: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.161837  (0.697087 s/it)
Iteration 28840: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.158502  (0.697381 s/it)
Iteration 28850: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.183906  (0.697715 s/it)
Iteration 28860: accuracy_at_1 = 97.27%; accuracy_at_5 = 100.00%; loss = 0.141217  (0.697418 s/it)
Iteration 28870: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.155407  (0.696503 s/it)
Iteration 28880: accuracy_at_1 = 97.66%; accuracy_at_5 = 100.00%; loss = 0.115984  (0.696686 s/it)
Iteration 28890: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.152731  (0.696534 s/it)
Iteration 28900: accuracy_at_1 = 94.92%; accuracy_at_5 = 99.22%; loss = 0.189043  (0.696250 s/it)
Iteration 28910: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.189449  (0.698060 s/it)
Iteration 28920: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.151945  (0.696539 s/it)
Iteration 28930: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.172163  (0.697409 s/it)
Iteration 28940: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.142620  (0.697067 s/it)
Iteration 28950: accuracy_at_1 = 98.05%; accuracy_at_5 = 100.00%; loss = 0.109607  (0.697555 s/it)
Iteration 28960: accuracy_at_1 = 96.88%; accuracy_at_5 = 100.00%; loss = 0.133018  (0.697582 s/it)
Iteration 28970: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.61%; loss = 0.186846  (0.697659 s/it)
Iteration 28980: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.131947  (0.697076 s/it)
Iteration 28990: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.150094  (0.697890 s/it)
Iteration 29000: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.181176  (0.696112 s/it)
Iteration 29010: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.161129  (0.695841 s/it)
Iteration 29020: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.137911  (0.696340 s/it)
Iteration 29030: accuracy_at_1 = 96.09%; accuracy_at_5 = 99.61%; loss = 0.123662  (0.696051 s/it)
Iteration 29040: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.140773  (0.697980 s/it)
Iteration 29050: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.138741  (0.696277 s/it)
Iteration 29060: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.131044  (0.697936 s/it)
Iteration 29070: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.149684  (0.698109 s/it)
Iteration 29080: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.155808  (0.697652 s/it)
Iteration 29090: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.122945  (0.697443 s/it)
Iteration 29100: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.161462  (0.697268 s/it)
Iteration 29110: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.132005  (0.697632 s/it)
Iteration 29120: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.141636  (0.697001 s/it)
Iteration 29130: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.120739  (0.696509 s/it)
Iteration 29140: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.22%; loss = 0.200696  (0.696255 s/it)
Iteration 29150: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.154484  (0.695877 s/it)
Iteration 29160: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.155543  (0.695714 s/it)
Iteration 29170: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.61%; loss = 0.175924  (0.696360 s/it)
Iteration 29180: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.159530  (0.696163 s/it)
Iteration 29190: accuracy_at_1 = 97.27%; accuracy_at_5 = 100.00%; loss = 0.133109  (0.697389 s/it)
Iteration 29200: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.149800  (0.697143 s/it)
Iteration 29210: accuracy_at_1 = 97.27%; accuracy_at_5 = 100.00%; loss = 0.113990  (0.697778 s/it)
Iteration 29220: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.129820  (0.697351 s/it)
Iteration 29230: accuracy_at_1 = 91.80%; accuracy_at_5 = 99.61%; loss = 0.213168  (0.697807 s/it)
Iteration 29240: accuracy_at_1 = 95.70%; accuracy_at_5 = 99.61%; loss = 0.196263  (0.698443 s/it)
Iteration 29250: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.61%; loss = 0.187550  (0.697448 s/it)
Iteration 29260: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.190484  (0.696783 s/it)
Iteration 29270: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.165279  (0.697546 s/it)
Iteration 29280: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.152884  (0.696090 s/it)
Iteration 29290: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.137482  (0.696625 s/it)
Iteration 29300: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.205242  (0.697728 s/it)
Iteration 29310: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.144852  (0.696131 s/it)
Iteration 29320: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.170176  (0.698018 s/it)
Iteration 29330: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.61%; loss = 0.190628  (0.697797 s/it)
Iteration 29340: accuracy_at_1 = 96.09%; accuracy_at_5 = 99.22%; loss = 0.148505  (0.697122 s/it)
Iteration 29350: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.150541  (0.697483 s/it)
Iteration 29360: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.150909  (0.697862 s/it)
Iteration 29370: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.146626  (0.698286 s/it)
Iteration 29380: accuracy_at_1 = 93.75%; accuracy_at_5 = 100.00%; loss = 0.178038  (0.697337 s/it)
Iteration 29390: accuracy_at_1 = 92.19%; accuracy_at_5 = 100.00%; loss = 0.202237  (0.696111 s/it)
Iteration 29400: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.198040  (0.696479 s/it)
Iteration 29410: accuracy_at_1 = 91.80%; accuracy_at_5 = 100.00%; loss = 0.214640  (0.696233 s/it)
Iteration 29420: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.113126  (0.696158 s/it)
Iteration 29430: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.146532  (0.696077 s/it)
Iteration 29440: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.139670  (0.696481 s/it)
Iteration 29450: accuracy_at_1 = 96.48%; accuracy_at_5 = 99.61%; loss = 0.133837  (0.697752 s/it)
Iteration 29460: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.192517  (0.697207 s/it)
Iteration 29470: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.137035  (0.697614 s/it)
Iteration 29480: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.143948  (0.697316 s/it)
Iteration 29490: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.146174  (0.697736 s/it)
Iteration 29500: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.131821  (0.697503 s/it)
Iteration 29510: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.184605  (0.696891 s/it)
Iteration 29520: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.150587  (0.696440 s/it)
Iteration 29530: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.184868  (0.695959 s/it)
Iteration 29540: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.183288  (0.696331 s/it)
Iteration 29550: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.174464  (0.696341 s/it)
Iteration 29560: accuracy_at_1 = 97.66%; accuracy_at_5 = 99.61%; loss = 0.127909  (0.696146 s/it)
Iteration 29570: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.149917  (0.697369 s/it)
Iteration 29580: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.131720  (0.697932 s/it)
Iteration 29590: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.209409  (0.697947 s/it)
Iteration 29600: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.143579  (0.698789 s/it)
Iteration 29610: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.148937  (0.698206 s/it)
Iteration 29620: accuracy_at_1 = 94.14%; accuracy_at_5 = 99.61%; loss = 0.182821  (0.697276 s/it)
Iteration 29630: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.135147  (0.697555 s/it)
Iteration 29640: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.146088  (0.696310 s/it)
Iteration 29650: accuracy_at_1 = 96.48%; accuracy_at_5 = 99.61%; loss = 0.154901  (0.696308 s/it)
Iteration 29660: accuracy_at_1 = 96.09%; accuracy_at_5 = 99.61%; loss = 0.164940  (0.696456 s/it)
Iteration 29670: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.134564  (0.695795 s/it)
Iteration 29680: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.114266  (0.695722 s/it)
Iteration 29690: accuracy_at_1 = 92.97%; accuracy_at_5 = 100.00%; loss = 0.197052  (0.697290 s/it)
Iteration 29700: accuracy_at_1 = 93.75%; accuracy_at_5 = 99.61%; loss = 0.172074  (0.696535 s/it)
Iteration 29710: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.153269  (0.698011 s/it)
Iteration 29720: accuracy_at_1 = 96.48%; accuracy_at_5 = 99.61%; loss = 0.122907  (0.697113 s/it)
Iteration 29730: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.134973  (0.697427 s/it)
Iteration 29740: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.157537  (0.697340 s/it)
Iteration 29750: accuracy_at_1 = 97.27%; accuracy_at_5 = 100.00%; loss = 0.121783  (0.696666 s/it)
Iteration 29760: accuracy_at_1 = 96.88%; accuracy_at_5 = 100.00%; loss = 0.108884  (0.696999 s/it)
Iteration 29770: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.147701  (0.695715 s/it)
Iteration 29780: accuracy_at_1 = 95.31%; accuracy_at_5 = 100.00%; loss = 0.149165  (0.695779 s/it)
Iteration 29790: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.152947  (0.695927 s/it)
Iteration 29800: accuracy_at_1 = 95.31%; accuracy_at_5 = 99.61%; loss = 0.177480  (0.697429 s/it)
Iteration 29810: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.186923  (0.696795 s/it)
Iteration 29820: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.127562  (0.695595 s/it)
Iteration 29830: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.170913  (0.697034 s/it)
Iteration 29840: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.157131  (0.697113 s/it)
Iteration 29850: accuracy_at_1 = 96.09%; accuracy_at_5 = 99.61%; loss = 0.156237  (0.697388 s/it)
Iteration 29860: accuracy_at_1 = 94.53%; accuracy_at_5 = 99.61%; loss = 0.145939  (0.697769 s/it)
Iteration 29870: accuracy_at_1 = 94.14%; accuracy_at_5 = 100.00%; loss = 0.179336  (0.697022 s/it)
Iteration 29880: accuracy_at_1 = 92.58%; accuracy_at_5 = 100.00%; loss = 0.190312  (0.697318 s/it)
Iteration 29890: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.147710  (0.696372 s/it)
Iteration 29900: accuracy_at_1 = 94.53%; accuracy_at_5 = 100.00%; loss = 0.149196  (0.695930 s/it)
Iteration 29910: accuracy_at_1 = 96.48%; accuracy_at_5 = 99.61%; loss = 0.115680  (0.695615 s/it)
Iteration 29920: accuracy_at_1 = 95.70%; accuracy_at_5 = 100.00%; loss = 0.161259  (0.696776 s/it)
Iteration 29930: accuracy_at_1 = 94.92%; accuracy_at_5 = 100.00%; loss = 0.139190  (0.696842 s/it)
Iteration 29940: accuracy_at_1 = 93.36%; accuracy_at_5 = 100.00%; loss = 0.157083  (0.696204 s/it)
Iteration 29950: accuracy_at_1 = 96.88%; accuracy_at_5 = 100.00%; loss = 0.133546  (0.696710 s/it)
Iteration 29960: accuracy_at_1 = 97.27%; accuracy_at_5 = 100.00%; loss = 0.117485  (0.697616 s/it)
Iteration 29970: accuracy_at_1 = 96.09%; accuracy_at_5 = 100.00%; loss = 0.161628  (0.697727 s/it)
Iteration 29980: accuracy_at_1 = 94.92%; accuracy_at_5 = 99.61%; loss = 0.172627  (0.697042 s/it)
Iteration 29990: accuracy_at_1 = 96.48%; accuracy_at_5 = 100.00%; loss = 0.163612  (0.697243 s/it)

Training complete. Evaluating...

Running evaluation for split: train
	Accuracy at 1 = 99.71%
	Accuracy at 5 = 99.99%
	Softmax cross-entropy error = 0.0308
Predictions for split train dumped to: top_5_predictions_nda.train.csv

Running evaluation for split: val
	Accuracy at 1 = 28.35%
	Accuracy at 5 = 55.12%
	Softmax cross-entropy error = 6.5507
Predictions for split val dumped to: top_5_predictions_nda.val.csv

Running evaluation for split: test
Not computing accuracy; ground truth unknown for split: test
Predictions for split test dumped to: top_5_predictions_nda.test.csv

Evaluation complete.
